const fs = require('fs');
const path = require('path');

// ë‚˜ë ˆì´ì…˜ í…ìŠ¤íŠ¸ ì •ì˜
const narrations = [
  {
    id: 'chapter1-title',
    text: 'ì•ˆë…•í•˜ì„¸ìš”. KSS ì˜¨í†¨ë¡œì§€ ê°•ì˜ 1ì¥, ì˜¨í†¨ë¡œì§€ë€ ë¬´ì—‡ì¸ê°€í¸ì…ë‹ˆë‹¤.',
    voice: 'female',
    language: 'ko'
  },
  {
    id: 'chapter1-section1',
    text: 'ì˜¨í†¨ë¡œì§€ëŠ” íŠ¹ì • ë„ë©”ì¸ì˜ ê°œë…ê³¼ ê·¸ë“¤ ê°„ì˜ ê´€ê³„ë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì •ì˜í•œ ê²ƒì…ë‹ˆë‹¤.',
    voice: 'female',
    language: 'ko'
  },
  {
    id: 'chapter1-section2',
    text: 'RDF íŠ¸ë¦¬í”Œì€ ì£¼ì–´, ìˆ ì–´, ëª©ì ì–´ë¡œ êµ¬ì„±ë˜ë©°, ì§€ì‹ì„ í‘œí˜„í•˜ëŠ” ê¸°ë³¸ ë‹¨ìœ„ì…ë‹ˆë‹¤.',
    voice: 'female',
    language: 'ko'
  },
  {
    id: 'chapter1-section3',
    text: 'ì˜ˆë¥¼ ë“¤ì–´, í™ê¸¸ë™ì€ ì‚¬ëŒì´ë‹¤ë¼ëŠ” ì§€ì‹ì€ í™ê¸¸ë™, rdf:type, ì‚¬ëŒìœ¼ë¡œ í‘œí˜„ë©ë‹ˆë‹¤.',
    voice: 'female',
    language: 'ko'
  },
  {
    id: 'chapter1-summary',
    text: 'ì˜¤ëŠ˜ ë°°ìš´ ë‚´ìš©ì„ KSS í”Œë«í¼ì—ì„œ ì§ì ‘ ì‹¤ìŠµí•´ë³´ì„¸ìš”. ë‹¤ìŒ ê°•ì˜ì—ì„œ ë§Œë‚˜ìš”!',
    voice: 'female',
    language: 'ko'
  }
];

// TTS ìƒì„± í•¨ìˆ˜ (ë¡œì»¬ API ì‚¬ìš©)
async function generateTTS(narration) {
  console.log(`Generating TTS for: ${narration.id}`);
  
  try {
    const response = await fetch('http://localhost:3000/api/tts/google', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        text: narration.text,
        voice: narration.voice,
        language: narration.language,
        speed: 1.0
      })
    });

    if (!response.ok) {
      const errorText = await response.text();
      console.error('API Error Response:', errorText);
      throw new Error(`TTS API error: ${response.status}`);
    }

    // ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ ArrayBufferë¡œ ë°›ê¸°
    const audioBuffer = await response.arrayBuffer();
    
    // íŒŒì¼ë¡œ ì €ì¥
    const outputPath = path.join(__dirname, '..', 'public', 'sounds', 'narrations', `${narration.id}.mp3`);
    
    // narrations ë””ë ‰í† ë¦¬ ìƒì„±
    const narrationsDir = path.join(__dirname, '..', 'public', 'sounds', 'narrations');
    if (!fs.existsSync(narrationsDir)) {
      fs.mkdirSync(narrationsDir, { recursive: true });
    }
    
    // Bufferë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥
    fs.writeFileSync(outputPath, Buffer.from(audioBuffer));
    console.log(`âœ… Saved: ${narration.id}.mp3 (${Buffer.from(audioBuffer).length} bytes)`);
    
    return outputPath;
  } catch (error) {
    console.error(`âŒ Error generating TTS for ${narration.id}:`, error.message);
    throw error;
  }
}

// ëª¨ë“  ë‚˜ë ˆì´ì…˜ ìƒì„±
async function generateAllNarrations() {
  console.log('ğŸ™ï¸ Starting TTS generation using local API...');
  console.log('âš ï¸  Make sure the dev server is running (npm run dev)\n');
  
  let successCount = 0;
  let errorCount = 0;
  
  for (const narration of narrations) {
    try {
      await generateTTS(narration);
      successCount++;
      // API ì œí•œì„ í”¼í•˜ê¸° ìœ„í•œ ë”œë ˆì´
      await new Promise(resolve => setTimeout(resolve, 500));
    } catch (error) {
      errorCount++;
      console.error(`Failed to generate ${narration.id}:`, error.message);
    }
  }
  
  console.log(`\nâœ¨ TTS generation completed!`);
  console.log(`âœ… Success: ${successCount}`);
  console.log(`âŒ Failed: ${errorCount}`);
  
  if (successCount > 0) {
    console.log('\nğŸ“ Audio files saved to: public/sounds/narrations/');
    console.log('ğŸ¬ You can now render videos with audio using:');
    console.log('   npm run video:render -- ChapterExplainerWithAudio');
  }
}

// ì‹¤í–‰
generateAllNarrations().catch(console.error);
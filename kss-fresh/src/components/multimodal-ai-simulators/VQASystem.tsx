'use client';

import { useState, useRef, useEffect } from 'react';
import {
  Image as ImageIcon, MessageSquare, Send, Sparkles,
  Eye, Brain, Lightbulb, RefreshCw, Camera
} from 'lucide-react';

interface ImageItem {
  id: string;
  label: string;
  emoji: string;
  description: string;
  exampleQuestions: string[];
}

interface VQAResult {
  question: string;
  answer: string;
  confidence: number;
  attentionRegions: { x: number; y: number; intensity: number }[];
  reasoning: string;
}

export default function VQASystem() {
  const [selectedImage, setSelectedImage] = useState<string>('cat');
  const [question, setQuestion] = useState('');
  const [vqaResults, setVqaResults] = useState<VQAResult[]>([]);
  const [isProcessing, setIsProcessing] = useState(false);
  const [showAttention, setShowAttention] = useState(true);
  const canvasRef = useRef<HTMLCanvasElement>(null);

  const imageGallery: ImageItem[] = [
    {
      id: 'cat',
      label: 'ê³ ì–‘ì´',
      emoji: 'ğŸ±',
      description: 'ì†ŒíŒŒì— ì•‰ì•„ìˆëŠ” ì£¼í™©ìƒ‰ ê³ ì–‘ì´',
      exampleQuestions: [
        'What color is the cat?',
        'Where is the cat sitting?',
        'Is the cat sleeping?',
        'How many cats are in the image?'
      ]
    },
    {
      id: 'beach',
      label: 'í•´ë³€',
      emoji: 'ğŸ–ï¸',
      description: 'ì•¼ììˆ˜ì™€ ë§‘ì€ ë¬¼ì´ ìˆëŠ” ì—´ëŒ€ í•´ë³€',
      exampleQuestions: [
        'What is the weather like?',
        'Are there palm trees?',
        'Is it a tropical beach?',
        'What color is the water?'
      ]
    },
    {
      id: 'city',
      label: 'ë„ì‹œ',
      emoji: 'ğŸŒƒ',
      description: 'ë°¤ì˜ í˜„ëŒ€ì ì¸ ë„ì‹œ ìŠ¤ì¹´ì´ë¼ì¸',
      exampleQuestions: [
        'Is it day or night?',
        'How many buildings are there?',
        'Are the lights on?',
        'What kind of city is this?'
      ]
    },
    {
      id: 'food',
      label: 'ìŒì‹',
      emoji: 'ğŸ•',
      description: 'ì¹˜ì¦ˆì™€ í† í•‘ì´ ìˆëŠ” í”¼ì',
      exampleQuestions: [
        'What type of food is this?',
        'What toppings are on the pizza?',
        'Is this Italian food?',
        'Does it look delicious?'
      ]
    },
    {
      id: 'mountain',
      label: 'ì‚°',
      emoji: 'â›°ï¸',
      description: 'íŒŒë€ í•˜ëŠ˜ ì•„ë˜ ëˆˆ ë®ì¸ ì‚°ë´‰ìš°ë¦¬',
      exampleQuestions: [
        'Is there snow on the mountain?',
        'What is the weather like?',
        'Is it a high mountain?',
        'What color is the sky?'
      ]
    },
    {
      id: 'car',
      label: 'ìë™ì°¨',
      emoji: 'ğŸš—',
      description: 'ì‚°ê¸¸ì˜ ë¹¨ê°„ ìŠ¤í¬ì¸ ì¹´',
      exampleQuestions: [
        'What color is the car?',
        'What type of car is it?',
        'Where is the car located?',
        'Is it moving?'
      ]
    }
  ];

  // Simulate VQA processing
  const processVQA = async (q: string) => {
    setIsProcessing(true);

    // Simulate processing delay
    await new Promise(resolve => setTimeout(resolve, 1000));

    const selectedImg = imageGallery.find(img => img.id === selectedImage)!;

    // Generate simulated answer based on question and image
    let answer = '';
    let confidence = 0.85 + Math.random() * 0.1;
    let reasoning = '';

    const qLower = q.toLowerCase();

    // Simple rule-based answering (simulating VQA model)
    if (qLower.includes('color')) {
      if (selectedImage === 'cat') {
        answer = 'The cat is orange/ginger colored.';
        reasoning = 'Detected dominant warm color tones in the main object (cat).';
      } else if (selectedImage === 'car') {
        answer = 'The car is red.';
        reasoning = 'Identified red color in the vehicle region.';
      } else if (selectedImage === 'beach') {
        answer = 'The water is turquoise blue and the sand is white.';
        reasoning = 'Analyzed color distribution in ocean and beach areas.';
      } else {
        answer = 'The image contains various colors.';
        reasoning = 'Multiple color regions detected.';
      }
    } else if (qLower.includes('how many')) {
      if (qLower.includes('cat')) {
        answer = 'There is one cat in the image.';
        reasoning = 'Object detection identified a single cat instance.';
      } else if (qLower.includes('building')) {
        answer = 'There are approximately 5-7 buildings visible.';
        reasoning = 'Counted building structures in the skyline.';
      } else {
        answer = 'Multiple objects are present.';
        reasoning = 'Performed object counting in the scene.';
      }
    } else if (qLower.includes('where')) {
      answer = `The ${selectedImg.label} is ${selectedImg.description.split(' ').slice(-3).join(' ')}.`;
      reasoning = 'Analyzed spatial relationships and scene context.';
    } else if (qLower.includes('is it') || qLower.includes('is the') || qLower.includes('are there')) {
      // Yes/No questions
      const keywords = ['yes', 'no', 'probably', 'likely'];
      answer = `${keywords[Math.floor(Math.random() * 2)]}, ${selectedImg.description.split(' ').slice(0, 5).join(' ')}.`;
      reasoning = 'Binary classification based on visual features.';
      confidence = 0.9 + Math.random() * 0.05;
    } else {
      answer = selectedImg.description;
      reasoning = 'Generated description using image captioning model.';
    }

    // Generate attention map (simulated)
    const attentionRegions: { x: number; y: number; intensity: number }[] = [];
    for (let i = 0; i < 20; i++) {
      attentionRegions.push({
        x: Math.random() * 400,
        y: Math.random() * 300,
        intensity: Math.random() * 0.8 + 0.2
      });
    }

    const result: VQAResult = {
      question: q,
      answer,
      confidence,
      attentionRegions,
      reasoning
    };

    setVqaResults([result, ...vqaResults].slice(0, 5));
    setIsProcessing(false);
  };

  const handleSubmit = () => {
    if (!question.trim()) {
      alert('Please enter a question.');
      return;
    }
    processVQA(question);
  };

  // Draw attention map
  useEffect(() => {
    const canvas = canvasRef.current;
    if (!canvas || !showAttention || vqaResults.length === 0) return;

    const ctx = canvas.getContext('2d');
    if (!ctx) return;

    const rect = canvas.getBoundingClientRect();
    canvas.width = rect.width * window.devicePixelRatio;
    canvas.height = rect.height * window.devicePixelRatio;
    ctx.scale(window.devicePixelRatio, window.devicePixelRatio);

    // Clear
    ctx.clearRect(0, 0, rect.width, rect.height);

    // Draw base image representation
    const selectedImg = imageGallery.find(img => img.id === selectedImage)!;
    ctx.fillStyle = '#1f2937';
    ctx.fillRect(0, 0, rect.width, rect.height);
    ctx.font = 'bold 80px sans-serif';
    ctx.textAlign = 'center';
    ctx.textBaseline = 'middle';
    ctx.fillText(selectedImg.emoji, rect.width / 2, rect.height / 2);

    // Draw attention regions
    const latestResult = vqaResults[0];
    latestResult.attentionRegions.forEach(region => {
      const gradient = ctx.createRadialGradient(
        region.x, region.y, 0,
        region.x, region.y, 30
      );
      gradient.addColorStop(0, `rgba(255, 0, 0, ${region.intensity * 0.6})`);
      gradient.addColorStop(1, 'rgba(255, 0, 0, 0)');
      ctx.fillStyle = gradient;
      ctx.fillRect(region.x - 30, region.y - 30, 60, 60);
    });
  }, [selectedImage, vqaResults, showAttention]);

  return (
    <div className="space-y-6">
      {/* Header */}
      <div className="bg-gradient-to-r from-violet-500 to-purple-600 rounded-xl p-6 text-white">
        <div className="flex items-center gap-3 mb-2">
          <Eye size={32} />
          <h2 className="text-2xl font-bold">Visual Question Answering ì‹œìŠ¤í…œ</h2>
        </div>
        <p className="text-violet-100">
          ì´ë¯¸ì§€ì— ëŒ€í•œ ìì—°ì–´ ì§ˆë¬¸ì— AIê°€ ë‹µë³€í•©ë‹ˆë‹¤
        </p>
      </div>

      {/* Image Gallery */}
      <div className="bg-white dark:bg-gray-800 rounded-lg p-6 shadow-lg">
        <h3 className="text-lg font-bold mb-4 flex items-center gap-2">
          <ImageIcon className="text-blue-600" />
          ì´ë¯¸ì§€ ê°¤ëŸ¬ë¦¬
        </h3>
        <div className="grid grid-cols-3 md:grid-cols-6 gap-3">
          {imageGallery.map(img => (
            <button
              key={img.id}
              onClick={() => {
                setSelectedImage(img.id);
                setVqaResults([]);
              }}
              className={`p-4 rounded-lg border-2 transition-all text-center ${
                selectedImage === img.id
                  ? 'border-purple-500 bg-purple-50 dark:bg-purple-900/30'
                  : 'border-gray-200 dark:border-gray-700 hover:border-purple-300'
              }`}
            >
              <div className="text-4xl mb-2">{img.emoji}</div>
              <div className="text-xs font-semibold">{img.label}</div>
            </button>
          ))}
        </div>
        <div className="mt-4 p-4 bg-gray-50 dark:bg-gray-900 rounded-lg">
          <p className="text-sm text-gray-600 dark:text-gray-400">
            <strong>ì„ íƒëœ ì´ë¯¸ì§€:</strong> {imageGallery.find(img => img.id === selectedImage)?.description}
          </p>
        </div>
      </div>

      {/* Question Input */}
      <div className="bg-white dark:bg-gray-800 rounded-lg p-6 shadow-lg">
        <h3 className="text-lg font-bold mb-4 flex items-center gap-2">
          <MessageSquare className="text-green-600" />
          ì§ˆë¬¸ ì…ë ¥
        </h3>
        <div className="flex gap-3">
          <input
            type="text"
            value={question}
            onChange={(e) => setQuestion(e.target.value)}
            onKeyPress={(e) => e.key === 'Enter' && handleSubmit()}
            placeholder="Ask a question about the image..."
            className="flex-1 px-4 py-3 bg-gray-50 dark:bg-gray-700 border border-gray-300 dark:border-gray-600 rounded-lg focus:ring-2 focus:ring-purple-500"
          />
          <button
            onClick={handleSubmit}
            disabled={isProcessing}
            className="flex items-center gap-2 px-6 py-3 bg-purple-500 hover:bg-purple-600 disabled:bg-gray-400 text-white rounded-lg font-semibold transition-colors"
          >
            <Send size={18} />
            {isProcessing ? 'ì²˜ë¦¬ì¤‘...' : 'ì§ˆë¬¸'}
          </button>
        </div>

        {/* Example Questions */}
        <div className="mt-4">
          <p className="text-sm font-semibold text-gray-600 dark:text-gray-400 mb-2">ì˜ˆì‹œ ì§ˆë¬¸:</p>
          <div className="flex flex-wrap gap-2">
            {imageGallery.find(img => img.id === selectedImage)?.exampleQuestions.map((q, idx) => (
              <button
                key={idx}
                onClick={() => setQuestion(q)}
                className="px-3 py-1 bg-purple-50 dark:bg-purple-900/30 text-purple-700 dark:text-purple-300 text-sm rounded-full hover:bg-purple-100 dark:hover:bg-purple-900/50 transition-colors"
              >
                {q}
              </button>
            ))}
          </div>
        </div>
      </div>

      {/* Attention Map */}
      {vqaResults.length > 0 && (
        <div className="bg-white dark:bg-gray-800 rounded-lg p-6 shadow-lg">
          <div className="flex items-center justify-between mb-4">
            <h3 className="text-lg font-bold flex items-center gap-2">
              <Brain className="text-purple-600" />
              ì–´í…ì…˜ ë§µ (Attention Map)
            </h3>
            <label className="flex items-center gap-2 cursor-pointer">
              <input
                type="checkbox"
                checked={showAttention}
                onChange={(e) => setShowAttention(e.target.checked)}
                className="w-4 h-4"
              />
              <span className="text-sm">í‘œì‹œ</span>
            </label>
          </div>
          <canvas
            ref={canvasRef}
            className="w-full bg-gray-900 rounded-lg border-2 border-purple-300"
            style={{ height: 300 }}
          />
          <p className="mt-3 text-sm text-gray-600 dark:text-gray-400">
            ğŸ”´ ë¹¨ê°„ ì˜ì—­ì€ AIê°€ ì§ˆë¬¸ì— ë‹µí•˜ê¸° ìœ„í•´ ì§‘ì¤‘í•œ ì´ë¯¸ì§€ ë¶€ë¶„ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.
          </p>
        </div>
      )}

      {/* VQA Results */}
      {vqaResults.length > 0 && (
        <div className="bg-white dark:bg-gray-800 rounded-lg p-6 shadow-lg">
          <h3 className="text-lg font-bold mb-4 flex items-center gap-2">
            <Sparkles className="text-purple-600" />
            ì§ˆë¬¸-ë‹µë³€ ê²°ê³¼
          </h3>
          <div className="space-y-4">
            {vqaResults.map((result, idx) => (
              <div
                key={idx}
                className={`p-4 rounded-lg border-2 ${
                  idx === 0
                    ? 'border-purple-500 bg-purple-50 dark:bg-purple-900/30'
                    : 'border-gray-200 dark:border-gray-700 bg-gray-50 dark:bg-gray-900'
                }`}
              >
                <div className="flex items-start gap-3 mb-3">
                  <MessageSquare className="text-blue-600 flex-shrink-0" size={20} />
                  <div className="flex-1">
                    <p className="font-semibold text-blue-600 mb-1">ì§ˆë¬¸:</p>
                    <p>{result.question}</p>
                  </div>
                </div>
                <div className="flex items-start gap-3 mb-3">
                  <Lightbulb className="text-green-600 flex-shrink-0" size={20} />
                  <div className="flex-1">
                    <p className="font-semibold text-green-600 mb-1">ë‹µë³€:</p>
                    <p>{result.answer}</p>
                  </div>
                </div>
                <div className="flex items-center justify-between mt-3 pt-3 border-t border-gray-200 dark:border-gray-700">
                  <div className="flex items-center gap-4 text-sm">
                    <span className="text-gray-500">
                      ì‹ ë¢°ë„: <strong className="text-purple-600">{(result.confidence * 100).toFixed(1)}%</strong>
                    </span>
                    <div className="h-2 w-32 bg-gray-200 dark:bg-gray-700 rounded-full overflow-hidden">
                      <div
                        className="h-full bg-gradient-to-r from-purple-500 to-pink-600"
                        style={{ width: `${result.confidence * 100}%` }}
                      />
                    </div>
                  </div>
                </div>
                <div className="mt-3 p-3 bg-white dark:bg-gray-800 rounded text-sm">
                  <p className="text-gray-500 mb-1"><strong>ì¶”ë¡  ê³¼ì •:</strong></p>
                  <p className="text-gray-600 dark:text-gray-400">{result.reasoning}</p>
                </div>
              </div>
            ))}
          </div>
        </div>
      )}

      {vqaResults.length === 0 && (
        <div className="bg-white dark:bg-gray-800 rounded-lg p-12 shadow-lg text-center">
          <Camera size={48} className="mx-auto text-gray-400 mb-3" />
          <p className="text-gray-500">ì´ë¯¸ì§€ë¥¼ ì„ íƒí•˜ê³  ì§ˆë¬¸ì„ ì…ë ¥í•˜ì—¬ ì‹œì‘í•˜ì„¸ìš”.</p>
        </div>
      )}

      {/* How VQA Works */}
      <div className="bg-white dark:bg-gray-800 rounded-lg p-6 shadow-lg">
        <h3 className="text-lg font-bold mb-4">ğŸ§  VQA ì‹œìŠ¤í…œ ì‘ë™ ì›ë¦¬</h3>
        <div className="grid md:grid-cols-2 gap-6">
          <div>
            <h4 className="font-semibold mb-2 text-purple-600">1. ì´ë¯¸ì§€ ì¸ì½”ë”©</h4>
            <p className="text-sm text-gray-600 dark:text-gray-400">
              CNN ë˜ëŠ” Vision Transformerë¡œ ì´ë¯¸ì§€ë¥¼ ê³ ì°¨ì› íŠ¹ì§• ë²¡í„°ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
            </p>
          </div>
          <div>
            <h4 className="font-semibold mb-2 text-purple-600">2. ì§ˆë¬¸ ì¸ì½”ë”©</h4>
            <p className="text-sm text-gray-600 dark:text-gray-400">
              BERT, GPT ë“±ì˜ ì–¸ì–´ ëª¨ë¸ë¡œ ì§ˆë¬¸ì„ ì„ë² ë”©í•©ë‹ˆë‹¤.
            </p>
          </div>
          <div>
            <h4 className="font-semibold mb-2 text-purple-600">3. ë©€í‹°ëª¨ë‹¬ ìœµí•©</h4>
            <p className="text-sm text-gray-600 dark:text-gray-400">
              Cross-Attentionìœ¼ë¡œ ì´ë¯¸ì§€ì™€ ì§ˆë¬¸ì„ ê²°í•©í•˜ì—¬ ê´€ë ¨ ì˜ì—­ì„ íŒŒì•…í•©ë‹ˆë‹¤.
            </p>
          </div>
          <div>
            <h4 className="font-semibold mb-2 text-purple-600">4. ë‹µë³€ ìƒì„±</h4>
            <p className="text-sm text-gray-600 dark:text-gray-400">
              ë¶„ë¥˜ê¸° ë˜ëŠ” ìƒì„± ëª¨ë¸ë¡œ ìì—°ì–´ ë‹µë³€ì„ ì¶œë ¥í•©ë‹ˆë‹¤.
            </p>
          </div>
        </div>
      </div>

      {/* Code Example */}
      <div className="bg-white dark:bg-gray-800 rounded-lg p-6 shadow-lg">
        <h3 className="text-lg font-bold mb-4">ğŸ’» Python êµ¬í˜„ ì˜ˆì œ</h3>
        <pre className="bg-gray-900 text-gray-100 p-4 rounded-lg text-sm overflow-x-auto">
{`from transformers import ViltProcessor, ViltForQuestionAnswering
from PIL import Image

# Load VQA model
processor = ViltProcessor.from_pretrained("dandelin/vilt-b32-finetuned-vqa")
model = ViltForQuestionAnswering.from_pretrained("dandelin/vilt-b32-finetuned-vqa")

# Prepare inputs
image = Image.open("${selectedImage}.jpg")
question = "${vqaResults.length > 0 ? vqaResults[0].question : 'What is in the image?'}"

# Process
inputs = processor(image, question, return_tensors="pt")
outputs = model(**inputs)

# Get answer
logits = outputs.logits
predicted_idx = logits.argmax(-1).item()
answer = model.config.id2label[predicted_idx]

print(f"Q: {question}")
print(f"A: {answer}")

# Visualize attention (requires additional processing)
attention_weights = outputs.attentions[-1]  # Last layer attention
# ... plot attention map`}
        </pre>
      </div>

      {/* Stats */}
      <div className="grid md:grid-cols-4 gap-4">
        <div className="bg-gradient-to-br from-blue-500 to-blue-600 rounded-lg p-4 text-white">
          <div className="text-3xl font-bold">{imageGallery.length}</div>
          <div className="text-sm text-blue-100">ì´ë¯¸ì§€ ê°¤ëŸ¬ë¦¬</div>
        </div>
        <div className="bg-gradient-to-br from-green-500 to-green-600 rounded-lg p-4 text-white">
          <div className="text-3xl font-bold">{vqaResults.length}</div>
          <div className="text-sm text-green-100">ì§ˆë¬¸-ë‹µë³€ ê¸°ë¡</div>
        </div>
        <div className="bg-gradient-to-br from-purple-500 to-purple-600 rounded-lg p-4 text-white">
          <div className="text-3xl font-bold">
            {vqaResults.length > 0 ? (vqaResults[0].confidence * 100).toFixed(0) : 0}%
          </div>
          <div className="text-sm text-purple-100">ìµœê·¼ ì‹ ë¢°ë„</div>
        </div>
        <div className="bg-gradient-to-br from-orange-500 to-orange-600 rounded-lg p-4 text-white">
          <div className="text-3xl font-bold">
            {vqaResults.reduce((sum, r) => sum + r.attentionRegions.length, 0)}
          </div>
          <div className="text-sm text-orange-100">ì–´í…ì…˜ í¬ì¸íŠ¸</div>
        </div>
      </div>
    </div>
  );
}

'use client'

import { useState, useEffect } from 'react'

interface TokenizerDemoProps {
  initialText?: string
}

export default function TokenizerDemo({ initialText = 'ì•ˆë…•í•˜ì„¸ìš”! LLMì„ ë°°ìš°ê³  ìˆìŠµë‹ˆë‹¤.' }: TokenizerDemoProps) {
  const [text, setText] = useState(initialText)
  const [tokenizer, setTokenizer] = useState('gpt')
  const [tokens, setTokens] = useState<string[]>([])
  const [tokenCount, setTokenCount] = useState(0)

  // ê°„ë‹¨í•œ í† í¬ë‚˜ì´ì € ì‹œë®¬ë ˆì´ì…˜ (ì‹¤ì œë¡œëŠ” ê° ëª¨ë¸ì˜ ì‹¤ì œ í† í¬ë‚˜ì´ì €ë¥¼ ì‚¬ìš©í•´ì•¼ í•¨)
  const tokenizeText = (text: string, tokenizerType: string) => {
    let tokenized: string[] = []
    
    switch (tokenizerType) {
      case 'gpt':
        // GPT ìŠ¤íƒ€ì¼: BPE (Byte Pair Encoding) ì‹œë®¬ë ˆì´ì…˜
        // í•œê¸€ì€ ë³´í†µ ê¸€ì ë‹¨ìœ„ë¡œ, ì˜ì–´ëŠ” ì„œë¸Œì›Œë“œ ë‹¨ìœ„ë¡œ
        tokenized = text.match(/[\u3131-\uD79D]|[a-zA-Z]+|[0-9]+|[^\s\wê°€-í£]/g) || []
        break
      
      case 'claude':
        // Claude ìŠ¤íƒ€ì¼: ì¡°ê¸ˆ ë” ì„¸ë°€í•œ ë¶„í• 
        tokenized = text.match(/[\u3131-\uD79D]|[a-zA-Z]+\'?[a-zA-Z]*|[0-9]+|[^\s\wê°€-í£]/g) || []
        break
      
      case 'bert':
        // BERT ìŠ¤íƒ€ì¼: WordPiece ì‹œë®¬ë ˆì´ì…˜
        tokenized = text.split(/\s+/).flatMap(word => {
          if (/^[ê°€-í£]+$/.test(word)) {
            // í•œê¸€ì€ ìŒì ˆ ë‹¨ìœ„ë¡œ
            return word.split('')
          } else if (/^[a-zA-Z]+$/.test(word)) {
            // ì˜ì–´ëŠ” ì„œë¸Œì›Œë“œë¡œ (ê°„ë‹¨íˆ ì‹œë®¬ë ˆì´ì…˜)
            if (word.length > 5) {
              return [word.slice(0, 3) + '##', '##' + word.slice(3)]
            }
            return [word]
          }
          return [word]
        }).filter(Boolean)
        break
      
      default:
        tokenized = text.split(/\s+/)
    }
    
    return tokenized
  }

  useEffect(() => {
    const newTokens = tokenizeText(text, tokenizer)
    setTokens(newTokens)
    setTokenCount(newTokens.length)
  }, [text, tokenizer])

  return (
    <div className="space-y-6">
      {/* Controls */}
      <div className="bg-white dark:bg-gray-800 rounded-lg p-4 shadow-sm border border-gray-200 dark:border-gray-700">
        <div className="flex gap-4 mb-4">
          <div className="flex-1">
            <label className="block text-sm font-medium text-gray-700 dark:text-gray-300 mb-2">
              í† í¬ë‚˜ì´ì € ì„ íƒ
            </label>
            <select 
              className="w-full px-3 py-2 rounded-lg border border-gray-300 dark:border-gray-600 bg-white dark:bg-gray-800 text-gray-900 dark:text-white focus:ring-2 focus:ring-indigo-500 focus:border-transparent"
              value={tokenizer}
              onChange={(e) => setTokenizer(e.target.value)}
            >
              <option value="gpt">GPT-3/4 Tokenizer</option>
              <option value="claude">Claude Tokenizer</option>
              <option value="bert">BERT Tokenizer</option>
            </select>
          </div>
          <div className="flex items-end">
            <div className="bg-indigo-50 dark:bg-indigo-900/20 px-4 py-2 rounded-lg">
              <div className="text-sm text-gray-600 dark:text-gray-400">í† í° ìˆ˜</div>
              <div className="text-xl font-bold text-indigo-600 dark:text-indigo-400">{tokenCount}</div>
            </div>
          </div>
        </div>
        <div>
          <label className="block text-sm font-medium text-gray-700 dark:text-gray-300 mb-2">
            ì…ë ¥ í…ìŠ¤íŠ¸
          </label>
          <textarea 
            className="w-full h-24 px-3 py-2 rounded-lg border border-gray-300 dark:border-gray-600 bg-white dark:bg-gray-800 text-gray-900 dark:text-white focus:ring-2 focus:ring-indigo-500 focus:border-transparent resize-none"
            placeholder="ì—¬ê¸°ì— í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”..."
            value={text}
            onChange={(e) => setText(e.target.value)}
          />
        </div>
      </div>

      {/* Token Visualization */}
      <div className="bg-white dark:bg-gray-800 rounded-lg p-4 shadow-sm border border-gray-200 dark:border-gray-700">
        <h4 className="font-semibold text-gray-900 dark:text-white mb-4">í† í°í™” ê²°ê³¼</h4>
        <div className="min-h-[80px] p-4 bg-gray-50 dark:bg-gray-900 rounded-lg border border-gray-200 dark:border-gray-600">
          <div className="flex flex-wrap gap-1">
            {tokens.map((token, index) => (
              <span 
                key={index} 
                className="inline-block px-2 py-1 text-xs bg-indigo-100 dark:bg-indigo-900/30 text-indigo-800 dark:text-indigo-200 rounded border border-indigo-200 dark:border-indigo-700"
              >
                {token}
              </span>
            ))}
          </div>
        </div>
      </div>
      
      {/* Information */}
      <div className="bg-blue-50 dark:bg-blue-900/20 rounded-lg p-4">
        <h4 className="font-semibold text-blue-800 dark:text-blue-200 mb-3 flex items-center gap-2">
          ğŸ’¡ í† í¬ë‚˜ì´ì €ë³„ íŠ¹ì§•
        </h4>
        <div className="space-y-2 text-sm text-blue-700 dark:text-blue-300">
          <div><strong>GPT:</strong> BPE(Byte Pair Encoding) ë°©ì‹, í•œê¸€ì€ ì£¼ë¡œ ê¸€ì ë‹¨ìœ„ë¡œ ë¶„í• </div>
          <div><strong>Claude:</strong> ê°œì„ ëœ BPE, ë¬¸ë§¥ì„ ê³ ë ¤í•œ ë” íš¨ìœ¨ì ì¸ í† í°í™”</div>
          <div><strong>BERT:</strong> WordPiece ë°©ì‹, ì„œë¸Œì›Œë“œ ë‹¨ìœ„ë¡œ ë¶„í•  (## í”„ë¦¬í”½ìŠ¤ ì‚¬ìš©)</div>
        </div>
      </div>
    </div>
  )
}
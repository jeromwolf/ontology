'use client'

import References from '@/components/common/References'

export default function Chapter8() {
  return (
    <div className="space-y-8">
      {/* Hero Section */}
      <div className="bg-gradient-to-r from-indigo-50 to-purple-50 dark:from-indigo-900/20 dark:to-purple-900/20 rounded-2xl p-8 border border-indigo-200 dark:border-indigo-800">
        <div className="flex items-start gap-4">
          <div className="text-5xl">ğŸš€</div>
          <div>
            <h1 className="text-3xl font-bold text-gray-900 dark:text-white mb-3">
              AI ì„œë¹„ìŠ¤ì™€ API í™œìš©
            </h1>
            <p className="text-lg text-gray-700 dark:text-gray-300">
              OpenAI, Claude, Gemini ë“± ì£¼ìš” AI ê¸°ì—… API ì‹¤ì „ ê°€ì´ë“œ - í”„ë¡œë•ì…˜ ë ˆë²¨ êµ¬í˜„
            </p>
          </div>
        </div>
      </div>

      {/* Learning Objectives */}
      <div className="bg-blue-50 dark:bg-blue-900/20 rounded-xl p-6 border border-blue-200 dark:border-blue-800">
        <h2 className="text-xl font-semibold text-blue-900 dark:text-blue-300 mb-4">
          ğŸ¯ í•™ìŠµ ëª©í‘œ
        </h2>
        <ul className="space-y-2 text-gray-700 dark:text-gray-300">
          <li className="flex items-start gap-2">
            <span className="text-blue-500 mt-1">âœ“</span>
            <span>OpenAI API (GPT-4o, DALL-E 3, Whisper)ë¡œ ë©€í‹°ëª¨ë‹¬ ì•± êµ¬ì¶•</span>
          </li>
          <li className="flex items-start gap-2">
            <span className="text-blue-500 mt-1">âœ“</span>
            <span>Anthropic Claude API ê³ ê¸‰ ê¸°ëŠ¥ (Computer Use, Analysis) ë§ˆìŠ¤í„°</span>
          </li>
          <li className="flex items-start gap-2">
            <span className="text-blue-500 mt-1">âœ“</span>
            <span>Google Gemini 2.5 Flashì˜ 100ë§Œ í† í° ì»¨í…ìŠ¤íŠ¸ í™œìš©</span>
          </li>
          <li className="flex items-start gap-2">
            <span className="text-blue-500 mt-1">âœ“</span>
            <span>AWS Bedrockìœ¼ë¡œ ë©€í‹°ëª¨ë¸ í†µí•© í”Œë«í¼ êµ¬ì¶•</span>
          </li>
          <li className="flex items-start gap-2">
            <span className="text-blue-500 mt-1">âœ“</span>
            <span>Azure OpenAI Service ì—”í„°í”„ë¼ì´ì¦ˆ ë°°í¬</span>
          </li>
          <li className="flex items-start gap-2">
            <span className="text-blue-500 mt-1">âœ“</span>
            <span>LangChainìœ¼ë¡œ API í†µí•© ë° ì—ì´ì „íŠ¸ êµ¬ì¶•</span>
          </li>
        </ul>
      </div>

      {/* Section 1: OpenAI API */}
      <section className="space-y-6">
        <h2 className="text-2xl font-bold text-gray-900 dark:text-white border-b-2 border-indigo-500 pb-2">
          1. OpenAI API - ì—…ê³„ í‘œì¤€
        </h2>

        <div className="bg-white dark:bg-gray-800 rounded-xl p-6 border border-gray-200 dark:border-gray-700">
          <h3 className="text-xl font-semibold text-gray-900 dark:text-white mb-4">
            1.1 GPT-4o - ìµœì‹  ë©€í‹°ëª¨ë‹¬ ëª¨ë¸
          </h3>

          <div className="bg-gray-900 rounded-lg p-4 mb-4">
            <pre className="text-sm text-gray-100 overflow-x-auto">
              <code>{`from openai import OpenAI
import os

client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))

# ê¸°ë³¸ ì±„íŒ… ì™„ì„±
response = client.chat.completions.create(
    model="gpt-4o",  # 2025ë…„ ìµœì‹  ëª¨ë¸
    messages=[
        {"role": "system", "content": "You are a helpful AI assistant specialized in Python programming."},
        {"role": "user", "content": "Write a Python function to calculate Fibonacci numbers efficiently."}
    ],
    temperature=0.7,
    max_tokens=1000,
    top_p=0.9,
    frequency_penalty=0.0,
    presence_penalty=0.0
)

print(response.choices[0].message.content)
print(f"Tokens used: {response.usage.total_tokens}")
print(f"Cost: \${response.usage.total_tokens * 0.000005:.4f}")  # GPT-4o ê°€ê²©

# ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ (ì‹¤ì‹œê°„ ì¶œë ¥)
stream = client.chat.completions.create(
    model="gpt-4o",
    messages=[{"role": "user", "content": "Explain quantum entanglement"}],
    stream=True
)

for chunk in stream:
    if chunk.choices[0].delta.content is not None:
        print(chunk.choices[0].delta.content, end="", flush=True)

# Function Calling (ë„êµ¬ ì‚¬ìš©)
tools = [
    {
        "type": "function",
        "function": {
            "name": "get_weather",
            "description": "Get current weather for a location",
            "parameters": {
                "type": "object",
                "properties": {
                    "location": {
                        "type": "string",
                        "description": "City name, e.g. Seoul"
                    },
                    "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]}
                },
                "required": ["location"]
            }
        }
    }
]

response = client.chat.completions.create(
    model="gpt-4o",
    messages=[{"role": "user", "content": "What's the weather in Seoul?"}],
    tools=tools,
    tool_choice="auto"
)

# í•¨ìˆ˜ í˜¸ì¶œ ì²˜ë¦¬
if response.choices[0].message.tool_calls:
    tool_call = response.choices[0].message.tool_calls[0]
    print(f"Function: {tool_call.function.name}")
    print(f"Arguments: {tool_call.function.arguments}")`}</code>
            </pre>
          </div>

          <div className="grid md:grid-cols-2 gap-4">
            <div className="bg-green-50 dark:bg-green-900/20 rounded-lg p-4">
              <h4 className="font-semibold text-green-900 dark:text-green-300 mb-2">
                GPT-4o ì¥ì 
              </h4>
              <ul className="text-sm text-gray-700 dark:text-gray-300 space-y-1">
                <li>â€¢ í…ìŠ¤íŠ¸ + ì´ë¯¸ì§€ + ì˜¤ë””ì˜¤ í†µí•© ì²˜ë¦¬</li>
                <li>â€¢ 128K í† í° ì»¨í…ìŠ¤íŠ¸ (GPT-4 Turbo)</li>
                <li>â€¢ GPT-4 ëŒ€ë¹„ 50% ì €ë ´ ($5/1M tokens)</li>
                <li>â€¢ 2ë°° ë¹ ë¥¸ ì‘ë‹µ ì†ë„</li>
                <li>â€¢ JSON ëª¨ë“œ, Structured Output ì§€ì›</li>
              </ul>
            </div>
            <div className="bg-orange-50 dark:bg-orange-900/20 rounded-lg p-4">
              <h4 className="font-semibold text-orange-900 dark:text-orange-300 mb-2">
                ëª¨ë¸ ì„ íƒ ê°€ì´ë“œ
              </h4>
              <ul className="text-sm text-gray-700 dark:text-gray-300 space-y-1">
                <li>â€¢ <strong>gpt-4o</strong>: ë©€í‹°ëª¨ë‹¬, ê³ í’ˆì§ˆ + ì†ë„</li>
                <li>â€¢ <strong>gpt-4-turbo</strong>: ê¸´ ì»¨í…ìŠ¤íŠ¸</li>
                <li>â€¢ <strong>gpt-3.5-turbo</strong>: ì €ë¹„ìš©, ë¹ ë¥¸ ì‘ë‹µ</li>
                <li>â€¢ <strong>gpt-4o-mini</strong>: ì´ˆì €ë¹„ìš© ($0.15/1M)</li>
              </ul>
            </div>
          </div>
        </div>

        <div className="bg-white dark:bg-gray-800 rounded-xl p-6 border border-gray-200 dark:border-gray-700">
          <h3 className="text-xl font-semibold text-gray-900 dark:text-white mb-4">
            1.2 DALL-E 3 - ìµœê³  í’ˆì§ˆ ì´ë¯¸ì§€ ìƒì„±
          </h3>

          <div className="bg-gray-900 rounded-lg p-4 mb-4">
            <pre className="text-sm text-gray-100 overflow-x-auto">
              <code>{`# ì´ë¯¸ì§€ ìƒì„±
response = client.images.generate(
    model="dall-e-3",
    prompt="A serene Japanese garden with cherry blossoms, koi pond, and a traditional tea house, rendered in ukiyo-e art style",
    size="1792x1024",  # HD: 1024x1024, 1792x1024, 1024x1792
    quality="hd",      # "standard" or "hd"
    style="vivid",     # "vivid" or "natural"
    n=1
)

image_url = response.data[0].url
revised_prompt = response.data[0].revised_prompt  # GPT-4ë¡œ ìë™ ê°œì„ ëœ í”„ë¡¬í”„íŠ¸
print(f"Generated: {image_url}")
print(f"Revised: {revised_prompt}")

# ì´ë¯¸ì§€ í¸ì§‘ (DALL-E 2)
response = client.images.edit(
    image=open("original.png", "rb"),
    mask=open("mask.png", "rb"),  # í¸ì§‘í•  ì˜ì—­ (í°ìƒ‰)
    prompt="Replace the background with a futuristic cityscape",
    size="1024x1024",
    n=1
)

# ì´ë¯¸ì§€ ë³€í˜• ìƒì„±
response = client.images.create_variation(
    image=open("original.png", "rb"),
    n=3,  # 3ê°œì˜ ë³€í˜• ìƒì„±
    size="1024x1024"
)`}</code>
            </pre>
          </div>
        </div>

        <div className="bg-white dark:bg-gray-800 rounded-xl p-6 border border-gray-200 dark:border-gray-700">
          <h3 className="text-xl font-semibold text-gray-900 dark:text-white mb-4">
            1.3 Whisper - ìŒì„± ì¸ì‹ ë° ë²ˆì—­
          </h3>

          <div className="bg-gray-900 rounded-lg p-4 mb-4">
            <pre className="text-sm text-gray-100 overflow-x-auto">
              <code>{`# ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ (STT)
audio_file = open("speech.mp3", "rb")
transcript = client.audio.transcriptions.create(
    model="whisper-1",
    file=audio_file,
    language="ko",  # ì–¸ì–´ íŒíŠ¸ (ì„ íƒ)
    response_format="verbose_json",  # text, json, verbose_json, srt, vtt
    timestamp_granularities=["word", "segment"]
)

print(transcript.text)
for word in transcript.words:
    print(f"{word.word} ({word.start:.2f}s - {word.end:.2f}s)")

# ìŒì„± ë²ˆì—­ (ë‹¤êµ­ì–´ â†’ ì˜ì–´)
translation = client.audio.translations.create(
    model="whisper-1",
    file=open("korean_speech.mp3", "rb")
)
print(translation.text)  # ì˜ì–´ë¡œ ìë™ ë²ˆì—­

# í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ (TTS)
speech_file = Path(__file__).parent / "speech.mp3"
response = client.audio.speech.create(
    model="tts-1-hd",  # tts-1 (ë¹ ë¦„) or tts-1-hd (ê³ í’ˆì§ˆ)
    voice="alloy",     # alloy, echo, fable, onyx, nova, shimmer
    input="ì•ˆë…•í•˜ì„¸ìš”. OpenAIì˜ ìŒì„± í•©ì„± ê¸°ìˆ ì…ë‹ˆë‹¤.",
    speed=1.0
)

response.stream_to_file(speech_file)`}</code>
            </pre>
          </div>
        </div>
      </section>

      {/* Section 2: Anthropic Claude */}
      <section className="space-y-6">
        <h2 className="text-2xl font-bold text-gray-900 dark:text-white border-b-2 border-indigo-500 pb-2">
          2. Anthropic Claude - ì•ˆì „ì„±ê³¼ ê¸´ ì»¨í…ìŠ¤íŠ¸
        </h2>

        <div className="bg-white dark:bg-gray-800 rounded-xl p-6 border border-gray-200 dark:border-gray-700">
          <h3 className="text-xl font-semibold text-gray-900 dark:text-white mb-4">
            2.1 Claude 3.5 Sonnet & Opus 4 í™œìš©
          </h3>

          <div className="bg-gray-900 rounded-lg p-4 mb-4">
            <pre className="text-sm text-gray-100 overflow-x-auto">
              <code>{`import anthropic

client = anthropic.Anthropic(api_key=os.environ.get("ANTHROPIC_API_KEY"))

# ê¸°ë³¸ ë©”ì‹œì§€ ìƒì„±
message = client.messages.create(
    model="claude-opus-4-20250514",  # 2025ë…„ ìµœì‹  ëª¨ë¸
    max_tokens=4096,
    temperature=1.0,
    system="You are a world-class poet. Respond only with short poems.",
    messages=[
        {"role": "user", "content": "Write a haiku about recursion in programming."}
    ]
)

print(message.content[0].text)

# ìŠ¤íŠ¸ë¦¬ë°
with client.messages.stream(
    model="claude-3-5-sonnet-20250220",
    max_tokens=1024,
    messages=[{"role": "user", "content": "Explain black holes"}]
) as stream:
    for text in stream.text_stream:
        print(text, end="", flush=True)

# Vision (ì´ë¯¸ì§€ ë¶„ì„)
import base64

with open("diagram.png", "rb") as f:
    image_data = base64.standard_b64encode(f.read()).decode("utf-8")

message = client.messages.create(
    model="claude-3-5-sonnet-20250220",
    max_tokens=1024,
    messages=[
        {
            "role": "user",
            "content": [
                {
                    "type": "image",
                    "source": {
                        "type": "base64",
                        "media_type": "image/png",
                        "data": image_data,
                    },
                },
                {
                    "type": "text",
                    "text": "Describe this diagram in detail and explain the workflow."
                }
            ],
        }
    ]
)

print(message.content[0].text)`}</code>
            </pre>
          </div>

          <div className="bg-purple-50 dark:bg-purple-900/20 rounded-lg p-4 border-l-4 border-purple-500">
            <p className="text-sm text-gray-700 dark:text-gray-300">
              <strong>ğŸ¯ Claudeì˜ ê°•ì :</strong> Claude Opus 4ëŠ” 200K í† í° ì»¨í…ìŠ¤íŠ¸ë¥¼ ì§€ì›í•˜ë©°,
              ë³µì¡í•œ ì¶”ë¡ , ì½”ë“œ ìƒì„±, ìˆ˜í•™ ë¬¸ì œì—ì„œ GPT-4oë¥¼ ëŠ¥ê°€í•©ë‹ˆë‹¤. íŠ¹íˆ ì•ˆì „ì„±ê³¼ ì •í™•ì„±ì´ ì¤‘ìš”í•œ ì—”í„°í”„ë¼ì´ì¦ˆ í™˜ê²½ì— ìµœì ì…ë‹ˆë‹¤.
            </p>
          </div>
        </div>

        <div className="bg-white dark:bg-gray-800 rounded-xl p-6 border border-gray-200 dark:border-gray-700">
          <h3 className="text-xl font-semibold text-gray-900 dark:text-white mb-4">
            2.2 Tool Use (Function Calling)
          </h3>

          <div className="bg-gray-900 rounded-lg p-4 mb-4">
            <pre className="text-sm text-gray-100 overflow-x-auto">
              <code>{`tools = [
    {
        "name": "get_stock_price",
        "description": "Get the current stock price for a given ticker symbol",
        "input_schema": {
            "type": "object",
            "properties": {
                "ticker": {
                    "type": "string",
                    "description": "The stock ticker symbol, e.g. AAPL for Apple"
                }
            },
            "required": ["ticker"]
        }
    }
]

message = client.messages.create(
    model="claude-3-5-sonnet-20250220",
    max_tokens=1024,
    tools=tools,
    messages=[{"role": "user", "content": "What's the current price of Apple stock?"}]
)

# Tool ì‚¬ìš© ì²˜ë¦¬
if message.stop_reason == "tool_use":
    tool_use = next(block for block in message.content if block.type == "tool_use")
    print(f"Claude wants to call: {tool_use.name}")
    print(f"With arguments: {tool_use.input}")

    # ì‹¤ì œ í•¨ìˆ˜ ì‹¤í–‰ (ì˜ˆì‹œ)
    result = get_stock_price(tool_use.input["ticker"])

    # ê²°ê³¼ë¥¼ Claudeì—ê²Œ ë‹¤ì‹œ ì „ë‹¬
    response = client.messages.create(
        model="claude-3-5-sonnet-20250220",
        max_tokens=1024,
        tools=tools,
        messages=[
            {"role": "user", "content": "What's the current price of Apple stock?"},
            {"role": "assistant", "content": message.content},
            {
                "role": "user",
                "content": [
                    {
                        "type": "tool_result",
                        "tool_use_id": tool_use.id,
                        "content": str(result)
                    }
                ]
            }
        ]
    )
    print(response.content[0].text)`}</code>
            </pre>
          </div>
        </div>
      </section>

      {/* Section 3: Google Gemini */}
      <section className="space-y-6">
        <h2 className="text-2xl font-bold text-gray-900 dark:text-white border-b-2 border-indigo-500 pb-2">
          3. Google Gemini - 100ë§Œ í† í° ì»¨í…ìŠ¤íŠ¸
        </h2>

        <div className="bg-white dark:bg-gray-800 rounded-xl p-6 border border-gray-200 dark:border-gray-700">
          <h3 className="text-xl font-semibold text-gray-900 dark:text-white mb-4">
            3.1 Gemini 2.5 Flash í™œìš©
          </h3>

          <div className="bg-gray-900 rounded-lg p-4 mb-4">
            <pre className="text-sm text-gray-100 overflow-x-auto">
              <code>{`import google.generativeai as genai

genai.configure(api_key=os.environ.get("GOOGLE_API_KEY"))

# ëª¨ë¸ ì´ˆê¸°í™”
model = genai.GenerativeModel("gemini-2.5-flash")

# í…ìŠ¤íŠ¸ ìƒì„±
response = model.generate_content("Explain quantum computing in simple terms")
print(response.text)

# ë©€í‹°ëª¨ë‹¬: ì´ë¯¸ì§€ + í…ìŠ¤íŠ¸
import PIL.Image

img = PIL.Image.open("chart.png")
response = model.generate_content(["Analyze this chart and provide insights", img])
print(response.text)

# ëŒ€í™”í˜• ì±„íŒ…
chat = model.start_chat(history=[])

response = chat.send_message("Hello! Can you help me with Python?")
print(response.text)

response = chat.send_message("Write a function to sort a list")
print(response.text)

# ê¸´ ì»¨í…ìŠ¤íŠ¸ ì²˜ë¦¬ (1M í† í°!)
with open("entire_codebase.txt", "r") as f:
    large_text = f.read()  # ìˆ˜ë°±ë§Œ ìì˜ ì½”ë“œ

response = model.generate_content([
    "Analyze this entire codebase and suggest architectural improvements",
    large_text
])
print(response.text)`}</code>
            </pre>
          </div>

          <div className="bg-green-50 dark:bg-green-900/20 rounded-lg p-4 border-l-4 border-green-500">
            <p className="text-sm text-gray-700 dark:text-gray-300">
              <strong>ğŸš€ Gemini 2.5 Flashì˜ í˜ì‹ :</strong> 100ë§Œ í† í° ì»¨í…ìŠ¤íŠ¸ëŠ” ì±… ì—¬ëŸ¬ ê¶Œ, ì „ì²´ ì½”ë“œë² ì´ìŠ¤,
              ê¸´ ë™ì˜ìƒì„ í•œ ë²ˆì— ì²˜ë¦¬ ê°€ëŠ¥í•©ë‹ˆë‹¤. ë¹„ìš©ë„ ë§¤ìš° ì €ë ´ ($0.075/1M tokens)í•˜ì—¬ ëŒ€ê·œëª¨ ë¬¸ì„œ ë¶„ì„ì— ìµœì ì…ë‹ˆë‹¤.
            </p>
          </div>
        </div>

        <div className="bg-white dark:bg-gray-800 rounded-xl p-6 border border-gray-200 dark:border-gray-700">
          <h3 className="text-xl font-semibold text-gray-900 dark:text-white mb-4">
            3.2 Function Calling & JSON Mode
          </h3>

          <div className="bg-gray-900 rounded-lg p-4 mb-4">
            <pre className="text-sm text-gray-100 overflow-x-auto">
              <code>{`# Function Calling
def get_weather(location: str, unit: str = "celsius"):
    """Get weather for a location"""
    return {"temperature": 22, "condition": "sunny"}

tools = [get_weather]

model = genai.GenerativeModel("gemini-2.5-flash", tools=tools)
chat = model.start_chat()

response = chat.send_message("What's the weather in Seoul?")

# Function call ìë™ ì‹¤í–‰
function_call = response.candidates[0].content.parts[0].function_call
result = get_weather(**dict(function_call.args))

response = chat.send_message(
    genai.types.Part.from_function_response(
        name="get_weather",
        response={"content": result}
    )
)
print(response.text)

# JSON ëª¨ë“œ - êµ¬ì¡°í™”ëœ ì¶œë ¥
model = genai.GenerativeModel(
    "gemini-2.5-flash",
    generation_config={
        "response_mime_type": "application/json",
        "response_schema": {
            "type": "object",
            "properties": {
                "name": {"type": "string"},
                "age": {"type": "integer"},
                "skills": {
                    "type": "array",
                    "items": {"type": "string"}
                }
            }
        }
    }
)

response = model.generate_content(
    "Create a profile for a senior Python developer"
)
import json
profile = json.loads(response.text)
print(profile)`}</code>
            </pre>
          </div>
        </div>
      </section>

      {/* Section 4: AWS Bedrock */}
      <section className="space-y-6">
        <h2 className="text-2xl font-bold text-gray-900 dark:text-white border-b-2 border-indigo-500 pb-2">
          4. AWS Bedrock - ë©€í‹°ëª¨ë¸ í”Œë«í¼
        </h2>

        <div className="bg-white dark:bg-gray-800 rounded-xl p-6 border border-gray-200 dark:border-gray-700">
          <h3 className="text-xl font-semibold text-gray-900 dark:text-white mb-4">
            4.1 ë‹¤ì–‘í•œ ëª¨ë¸ í†µí•© ì ‘ê·¼
          </h3>

          <div className="bg-gray-900 rounded-lg p-4 mb-4">
            <pre className="text-sm text-gray-100 overflow-x-auto">
              <code>{`import boto3
import json

bedrock = boto3.client(
    service_name='bedrock-runtime',
    region_name='us-east-1'
)

# Claude on Bedrock
body = json.dumps({
    "anthropic_version": "bedrock-2023-05-31",
    "max_tokens": 1024,
    "messages": [
        {
            "role": "user",
            "content": "Explain AWS Lambda"
        }
    ]
})

response = bedrock.invoke_model(
    modelId="anthropic.claude-3-5-sonnet-20250220-v1:0",
    body=body
)

result = json.loads(response['body'].read())
print(result['content'][0]['text'])

# Meta Llama 3.3 on Bedrock
body = json.dumps({
    "prompt": "Explain machine learning",
    "max_gen_len": 512,
    "temperature": 0.7,
    "top_p": 0.9
})

response = bedrock.invoke_model(
    modelId="meta.llama3-3-70b-instruct-v1:0",
    body=body
)

# Titan Embeddings (ì„ë² ë”©)
body = json.dumps({
    "inputText": "This is a sentence to embed"
})

response = bedrock.invoke_model(
    modelId="amazon.titan-embed-text-v2:0",
    body=body
)

embedding = json.loads(response['body'].read())['embedding']
print(f"Embedding dimension: {len(embedding)}")`}</code>
            </pre>
          </div>

          <div className="grid md:grid-cols-2 gap-4">
            <div className="bg-blue-50 dark:bg-blue-900/20 rounded-lg p-4">
              <h4 className="font-semibold text-blue-900 dark:text-blue-300 mb-2">
                Bedrock ì§€ì› ëª¨ë¸
              </h4>
              <ul className="text-sm text-gray-700 dark:text-gray-300 space-y-1">
                <li>â€¢ Claude (Anthropic)</li>
                <li>â€¢ Llama 3.3 (Meta)</li>
                <li>â€¢ Titan (Amazon)</li>
                <li>â€¢ Mistral & Mixtral</li>
                <li>â€¢ Stable Diffusion (ì´ë¯¸ì§€)</li>
                <li>â€¢ Cohere Command</li>
              </ul>
            </div>
            <div className="bg-yellow-50 dark:bg-yellow-900/20 rounded-lg p-4">
              <h4 className="font-semibold text-yellow-900 dark:text-yellow-300 mb-2">
                ì—”í„°í”„ë¼ì´ì¦ˆ ì¥ì 
              </h4>
              <ul className="text-sm text-gray-700 dark:text-gray-300 space-y-1">
                <li>â€¢ AWS ì¸í”„ë¼ ë‚´ í”„ë¼ì´ë¹— ë°°í¬</li>
                <li>â€¢ VPC ê²©ë¦¬, IAM í†µí•©</li>
                <li>â€¢ CloudWatch ëª¨ë‹ˆí„°ë§</li>
                <li>â€¢ ê·œì • ì¤€ìˆ˜ (HIPAA, SOC)</li>
                <li>â€¢ ë°ì´í„° ì£¼ê¶Œ ë³´ì¥</li>
              </ul>
            </div>
          </div>
        </div>
      </section>

      {/* Section 5: LangChain Integration */}
      <section className="space-y-6">
        <h2 className="text-2xl font-bold text-gray-900 dark:text-white border-b-2 border-indigo-500 pb-2">
          5. LangChain - API í†µí•© í”„ë ˆì„ì›Œí¬
        </h2>

        <div className="bg-white dark:bg-gray-800 rounded-xl p-6 border border-gray-200 dark:border-gray-700">
          <h3 className="text-xl font-semibold text-gray-900 dark:text-white mb-4">
            5.1 ë©€í‹° í”„ë¡œë°”ì´ë” í†µí•©
          </h3>

          <div className="bg-gray-900 rounded-lg p-4 mb-4">
            <pre className="text-sm text-gray-100 overflow-x-auto">
              <code>{`from langchain_openai import ChatOpenAI
from langchain_anthropic import ChatAnthropic
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.prompts import ChatPromptTemplate
from langchain.schema.output_parser import StrOutputParser

# ì—¬ëŸ¬ LLM ì •ì˜
openai_llm = ChatOpenAI(model="gpt-4o", temperature=0.7)
claude_llm = ChatAnthropic(model="claude-opus-4-20250514", temperature=0.7)
gemini_llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash", temperature=0.7)

# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
prompt = ChatPromptTemplate.from_messages([
    ("system", "You are a helpful AI assistant."),
    ("human", "{input}")
])

# Chain êµ¬ì„±
chain = prompt | openai_llm | StrOutputParser()

# ì‹¤í–‰
response = chain.invoke({"input": "What is LangChain?"})
print(response)

# ëª¨ë¸ ë¹„êµ (ë™ì‹œ ì‹¤í–‰)
from langchain.schema.runnable import RunnableParallel

comparison = RunnableParallel(
    openai=prompt | openai_llm,
    claude=prompt | claude_llm,
    gemini=prompt | gemini_llm
)

results = comparison.invoke({"input": "Explain quantum computing"})
for model, response in results.items():
    print(f"\n{model.upper()}:")
    print(response.content)`}</code>
            </pre>
          </div>
        </div>

        <div className="bg-white dark:bg-gray-800 rounded-xl p-6 border border-gray-200 dark:border-gray-700">
          <h3 className="text-xl font-semibold text-gray-900 dark:text-white mb-4">
            5.2 ì—ì´ì „íŠ¸ êµ¬ì¶•
          </h3>

          <div className="bg-gray-900 rounded-lg p-4 mb-4">
            <pre className="text-sm text-gray-100 overflow-x-auto">
              <code>{`from langchain.agents import AgentExecutor, create_openai_tools_agent
from langchain.tools import Tool
from langchain import hub

# ë„êµ¬ ì •ì˜
def search_web(query: str) -> str:
    """Search the web for information"""
    # ì‹¤ì œë¡œëŠ” Tavily, Serper ë“± ì‚¬ìš©
    return f"Search results for: {query}"

def calculator(expression: str) -> float:
    """Calculate mathematical expressions"""
    return eval(expression)

tools = [
    Tool(
        name="WebSearch",
        func=search_web,
        description="Search the web for current information"
    ),
    Tool(
        name="Calculator",
        func=calculator,
        description="Perform mathematical calculations"
    )
]

# í”„ë¡¬í”„íŠ¸ ë¡œë“œ
prompt = hub.pull("hwchase17/openai-tools-agent")

# ì—ì´ì „íŠ¸ ìƒì„±
agent = create_openai_tools_agent(
    llm=ChatOpenAI(model="gpt-4o", temperature=0),
    tools=tools,
    prompt=prompt
)

agent_executor = AgentExecutor(
    agent=agent,
    tools=tools,
    verbose=True,
    handle_parsing_errors=True
)

# ë³µì¡í•œ ì‘ì—… ì‹¤í–‰
result = agent_executor.invoke({
    "input": "What's 1284 * 567? Then search for information about that number."
})
print(result["output"])`}</code>
            </pre>
          </div>
        </div>
      </section>

      {/* API Comparison Table */}
      <div className="bg-white dark:bg-gray-800 rounded-xl p-6 border border-gray-200 dark:border-gray-700">
        <h2 className="text-xl font-semibold text-gray-900 dark:text-white mb-4">
          ğŸ“Š ì£¼ìš” API ë¹„êµ (2025ë…„ ê¸°ì¤€)
        </h2>
        <div className="overflow-x-auto">
          <table className="w-full text-sm">
            <thead className="bg-gray-50 dark:bg-gray-700">
              <tr>
                <th className="px-4 py-3 text-left">Provider</th>
                <th className="px-4 py-3 text-left">Top Model</th>
                <th className="px-4 py-3 text-left">Context</th>
                <th className="px-4 py-3 text-left">Price (Input)</th>
                <th className="px-4 py-3 text-left">íŠ¹ì§•</th>
              </tr>
            </thead>
            <tbody className="divide-y divide-gray-200 dark:divide-gray-600">
              <tr>
                <td className="px-4 py-3 font-semibold">OpenAI</td>
                <td className="px-4 py-3">GPT-4o</td>
                <td className="px-4 py-3">128K</td>
                <td className="px-4 py-3">$5/1M</td>
                <td className="px-4 py-3">ë©€í‹°ëª¨ë‹¬, Function Calling</td>
              </tr>
              <tr>
                <td className="px-4 py-3 font-semibold">Anthropic</td>
                <td className="px-4 py-3">Claude Opus 4</td>
                <td className="px-4 py-3">200K</td>
                <td className="px-4 py-3">$15/1M</td>
                <td className="px-4 py-3">ì¶”ë¡ , ì½”ë“œ, ì•ˆì „ì„±</td>
              </tr>
              <tr>
                <td className="px-4 py-3 font-semibold">Google</td>
                <td className="px-4 py-3">Gemini 2.5 Flash</td>
                <td className="px-4 py-3">1M</td>
                <td className="px-4 py-3">$0.075/1M</td>
                <td className="px-4 py-3">ì´ˆì¥ ì»¨í…ìŠ¤íŠ¸, ì €ë¹„ìš©</td>
              </tr>
              <tr>
                <td className="px-4 py-3 font-semibold">xAI</td>
                <td className="px-4 py-3">Grok 4</td>
                <td className="px-4 py-3">128K</td>
                <td className="px-4 py-3">$5/1M</td>
                <td className="px-4 py-3">ì‹¤ì‹œê°„ X ë°ì´í„° ì ‘ê·¼</td>
              </tr>
              <tr>
                <td className="px-4 py-3 font-semibold">Meta</td>
                <td className="px-4 py-3">Llama 3.3 70B</td>
                <td className="px-4 py-3">128K</td>
                <td className="px-4 py-3">ë¬´ë£Œ (ì˜¤í”ˆì†ŒìŠ¤)</td>
                <td className="px-4 py-3">ì™„ì „ ìì²´ í˜¸ìŠ¤íŒ… ê°€ëŠ¥</td>
              </tr>
            </tbody>
          </table>
        </div>
      </div>

      {/* Best Practices */}
      <div className="bg-gradient-to-r from-purple-50 to-pink-50 dark:from-purple-900/20 dark:to-pink-900/20 rounded-xl p-6 border border-purple-200 dark:border-purple-800">
        <h2 className="text-xl font-semibold text-purple-900 dark:text-purple-300 mb-4">
          ğŸ’ í”„ë¡œë•ì…˜ ë°°í¬ Best Practices
        </h2>
        <div className="grid md:grid-cols-3 gap-6">
          <div className="space-y-3">
            <h4 className="font-semibold text-gray-900 dark:text-white">ğŸ”’ ë³´ì•ˆ</h4>
            <ul className="space-y-2 text-sm text-gray-700 dark:text-gray-300">
              <li>â€¢ API í‚¤ í™˜ê²½ë³€ìˆ˜ ì €ì¥</li>
              <li>â€¢ í”„ë¡¬í”„íŠ¸ ì¸ì ì…˜ ë°©ì–´</li>
              <li>â€¢ Rate limiting êµ¬í˜„</li>
              <li>â€¢ ë¯¼ê° ë°ì´í„° í•„í„°ë§</li>
            </ul>
          </div>
          <div className="space-y-3">
            <h4 className="font-semibold text-gray-900 dark:text-white">âš¡ ì„±ëŠ¥</h4>
            <ul className="space-y-2 text-sm text-gray-700 dark:text-gray-300">
              <li>â€¢ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ í™œìš©</li>
              <li>â€¢ ìºì‹± ì „ëµ êµ¬í˜„</li>
              <li>â€¢ ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™”</li>
              <li>â€¢ íƒ€ì„ì•„ì›ƒ ì„¤ì •</li>
            </ul>
          </div>
          <div className="space-y-3">
            <h4 className="font-semibold text-gray-900 dark:text-white">ğŸ’° ë¹„ìš©</h4>
            <ul className="space-y-2 text-sm text-gray-700 dark:text-gray-300">
              <li>â€¢ í† í° ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§</li>
              <li>â€¢ ì ì ˆí•œ ëª¨ë¸ ì„ íƒ</li>
              <li>â€¢ í”„ë¡¬í”„íŠ¸ ìµœì í™”</li>
              <li>â€¢ ì‚¬ìš©ëŸ‰ ì•Œë¦¼ ì„¤ì •</li>
            </ul>
          </div>
        </div>
      </div>

      {/* Summary */}
      <div className="bg-gradient-to-r from-indigo-50 to-purple-50 dark:from-indigo-900/20 dark:to-purple-900/20 rounded-xl p-6 border border-indigo-200 dark:border-indigo-800">
        <h2 className="text-xl font-semibold text-indigo-900 dark:text-indigo-300 mb-3">
          âœ¨ í•µì‹¬ ìš”ì•½
        </h2>
        <ul className="space-y-2 text-gray-700 dark:text-gray-300">
          <li>â€¢ <strong>OpenAI:</strong> ê°€ì¥ ì„±ìˆ™í•œ ìƒíƒœê³„, GPT-4oì˜ ë©€í‹°ëª¨ë‹¬, DALL-E 3 ì´ë¯¸ì§€, Whisper ìŒì„±</li>
          <li>â€¢ <strong>Anthropic:</strong> Claude Opus 4ì˜ ìµœê³  ìˆ˜ì¤€ ì¶”ë¡ , 200K ì»¨í…ìŠ¤íŠ¸, Computer Use ê¸°ëŠ¥</li>
          <li>â€¢ <strong>Google:</strong> Gemini 2.5 Flashì˜ 100ë§Œ í† í° + ì´ˆì €ë¹„ìš©, ê¸´ ë¬¸ì„œ ë¶„ì„ ìµœì </li>
          <li>â€¢ <strong>AWS Bedrock:</strong> ì—”í„°í”„ë¼ì´ì¦ˆ ìš”êµ¬ì‚¬í•­, í”„ë¼ì´ë¹— VPC, ë©€í‹°ëª¨ë¸ ì„ íƒ</li>
          <li>â€¢ <strong>LangChain:</strong> í†µí•© í”„ë ˆì„ì›Œí¬ë¡œ í”„ë¡œë°”ì´ë” ì „í™˜ ìš©ì´, ë³µì¡í•œ ì—ì´ì „íŠ¸ êµ¬ì¶•</li>
        </ul>
      </div>

      {/* References */}
      <References
        sections={[
          {
            title: 'ğŸ“š ê³µì‹ API ë¬¸ì„œ',
            icon: 'web' as const,
            color: 'border-purple-500',
            items: [
              {
                title: 'OpenAI API Reference',
                authors: 'OpenAI',
                year: '2025',
                description: 'GPT-4o, DALL-E 3, Whisper API ì™„ì „ ê°€ì´ë“œ',
                link: 'https://platform.openai.com/docs'
              },
              {
                title: 'Anthropic Claude API',
                authors: 'Anthropic',
                year: '2025',
                description: 'Claude Opus 4 API ë¬¸ì„œ ë° Tool Use',
                link: 'https://docs.anthropic.com'
              },
              {
                title: 'Google AI for Developers',
                authors: 'Google',
                year: '2025',
                description: 'Gemini 2.5 Flash API ë° Function Calling',
                link: 'https://ai.google.dev'
              },
              {
                title: 'AWS Bedrock Documentation',
                authors: 'Amazon Web Services',
                year: '2025',
                description: 'ì—”í„°í”„ë¼ì´ì¦ˆ AI ë©€í‹°ëª¨ë¸ í”Œë«í¼',
                link: 'https://docs.aws.amazon.com/bedrock'
              },
              {
                title: 'Azure OpenAI Service',
                authors: 'Microsoft',
                year: '2025',
                description: 'ì—”í„°í”„ë¼ì´ì¦ˆê¸‰ OpenAI ë°°í¬',
                link: 'https://learn.microsoft.com/azure/ai-services/openai'
              }
            ]
          },
          {
            title: 'ğŸ› ï¸ í†µí•© í”„ë ˆì„ì›Œí¬',
            icon: 'paper' as const,
            color: 'border-indigo-500',
            items: [
              {
                title: 'LangChain Documentation',
                authors: 'LangChain',
                year: '2025',
                description: 'AI ì• í”Œë¦¬ì¼€ì´ì…˜ í†µí•© ê°œë°œ í”„ë ˆì„ì›Œí¬',
                link: 'https://python.langchain.com/docs'
              },
              {
                title: 'LlamaIndex',
                authors: 'LlamaIndex',
                year: '2025',
                description: 'RAG ë° ë°ì´í„° í”„ë ˆì„ì›Œí¬',
                link: 'https://docs.llamaindex.ai'
              },
              {
                title: 'AutoGen Framework',
                authors: 'Microsoft',
                year: '2024',
                description: 'Multi-agent ì‹œìŠ¤í…œ êµ¬ì¶•',
                link: 'https://microsoft.github.io/autogen'
              }
            ]
          },
          {
            title: 'ğŸ’° ê°€ê²© ì •ë³´',
            icon: 'web' as const,
            color: 'border-green-500',
            items: [
              {
                title: 'OpenAI Pricing',
                authors: 'OpenAI',
                year: '2025',
                description: 'GPT-4o \$5/1M tokens',
                link: 'https://openai.com/pricing'
              },
              {
                title: 'Anthropic Pricing',
                authors: 'Anthropic',
                year: '2025',
                description: 'Claude Opus 4 \$15/1M tokens',
                link: 'https://www.anthropic.com/pricing'
              },
              {
                title: 'Google AI Pricing',
                authors: 'Google',
                year: '2025',
                description: 'Gemini 2.5 Flash \$0.075/1M tokens',
                link: 'https://ai.google.dev/pricing'
              }
            ]
          },
          {
            title: 'ğŸ“– ì‹¤ì „ ê°€ì´ë“œ',
            icon: 'web' as const,
            color: 'border-red-500',
            items: [
              {
                title: 'OpenAI Cookbook',
                authors: 'OpenAI',
                year: '2025',
                description: 'API ì‚¬ìš© ì˜ˆì œ ë° ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤',
                link: 'https://cookbook.openai.com'
              },
              {
                title: 'Anthropic Prompt Engineering',
                authors: 'Anthropic',
                year: '2025',
                description: 'Claude ìµœì í™” í”„ë¡¬í”„íŠ¸ ê°€ì´ë“œ',
                link: 'https://docs.anthropic.com/claude/docs/prompt-engineering'
              },
              {
                title: 'LangChain Integrations',
                authors: 'LangChain',
                year: '2025',
                description: '40+ AI í”„ë¡œë°”ì´ë” í†µí•© ê°€ì´ë“œ',
                link: 'https://python.langchain.com/docs/integrations'
              }
            ]
          }
        ]}
      />
    </div>
  )
}

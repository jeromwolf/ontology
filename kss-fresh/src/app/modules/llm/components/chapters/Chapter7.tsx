'use client'

import References from '@/components/common/References'

export default function Chapter7() {
  return (
    <div className="space-y-8">
      {/* Hero Section */}
      <div className="bg-gradient-to-r from-yellow-50 to-orange-50 dark:from-yellow-900/20 dark:to-orange-900/20 rounded-2xl p-8 border border-yellow-200 dark:border-yellow-800">
        <div className="flex items-start gap-4">
          <div className="text-5xl">ğŸ¤—</div>
          <div>
            <h1 className="text-3xl font-bold text-gray-900 dark:text-white mb-3">
              Hugging Face ì‹¤ì „ í™œìš©
            </h1>
            <p className="text-lg text-gray-700 dark:text-gray-300">
              í—ˆê¹…í˜ì´ìŠ¤ í”Œë«í¼ìœ¼ë¡œ ëª¨ë¸ ê°œë°œë¶€í„° ë°°í¬ê¹Œì§€ - ì‹¤ë¬´ ì¤‘ì‹¬ ì™„ì „ ê°€ì´ë“œ
            </p>
          </div>
        </div>
      </div>

      {/* Learning Objectives */}
      <div className="bg-blue-50 dark:bg-blue-900/20 rounded-xl p-6 border border-blue-200 dark:border-blue-800">
        <h2 className="text-xl font-semibold text-blue-900 dark:text-blue-300 mb-4">
          ğŸ¯ í•™ìŠµ ëª©í‘œ
        </h2>
        <ul className="space-y-2 text-gray-700 dark:text-gray-300">
          <li className="flex items-start gap-2">
            <span className="text-blue-500 mt-1">âœ“</span>
            <span>Transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ ëª¨ë¸ ë¡œë“œ, íŒŒì¸íŠœë‹, ì¶”ë¡  ë§ˆìŠ¤í„°</span>
          </li>
          <li className="flex items-start gap-2">
            <span className="text-blue-500 mt-1">âœ“</span>
            <span>Datasetsë¡œ ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ íš¨ìœ¨ì  ì²˜ë¦¬</span>
          </li>
          <li className="flex items-start gap-2">
            <span className="text-blue-500 mt-1">âœ“</span>
            <span>Tokenizersë¡œ ì»¤ìŠ¤í…€ í† í¬ë‚˜ì´ì € êµ¬ì¶•</span>
          </li>
          <li className="flex items-start gap-2">
            <span className="text-blue-500 mt-1">âœ“</span>
            <span>Spacesë¡œ ì›¹ ë°ëª¨ ì•± ë°°í¬ ì‹¤ìŠµ</span>
          </li>
          <li className="flex items-start gap-2">
            <span className="text-blue-500 mt-1">âœ“</span>
            <span>AutoTrainìœ¼ë¡œ No-code ëª¨ë¸ í•™ìŠµ</span>
          </li>
          <li className="flex items-start gap-2">
            <span className="text-blue-500 mt-1">âœ“</span>
            <span>Inference APIë¥¼ í™œìš©í•œ í”„ë¡œë•ì…˜ ë°°í¬</span>
          </li>
        </ul>
      </div>

      {/* Section 1: Transformers Library */}
      <section className="space-y-6">
        <h2 className="text-2xl font-bold text-gray-900 dark:text-white border-b-2 border-yellow-500 pb-2">
          1. Transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ - í•µì‹¬ ë„êµ¬
        </h2>

        <div className="bg-white dark:bg-gray-800 rounded-xl p-6 border border-gray-200 dark:border-gray-700">
          <h3 className="text-xl font-semibold text-gray-900 dark:text-white mb-4">
            1.1 ê¸°ë³¸ ì‚¬ìš©ë²•: ëª¨ë¸ ë¡œë“œì™€ ì¶”ë¡ 
          </h3>

          <p className="text-gray-700 dark:text-gray-300 mb-4">
            Hugging Faceì˜ TransformersëŠ” 10ë§Œ+ ì‚¬ì „í•™ìŠµ ëª¨ë¸ì— 3ì¤„ ì½”ë“œë¡œ ì ‘ê·¼í•  ìˆ˜ ìˆëŠ” í˜ëª…ì  ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤.
          </p>

          <div className="bg-gray-900 rounded-lg p-4 mb-4">
            <pre className="text-sm text-gray-100 overflow-x-auto">
              <code>{`# í…ìŠ¤íŠ¸ ìƒì„± - GPT-2 ì˜ˆì œ
from transformers import pipeline

# Pipeline API - ê°€ì¥ ê°„ë‹¨í•œ ë°©ë²•
generator = pipeline('text-generation', model='gpt2')
result = generator(
    "Artificial Intelligence is",
    max_length=50,
    num_return_sequences=3
)
print(result)

# ê°ì • ë¶„ì„ - í•œêµ­ì–´ ëª¨ë¸
sentiment = pipeline(
    'sentiment-analysis',
    model='beomi/KcELECTRA-base-v2022'
)
result = sentiment("ì´ ì˜í™” ì •ë§ ì¬ë¯¸ìˆì–´ìš”!")
# Output: [{'label': 'POSITIVE', 'score': 0.9987}]`}</code>
            </pre>
          </div>

          <div className="bg-yellow-50 dark:bg-yellow-900/20 rounded-lg p-4 border-l-4 border-yellow-500">
            <p className="text-sm text-gray-700 dark:text-gray-300">
              <strong>ğŸ’¡ Pro Tip:</strong> pipeline() APIëŠ” í† í¬ë‚˜ì´ì €, ëª¨ë¸, í›„ì²˜ë¦¬ë¥¼ ìë™ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.
              í”„ë¡œí† íƒ€ì´í•‘ì— ìµœì ì´ì§€ë§Œ, ì„¸ë°€í•œ ì œì–´ê°€ í•„ìš”í•˜ë©´ AutoModelê³¼ AutoTokenizerë¥¼ ì§ì ‘ ì‚¬ìš©í•˜ì„¸ìš”.
            </p>
          </div>
        </div>

        <div className="bg-white dark:bg-gray-800 rounded-xl p-6 border border-gray-200 dark:border-gray-700">
          <h3 className="text-xl font-semibold text-gray-900 dark:text-white mb-4">
            1.2 ê³ ê¸‰ ì‚¬ìš©: ì§ì ‘ ëª¨ë¸ ì œì–´
          </h3>

          <div className="bg-gray-900 rounded-lg p-4 mb-4">
            <pre className="text-sm text-gray-100 overflow-x-auto">
              <code>{`from transformers import AutoTokenizer, AutoModelForCausalLM
import torch

# ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë¡œë“œ
model_name = "meta-llama/Llama-3.3-70B-Instruct"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    torch_dtype=torch.bfloat16,  # ë©”ëª¨ë¦¬ íš¨ìœ¨
    device_map="auto",            # ë©€í‹° GPU ìë™ ë¶„ì‚°
    load_in_8bit=True             # ì–‘ìí™”ë¡œ ë©”ëª¨ë¦¬ ì ˆì•½
)

# í† í°í™”
messages = [
    {"role": "system", "content": "You are a helpful AI assistant."},
    {"role": "user", "content": "Explain quantum computing simply."}
]
text = tokenizer.apply_chat_template(messages, tokenize=False)
inputs = tokenizer(text, return_tensors="pt").to(model.device)

# ìƒì„±
outputs = model.generate(
    **inputs,
    max_new_tokens=512,
    temperature=0.7,
    top_p=0.9,
    do_sample=True,
    pad_token_id=tokenizer.eos_token_id
)

response = tokenizer.decode(outputs[0], skip_special_tokens=True)
print(response)`}</code>
            </pre>
          </div>

          <div className="grid md:grid-cols-2 gap-4">
            <div className="bg-purple-50 dark:bg-purple-900/20 rounded-lg p-4">
              <h4 className="font-semibold text-purple-900 dark:text-purple-300 mb-2">
                ì£¼ìš” íŒŒë¼ë¯¸í„° ì„¤ëª…
              </h4>
              <ul className="text-sm text-gray-700 dark:text-gray-300 space-y-1">
                <li><code className="bg-purple-100 dark:bg-purple-900 px-1 rounded">temperature</code>: ì°½ì˜ì„± ì¡°ì ˆ (0.1-2.0)</li>
                <li><code className="bg-purple-100 dark:bg-purple-900 px-1 rounded">top_p</code>: ëˆ„ì  í™•ë¥  ìƒ˜í”Œë§</li>
                <li><code className="bg-purple-100 dark:bg-purple-900 px-1 rounded">top_k</code>: ìƒìœ„ Kê°œ í† í° ì œí•œ</li>
                <li><code className="bg-purple-100 dark:bg-purple-900 px-1 rounded">repetition_penalty</code>: ë°˜ë³µ ì–µì œ</li>
              </ul>
            </div>
            <div className="bg-green-50 dark:bg-green-900/20 rounded-lg p-4">
              <h4 className="font-semibold text-green-900 dark:text-green-300 mb-2">
                ë©”ëª¨ë¦¬ ìµœì í™” ê¸°ë²•
              </h4>
              <ul className="text-sm text-gray-700 dark:text-gray-300 space-y-1">
                <li><code className="bg-green-100 dark:bg-green-900 px-1 rounded">load_in_8bit</code>: 8ë¹„íŠ¸ ì–‘ìí™”</li>
                <li><code className="bg-green-100 dark:bg-green-900 px-1 rounded">load_in_4bit</code>: 4ë¹„íŠ¸ ì–‘ìí™” (QLoRA)</li>
                <li><code className="bg-green-100 dark:bg-green-900 px-1 rounded">device_map="auto"</code>: ìë™ GPU ë¶„ì‚°</li>
                <li><code className="bg-green-100 dark:bg-green-900 px-1 rounded">torch.compile()</code>: PyTorch 2.0 ê°€ì†</li>
              </ul>
            </div>
          </div>
        </div>

        <div className="bg-white dark:bg-gray-800 rounded-xl p-6 border border-gray-200 dark:border-gray-700">
          <h3 className="text-xl font-semibold text-gray-900 dark:text-white mb-4">
            1.3 íŒŒì¸íŠœë‹: Trainer API í™œìš©
          </h3>

          <div className="bg-gray-900 rounded-lg p-4 mb-4">
            <pre className="text-sm text-gray-100 overflow-x-auto">
              <code>{`from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    Trainer,
    TrainingArguments
)
from datasets import load_dataset

# ë°ì´í„°ì…‹ ë¡œë“œ (ê°ì • ë¶„ì„ ì˜ˆì œ)
dataset = load_dataset("yelp_review_full")
tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")

# í† í°í™” í•¨ìˆ˜
def tokenize_function(examples):
    return tokenizer(
        examples["text"],
        padding="max_length",
        truncation=True,
        max_length=512
    )

tokenized_datasets = dataset.map(tokenize_function, batched=True)

# ëª¨ë¸ ì´ˆê¸°í™”
model = AutoModelForSequenceClassification.from_pretrained(
    "bert-base-uncased",
    num_labels=5  # 5ì  í‰ì 
)

# í•™ìŠµ ì„¤ì •
training_args = TrainingArguments(
    output_dir="./results",
    evaluation_strategy="epoch",
    learning_rate=2e-5,
    per_device_train_batch_size=16,
    per_device_eval_batch_size=16,
    num_train_epochs=3,
    weight_decay=0.01,
    warmup_steps=500,
    logging_dir='./logs',
    logging_steps=100,
    save_strategy="epoch",
    load_best_model_at_end=True,
    metric_for_best_model="accuracy",
    fp16=True,  # Mixed precision training
    gradient_checkpointing=True,  # ë©”ëª¨ë¦¬ ì ˆì•½
)

# Trainer ì´ˆê¸°í™” ë° í•™ìŠµ
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["test"],
    compute_metrics=compute_metrics  # ì»¤ìŠ¤í…€ ë©”íŠ¸ë¦­ í•¨ìˆ˜
)

# í•™ìŠµ ì‹¤í–‰
trainer.train()

# ëª¨ë¸ ì €ì¥ ë° Hub ì—…ë¡œë“œ
trainer.save_model("./my-finetuned-model")
model.push_to_hub("your-username/yelp-sentiment-model")`}</code>
            </pre>
          </div>
        </div>
      </section>

      {/* Section 2: Datasets */}
      <section className="space-y-6">
        <h2 className="text-2xl font-bold text-gray-900 dark:text-white border-b-2 border-yellow-500 pb-2">
          2. Datasets - ëŒ€ê·œëª¨ ë°ì´í„° ì²˜ë¦¬
        </h2>

        <div className="bg-white dark:bg-gray-800 rounded-xl p-6 border border-gray-200 dark:border-gray-700">
          <h3 className="text-xl font-semibold text-gray-900 dark:text-white mb-4">
            2.1 Hubì—ì„œ ë°ì´í„°ì…‹ ë¡œë“œ
          </h3>

          <div className="bg-gray-900 rounded-lg p-4 mb-4">
            <pre className="text-sm text-gray-100 overflow-x-auto">
              <code>{`from datasets import load_dataset

# ê³µê°œ ë°ì´í„°ì…‹ ë¡œë“œ
dataset = load_dataset("squad")  # Stanford Question Answering

# íŠ¹ì • ì„¤ì •(configuration) ì§€ì •
dataset = load_dataset("glue", "mrpc")  # GLUE ë²¤ì¹˜ë§ˆí¬ì˜ MRPC íƒœìŠ¤í¬

# ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ (ë©”ëª¨ë¦¬ ì ˆì•½)
dataset = load_dataset("c4", "en", streaming=True)

# ë¡œì»¬ íŒŒì¼ ë¡œë“œ
dataset = load_dataset("csv", data_files="./my_data.csv")
dataset = load_dataset("json", data_files="./data/*.jsonl")

# ì»¤ìŠ¤í…€ split
dataset = load_dataset("imdb", split="train[:80%]")  # í›ˆë ¨ ë°ì´í„°ì˜ 80%ë§Œ`}</code>
            </pre>
          </div>
        </div>

        <div className="bg-white dark:bg-gray-800 rounded-xl p-6 border border-gray-200 dark:border-gray-700">
          <h3 className="text-xl font-semibold text-gray-900 dark:text-white mb-4">
            2.2 ë°ì´í„° ì „ì²˜ë¦¬ ë° ë³€í™˜
          </h3>

          <div className="bg-gray-900 rounded-lg p-4 mb-4">
            <pre className="text-sm text-gray-100 overflow-x-auto">
              <code>{`# map() - ê°€ì¥ ë§ì´ ì‚¬ìš©í•˜ëŠ” ë³€í™˜ í•¨ìˆ˜
def preprocess_function(examples):
    # ë°°ì¹˜ ì²˜ë¦¬ë¡œ ì†ë„ ìµœì í™”
    return tokenizer(
        examples["question"],
        examples["context"],
        truncation=True,
        max_length=384,
        padding="max_length"
    )

dataset = dataset.map(
    preprocess_function,
    batched=True,  # ë°°ì¹˜ ì²˜ë¦¬ í™œì„±í™”
    num_proc=4,    # ë©€í‹°í”„ë¡œì„¸ì‹±
    remove_columns=dataset.column_names,  # ì›ë³¸ ì»¬ëŸ¼ ì œê±°
    load_from_cache_file=True  # ìºì‹± í™œìš©
)

# filter() - ì¡°ê±´ì— ë§ëŠ” ë°ì´í„°ë§Œ ì„ íƒ
long_texts = dataset.filter(lambda x: len(x["text"]) > 1000)

# select() - ì¸ë±ìŠ¤ë¡œ ì„ íƒ
small_dataset = dataset.select(range(1000))

# train_test_split() - ë°ì´í„° ë¶„í• 
dataset = dataset.train_test_split(test_size=0.2, seed=42)

# shuffle() - ì…”í”Œ
dataset = dataset.shuffle(seed=42)`}</code>
            </pre>
          </div>

          <div className="bg-orange-50 dark:bg-orange-900/20 rounded-lg p-4 border-l-4 border-orange-500">
            <p className="text-sm text-gray-700 dark:text-gray-300">
              <strong>âš¡ ì„±ëŠ¥ ìµœì í™” íŒ:</strong> <code className="bg-orange-100 dark:bg-orange-900 px-1 rounded">batched=True</code>ì™€
              <code className="bg-orange-100 dark:bg-orange-900 px-1 rounded ml-1">num_proc</code>ì„ í•¨ê»˜ ì‚¬ìš©í•˜ë©´
              ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ ì²˜ë¦¬ ì†ë„ê°€ 10-100ë°° ë¹¨ë¼ì§‘ë‹ˆë‹¤. Arrow í¬ë§· ë•ë¶„ì— ë””ìŠ¤í¬ I/Oë„ ìµœì†Œí™”ë©ë‹ˆë‹¤.
            </p>
          </div>
        </div>
      </section>

      {/* Section 3: Tokenizers */}
      <section className="space-y-6">
        <h2 className="text-2xl font-bold text-gray-900 dark:text-white border-b-2 border-yellow-500 pb-2">
          3. Tokenizers - ì»¤ìŠ¤í…€ í† í¬ë‚˜ì´ì € êµ¬ì¶•
        </h2>

        <div className="bg-white dark:bg-gray-800 rounded-xl p-6 border border-gray-200 dark:border-gray-700">
          <h3 className="text-xl font-semibold text-gray-900 dark:text-white mb-4">
            3.1 ë¹ ë¥¸ í† í¬ë‚˜ì´ì € í•™ìŠµ
          </h3>

          <div className="bg-gray-900 rounded-lg p-4 mb-4">
            <pre className="text-sm text-gray-100 overflow-x-auto">
              <code>{`from tokenizers import Tokenizer
from tokenizers.models import BPE, WordPiece, Unigram
from tokenizers.trainers import BpeTrainer, WordPieceTrainer
from tokenizers.pre_tokenizers import Whitespace
from tokenizers.normalizers import NFD, Lowercase, StripAccents
from tokenizers.processors import TemplateProcessing

# BPE í† í¬ë‚˜ì´ì € ìƒì„± (GPT ìŠ¤íƒ€ì¼)
tokenizer = Tokenizer(BPE(unk_token="[UNK]"))

# ì •ê·œí™”: ì†Œë¬¸ì ë³€í™˜, ì•…ì„¼íŠ¸ ì œê±°
tokenizer.normalizer = normalizers.Sequence([
    NFD(),
    Lowercase(),
    StripAccents()
])

# ì‚¬ì „ í† í°í™”: ê³µë°± ê¸°ì¤€
tokenizer.pre_tokenizer = Whitespace()

# í•™ìŠµ ì¤€ë¹„
trainer = BpeTrainer(
    vocab_size=30000,
    min_frequency=2,
    special_tokens=["[UNK]", "[CLS]", "[SEP]", "[PAD]", "[MASK]"]
)

# íŒŒì¼ë¡œë¶€í„° í•™ìŠµ
files = ["path/to/corpus1.txt", "path/to/corpus2.txt"]
tokenizer.train(files, trainer)

# í›„ì²˜ë¦¬: BERT ìŠ¤íƒ€ì¼ [CLS], [SEP] ì¶”ê°€
tokenizer.post_processor = TemplateProcessing(
    single="[CLS] $A [SEP]",
    pair="[CLS] $A [SEP] $B:1 [SEP]:1",
    special_tokens=[
        ("[CLS]", tokenizer.token_to_id("[CLS]")),
        ("[SEP]", tokenizer.token_to_id("[SEP]")),
    ],
)

# ì €ì¥
tokenizer.save("my_tokenizer.json")

# Transformersì™€ í†µí•©
from transformers import PreTrainedTokenizerFast
fast_tokenizer = PreTrainedTokenizerFast(tokenizer_file="my_tokenizer.json")`}</code>
            </pre>
          </div>
        </div>
      </section>

      {/* Section 4: Spaces */}
      <section className="space-y-6">
        <h2 className="text-2xl font-bold text-gray-900 dark:text-white border-b-2 border-yellow-500 pb-2">
          4. Spaces - ì›¹ ë°ëª¨ ì•± ë°°í¬
        </h2>

        <div className="bg-white dark:bg-gray-800 rounded-xl p-6 border border-gray-200 dark:border-gray-700">
          <h3 className="text-xl font-semibold text-gray-900 dark:text-white mb-4">
            4.1 Gradioë¡œ ì¦‰ì‹œ ë°°í¬
          </h3>

          <div className="bg-gray-900 rounded-lg p-4 mb-4">
            <pre className="text-sm text-gray-100 overflow-x-auto">
              <code>{`import gradio as gr
from transformers import pipeline

# ëª¨ë¸ ë¡œë“œ
pipe = pipeline("text-generation", model="gpt2")

# ì¸í„°í˜ì´ìŠ¤ í•¨ìˆ˜
def generate_text(prompt, max_length=100, temperature=0.7):
    result = pipe(
        prompt,
        max_length=max_length,
        temperature=temperature,
        num_return_sequences=1
    )
    return result[0]['generated_text']

# Gradio ì¸í„°í˜ì´ìŠ¤ ìƒì„±
demo = gr.Interface(
    fn=generate_text,
    inputs=[
        gr.Textbox(label="í”„ë¡¬í”„íŠ¸", placeholder="í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”..."),
        gr.Slider(minimum=50, maximum=500, value=100, label="ìµœëŒ€ ê¸¸ì´"),
        gr.Slider(minimum=0.1, maximum=2.0, value=0.7, step=0.1, label="Temperature")
    ],
    outputs=gr.Textbox(label="ìƒì„±ëœ í…ìŠ¤íŠ¸"),
    title="GPT-2 í…ìŠ¤íŠ¸ ìƒì„±ê¸°",
    description="GPT-2 ëª¨ë¸ì„ ì‚¬ìš©í•œ ìë™ í…ìŠ¤íŠ¸ ìƒì„± ë°ëª¨",
    examples=[
        ["Once upon a time", 150, 0.9],
        ["In a galaxy far far away", 200, 0.8]
    ]
)

# ë¡œì»¬ ì‹¤í–‰
if __name__ == "__main__":
    demo.launch()

# Hugging Face Spacesì— ë°°í¬
# 1. Spaces ì €ì¥ì†Œ ìƒì„±: https://huggingface.co/new-space
# 2. Git clone
# 3. app.pyì— ìœ„ ì½”ë“œ ì €ì¥
# 4. requirements.txt ìƒì„±:
#    transformers
#    torch
#    gradio
# 5. git push â†’ ìë™ ë°°í¬!`}</code>
            </pre>
          </div>
        </div>

        <div className="bg-white dark:bg-gray-800 rounded-xl p-6 border border-gray-200 dark:border-gray-700">
          <h3 className="text-xl font-semibold text-gray-900 dark:text-white mb-4">
            4.2 Streamlitìœ¼ë¡œ ê³ ê¸‰ ì•± êµ¬ì¶•
          </h3>

          <div className="bg-gray-900 rounded-lg p-4 mb-4">
            <pre className="text-sm text-gray-100 overflow-x-auto">
              <code>{`import streamlit as st
from transformers import pipeline

@st.cache_resource
def load_model():
    return pipeline("sentiment-analysis")

st.title("ê°ì • ë¶„ì„ ì•±")
st.write("í…ìŠ¤íŠ¸ì˜ ê¸ì •/ë¶€ì •ì„ ë¶„ì„í•©ë‹ˆë‹¤")

# ì‚¬ì´ë“œë°” ì„¤ì •
with st.sidebar:
    st.header("ì„¤ì •")
    threshold = st.slider("ì‹ ë¢°ë„ ì„ê³„ê°’", 0.0, 1.0, 0.5)

# ë©”ì¸ ì˜ì—­
text = st.text_area("ë¶„ì„í•  í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”", height=150)

if st.button("ë¶„ì„"):
    if text:
        model = load_model()
        result = model(text)[0]

        # ê²°ê³¼ í‘œì‹œ
        st.subheader("ê²°ê³¼")
        col1, col2 = st.columns(2)

        with col1:
            st.metric("ê°ì •", result['label'])
        with col2:
            st.metric("ì‹ ë¢°ë„", f"{result['score']:.2%}")

        # ì‹œê°í™”
        if result['score'] >= threshold:
            st.success("ë†’ì€ ì‹ ë¢°ë„ë¡œ ë¶„ë¥˜ë˜ì—ˆìŠµë‹ˆë‹¤!")
        else:
            st.warning("ì‹ ë¢°ë„ê°€ ë‚®ìŠµë‹ˆë‹¤. ì¬ê²€í† ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
    else:
        st.error("í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”")`}</code>
            </pre>
          </div>
        </div>
      </section>

      {/* Section 5: AutoTrain */}
      <section className="space-y-6">
        <h2 className="text-2xl font-bold text-gray-900 dark:text-white border-b-2 border-yellow-500 pb-2">
          5. AutoTrain - No-code ëª¨ë¸ í•™ìŠµ
        </h2>

        <div className="bg-white dark:bg-gray-800 rounded-xl p-6 border border-gray-200 dark:border-gray-700">
          <p className="text-gray-700 dark:text-gray-300 mb-4">
            AutoTrainì€ ì½”ë“œ ì—†ì´ ë¸Œë¼ìš°ì €ì—ì„œ í´ë¦­ë§Œìœ¼ë¡œ ëª¨ë¸ì„ íŒŒì¸íŠœë‹í•  ìˆ˜ ìˆëŠ” í”Œë«í¼ì…ë‹ˆë‹¤.
          </p>

          <div className="grid md:grid-cols-2 gap-6">
            <div className="space-y-4">
              <h4 className="font-semibold text-gray-900 dark:text-white">
                ğŸ“Š ì§€ì› íƒœìŠ¤í¬
              </h4>
              <ul className="space-y-2 text-sm text-gray-700 dark:text-gray-300">
                <li>â€¢ Text Classification (ê°ì • ë¶„ì„, ì£¼ì œ ë¶„ë¥˜)</li>
                <li>â€¢ Token Classification (NER, POS tagging)</li>
                <li>â€¢ Question Answering (SQuAD ìŠ¤íƒ€ì¼)</li>
                <li>â€¢ Summarization (ìš”ì•½)</li>
                <li>â€¢ Translation (ë²ˆì—­)</li>
                <li>â€¢ Image Classification (ì´ë¯¸ì§€ ë¶„ë¥˜)</li>
                <li>â€¢ Object Detection (ê°ì²´ íƒì§€)</li>
                <li>â€¢ Tabular Data (í…Œì´ë¸” ë°ì´í„°)</li>
              </ul>
            </div>

            <div className="space-y-4">
              <h4 className="font-semibold text-gray-900 dark:text-white">
                ğŸš€ ì‚¬ìš© ë°©ë²•
              </h4>
              <ol className="space-y-2 text-sm text-gray-700 dark:text-gray-300">
                <li>1. huggingface.co/autotrain ì ‘ì†</li>
                <li>2. í”„ë¡œì íŠ¸ ìƒì„± ë° íƒœìŠ¤í¬ ì„ íƒ</li>
                <li>3. ë°ì´í„°ì…‹ ì—…ë¡œë“œ (CSV, JSON)</li>
                <li>4. ë² ì´ìŠ¤ ëª¨ë¸ ì„ íƒ (BERT, GPT, etc.)</li>
                <li>5. í•˜ì´í¼íŒŒë¼ë¯¸í„° ìë™ íŠœë‹</li>
                <li>6. í•™ìŠµ ì‹œì‘ (GPU ìë™ í• ë‹¹)</li>
                <li>7. ëª¨ë¸ í‰ê°€ ë° ë°°í¬</li>
              </ol>
            </div>
          </div>

          <div className="mt-6 bg-green-50 dark:bg-green-900/20 rounded-lg p-4 border-l-4 border-green-500">
            <p className="text-sm text-gray-700 dark:text-gray-300">
              <strong>ğŸ’° ë¹„ìš©:</strong> ë¬´ë£Œ í”Œëœì€ ì›” 5ì‹œê°„ GPU ì œê³µ.
              Pro í”Œëœ($9/ì›”)ì€ ë¬´ì œí•œ í•™ìŠµ + ìš°ì„  GPU ì ‘ê·¼ + í”„ë¼ì´ë¹— ëª¨ë¸ ì§€ì›.
            </p>
          </div>
        </div>
      </section>

      {/* Section 6: Inference API */}
      <section className="space-y-6">
        <h2 className="text-2xl font-bold text-gray-900 dark:text-white border-b-2 border-yellow-500 pb-2">
          6. Inference API - í”„ë¡œë•ì…˜ ë°°í¬
        </h2>

        <div className="bg-white dark:bg-gray-800 rounded-xl p-6 border border-gray-200 dark:border-gray-700">
          <h3 className="text-xl font-semibold text-gray-900 dark:text-white mb-4">
            6.1 REST APIë¡œ ëª¨ë¸ í˜¸ì¶œ
          </h3>

          <div className="bg-gray-900 rounded-lg p-4 mb-4">
            <pre className="text-sm text-gray-100 overflow-x-auto">
              <code>{`import requests

API_URL = "https://api-inference.huggingface.co/models/gpt2"
headers = {"Authorization": "Bearer YOUR_HF_TOKEN"}

def query(payload):
    response = requests.post(API_URL, headers=headers, json=payload)
    return response.json()

# í…ìŠ¤íŠ¸ ìƒì„±
output = query({
    "inputs": "The future of AI is",
    "parameters": {
        "max_new_tokens": 50,
        "temperature": 0.7,
        "top_p": 0.9
    }
})
print(output)

# ë°°ì¹˜ ì²˜ë¦¬
batch_output = query({
    "inputs": [
        "First prompt",
        "Second prompt",
        "Third prompt"
    ]
})

# ì´ë¯¸ì§€ ë¶„ë¥˜
import base64
with open("image.jpg", "rb") as f:
    img_data = base64.b64encode(f.read()).decode()

API_URL = "https://api-inference.huggingface.co/models/google/vit-base-patch16-224"
output = query({"inputs": img_data})`}</code>
            </pre>
          </div>
        </div>

        <div className="bg-white dark:bg-gray-800 rounded-xl p-6 border border-gray-200 dark:border-gray-700">
          <h3 className="text-xl font-semibold text-gray-900 dark:text-white mb-4">
            6.2 Python í´ë¼ì´ì–¸íŠ¸ ì‚¬ìš©
          </h3>

          <div className="bg-gray-900 rounded-lg p-4 mb-4">
            <pre className="text-sm text-gray-100 overflow-x-auto">
              <code>{`from huggingface_hub import InferenceClient

# í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
client = InferenceClient(token="YOUR_HF_TOKEN")

# í…ìŠ¤íŠ¸ ìƒì„±
response = client.text_generation(
    "Explain quantum computing",
    model="meta-llama/Llama-3.3-70B-Instruct",
    max_new_tokens=200,
    temperature=0.7,
    stream=True  # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ
)

for token in response:
    print(token, end="")

# ì±„íŒ… ì™„ì„±
messages = [
    {"role": "user", "content": "What is machine learning?"}
]
response = client.chat_completion(
    messages,
    model="mistralai/Mixtral-8x7B-Instruct-v0.1",
    max_tokens=500
)
print(response.choices[0].message.content)

# ì„ë² ë”© ìƒì„±
embeddings = client.feature_extraction(
    "This is a sentence to embed",
    model="sentence-transformers/all-MiniLM-L6-v2"
)
print(f"Embedding dimension: {len(embeddings[0])}")

# ì œë¡œìƒ· ë¶„ë¥˜
result = client.zero_shot_classification(
    "This movie was amazing!",
    labels=["positive", "negative", "neutral"],
    model="facebook/bart-large-mnli"
)
print(result)`}</code>
            </pre>
          </div>

          <div className="bg-blue-50 dark:bg-blue-900/20 rounded-lg p-4 border-l-4 border-blue-500">
            <p className="text-sm text-gray-700 dark:text-gray-300">
              <strong>ğŸ”‘ API í† í° ìƒì„±:</strong> huggingface.co/settings/tokensì—ì„œ
              Read ê¶Œí•œ í† í° ìƒì„±. í™˜ê²½ë³€ìˆ˜ <code className="bg-blue-100 dark:bg-blue-900 px-1 rounded">HF_TOKEN</code>ìœ¼ë¡œ ì €ì¥ ê¶Œì¥.
            </p>
          </div>
        </div>

        <div className="bg-white dark:bg-gray-800 rounded-xl p-6 border border-gray-200 dark:border-gray-700">
          <h3 className="text-xl font-semibold text-gray-900 dark:text-white mb-4">
            6.3 ì „ìš© ì—”ë“œí¬ì¸íŠ¸ (Dedicated Endpoints)
          </h3>

          <div className="grid md:grid-cols-2 gap-6">
            <div className="bg-gradient-to-br from-purple-50 to-pink-50 dark:from-purple-900/20 dark:to-pink-900/20 rounded-lg p-6">
              <h4 className="font-semibold text-purple-900 dark:text-purple-300 mb-3">
                ë¬´ë£Œ Inference API
              </h4>
              <ul className="space-y-2 text-sm text-gray-700 dark:text-gray-300">
                <li>âœ“ 10ë§Œ+ ê³µê°œ ëª¨ë¸ ì ‘ê·¼</li>
                <li>âœ“ ë¬´ì œí•œ ìš”ì²­ (rate limit æœ‰)</li>
                <li>âœ“ ì½œë“œ ìŠ¤íƒ€íŠ¸ ì§€ì—° æœ‰</li>
                <li>âœ“ ê³µìœ  ì¸í”„ë¼</li>
                <li>âœ“ ê°œë°œ/í”„ë¡œí† íƒ€ì´í•‘ ìµœì </li>
              </ul>
            </div>

            <div className="bg-gradient-to-br from-green-50 to-teal-50 dark:from-green-900/20 dark:to-teal-900/20 rounded-lg p-6">
              <h4 className="font-semibold text-green-900 dark:text-green-300 mb-3">
                Dedicated Endpoints (ìœ ë£Œ)
              </h4>
              <ul className="space-y-2 text-sm text-gray-700 dark:text-gray-300">
                <li>âœ“ ì „ìš© GPU/CPU í• ë‹¹</li>
                <li>âœ“ ì½œë“œ ìŠ¤íƒ€íŠ¸ ì—†ìŒ</li>
                <li>âœ“ ì˜ˆì¸¡ ê°€ëŠ¥í•œ ë ˆì´í„´ì‹œ</li>
                <li>âœ“ ì˜¤í† ìŠ¤ì¼€ì¼ë§ ì§€ì›</li>
                <li>âœ“ í”„ë¡œë•ì…˜ í™˜ê²½ ìµœì </li>
                <li>ğŸ’° $0.60/hr (GPU) ~</li>
              </ul>
            </div>
          </div>
        </div>
      </section>

      {/* Best Practices */}
      <div className="bg-gradient-to-r from-purple-50 to-pink-50 dark:from-purple-900/20 dark:to-pink-900/20 rounded-xl p-6 border border-purple-200 dark:border-purple-800">
        <h2 className="text-xl font-semibold text-purple-900 dark:text-purple-300 mb-4">
          ğŸ’ ì‹¤ë¬´ Best Practices
        </h2>
        <div className="grid md:grid-cols-2 gap-6">
          <div className="space-y-3">
            <h4 className="font-semibold text-gray-900 dark:text-white">ê°œë°œ ë‹¨ê³„</h4>
            <ul className="space-y-2 text-sm text-gray-700 dark:text-gray-300">
              <li>â€¢ <strong>ëª¨ë¸ ì„ íƒ:</strong> Hubì—ì„œ íƒœìŠ¤í¬ë³„ ë¦¬ë”ë³´ë“œ í™•ì¸</li>
              <li>â€¢ <strong>ë°ì´í„°:</strong> ìµœì†Œ 1,000ê°œ ìƒ˜í”Œë¡œ ì‹œì‘</li>
              <li>â€¢ <strong>ê²€ì¦:</strong> 10-20% í™€ë“œì•„ì›ƒ ì„¸íŠ¸ í•„ìˆ˜</li>
              <li>â€¢ <strong>ë²„ì „ ê´€ë¦¬:</strong> Git LFSë¡œ ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ê´€ë¦¬</li>
            </ul>
          </div>
          <div className="space-y-3">
            <h4 className="font-semibold text-gray-900 dark:text-white">í”„ë¡œë•ì…˜ ë‹¨ê³„</h4>
            <ul className="space-y-2 text-sm text-gray-700 dark:text-gray-300">
              <li>â€¢ <strong>ëª¨ë‹ˆí„°ë§:</strong> ì…ì¶œë ¥ ë¡œê¹…, ë ˆì´í„´ì‹œ ì¶”ì </li>
              <li>â€¢ <strong>A/B í…ŒìŠ¤íŒ…:</strong> Spacesë¡œ ì—¬ëŸ¬ ëª¨ë¸ ë¹„êµ</li>
              <li>â€¢ <strong>ë¹„ìš© ìµœì í™”:</strong> ì–‘ìí™”, ì§€ì‹ ì¦ë¥˜ ì ìš©</li>
              <li>â€¢ <strong>ë³´ì•ˆ:</strong> í”„ë¼ì´ë¹— ëª¨ë¸ + ì•¡ì„¸ìŠ¤ í† í° ê´€ë¦¬</li>
            </ul>
          </div>
        </div>
      </div>

      {/* Additional Resources */}
      <div className="bg-gray-50 dark:bg-gray-800 rounded-xl p-6 border border-gray-200 dark:border-gray-700">
        <h2 className="text-xl font-semibold text-gray-900 dark:text-white mb-4">
          ğŸ“š ì¶”ê°€ í•™ìŠµ ë¦¬ì†ŒìŠ¤
        </h2>
        <div className="grid md:grid-cols-2 gap-4">
          <div>
            <h4 className="font-semibold text-gray-900 dark:text-white mb-2">ê³µì‹ ë¬¸ì„œ</h4>
            <ul className="space-y-1 text-sm text-gray-700 dark:text-gray-300">
              <li>â€¢ <a href="https://huggingface.co/docs/transformers" className="text-blue-600 hover:underline">Transformers ë¬¸ì„œ</a></li>
              <li>â€¢ <a href="https://huggingface.co/docs/datasets" className="text-blue-600 hover:underline">Datasets ë¬¸ì„œ</a></li>
              <li>â€¢ <a href="https://huggingface.co/docs/tokenizers" className="text-blue-600 hover:underline">Tokenizers ë¬¸ì„œ</a></li>
              <li>â€¢ <a href="https://huggingface.co/docs/hub" className="text-blue-600 hover:underline">Hub ê°€ì´ë“œ</a></li>
            </ul>
          </div>
          <div>
            <h4 className="font-semibold text-gray-900 dark:text-white mb-2">ì‹¤ìŠµ ì½”ìŠ¤</h4>
            <ul className="space-y-1 text-sm text-gray-700 dark:text-gray-300">
              <li>â€¢ <a href="https://huggingface.co/learn/nlp-course" className="text-blue-600 hover:underline">NLP Course (ë¬´ë£Œ)</a></li>
              <li>â€¢ <a href="https://huggingface.co/learn/deep-rl-course" className="text-blue-600 hover:underline">Deep RL Course</a></li>
              <li>â€¢ <a href="https://github.com/huggingface/transformers/tree/main/examples" className="text-blue-600 hover:underline">ê³µì‹ ì˜ˆì œ ëª¨ìŒ</a></li>
            </ul>
          </div>
        </div>
      </div>

      {/* Summary */}
      <div className="bg-gradient-to-r from-yellow-50 to-orange-50 dark:from-yellow-900/20 dark:to-orange-900/20 rounded-xl p-6 border border-yellow-200 dark:border-yellow-800">
        <h2 className="text-xl font-semibold text-yellow-900 dark:text-yellow-300 mb-3">
          âœ¨ í•µì‹¬ ìš”ì•½
        </h2>
        <ul className="space-y-2 text-gray-700 dark:text-gray-300">
          <li>â€¢ <strong>Transformers:</strong> Pipeline APIë¡œ ë¹ ë¥¸ í”„ë¡œí† íƒ€ì´í•‘, Trainerë¡œ ì „ë¬¸ íŒŒì¸íŠœë‹</li>
          <li>â€¢ <strong>Datasets:</strong> Arrow í¬ë§· ë•ë¶„ì— í…Œë¼ë°”ì´íŠ¸ ë°ì´í„°ë„ íš¨ìœ¨ì  ì²˜ë¦¬</li>
          <li>â€¢ <strong>Tokenizers:</strong> Rust ê¸°ë°˜ ì´ˆê³ ì† í† í¬ë‚˜ì´ì €, ì»¤ìŠ¤í…€ ë¹Œë“œ ê°€ëŠ¥</li>
          <li>â€¢ <strong>Spaces:</strong> Gradio/Streamlitìœ¼ë¡œ git push í•œ ë²ˆì— ë°°í¬</li>
          <li>â€¢ <strong>AutoTrain:</strong> ì½”ë“œ ì—†ì´ ë¸Œë¼ìš°ì €ì—ì„œ ëª¨ë¸ í•™ìŠµ</li>
          <li>â€¢ <strong>Inference API:</strong> ì„œë²„ë¦¬ìŠ¤ ì¶”ë¡ , ë¬´ë£Œ â†’ ì „ìš© ì—”ë“œí¬ì¸íŠ¸ í™•ì¥</li>
        </ul>
      </div>

      {/* References */}
      <References
        sections={[
          {
            title: 'ğŸ“š ê³µì‹ ë¬¸ì„œ',
            icon: 'web' as const,
            color: 'border-orange-500',
            items: [
              {
                title: 'Transformers Documentation',
                authors: 'Hugging Face',
                year: '2025',
                description: 'Transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ ê³µì‹ ë¬¸ì„œ',
                link: 'https://huggingface.co/docs/transformers'
              },
              {
                title: 'Datasets Documentation',
                authors: 'Hugging Face',
                year: '2025',
                description: 'Datasets ë¼ì´ë¸ŒëŸ¬ë¦¬ ì™„ë²½ ê°€ì´ë“œ',
                link: 'https://huggingface.co/docs/datasets'
              },
              {
                title: 'Tokenizers Documentation',
                authors: 'Hugging Face',
                year: '2025',
                description: 'Rust ê¸°ë°˜ ê³ ì† í† í¬ë‚˜ì´ì €',
                link: 'https://huggingface.co/docs/tokenizers'
              },
              {
                title: 'Hugging Face Hub',
                authors: 'Hugging Face',
                year: '2025',
                description: '200,000+ ëª¨ë¸ê³¼ ë°ì´í„°ì…‹ í—ˆë¸Œ',
                link: 'https://huggingface.co/models'
              }
            ]
          },
          {
            title: 'ğŸ“ í•™ìŠµ ì½”ìŠ¤',
            icon: 'paper' as const,
            color: 'border-yellow-500',
            items: [
              {
                title: 'NLP Course',
                authors: 'Hugging Face',
                year: '2025',
                description: 'ë¬´ë£Œ NLP ì „ë¬¸ ì½”ìŠ¤ (í•œêµ­ì–´ ì§€ì›)',
                link: 'https://huggingface.co/learn/nlp-course'
              },
              {
                title: 'Deep Reinforcement Learning Course',
                authors: 'Hugging Face',
                year: '2024',
                description: 'ê°•í™”í•™ìŠµ ì‹¤ì „ ê°€ì´ë“œ',
                link: 'https://huggingface.co/learn/deep-rl-course'
              },
              {
                title: 'Fine-tuning Guide',
                authors: 'Hugging Face',
                year: '2025',
                description: 'ëª¨ë¸ íŒŒì¸íŠœë‹ ì™„ë²½ ê°€ì´ë“œ',
                link: 'https://huggingface.co/docs/transformers/training'
              }
            ]
          },
          {
            title: 'ğŸ› ï¸ ì‹¤ì „ ë¦¬ì†ŒìŠ¤',
            icon: 'web' as const,
            color: 'border-red-500',
            items: [
              {
                title: 'Spaces Documentation',
                authors: 'Hugging Face',
                year: '2025',
                description: 'ML ì•± ë¬´ë£Œ ë°°í¬ í”Œë«í¼',
                link: 'https://huggingface.co/docs/hub/spaces'
              },
              {
                title: 'AutoTrain',
                authors: 'Hugging Face',
                year: '2025',
                description: 'No-code ëª¨ë¸ í•™ìŠµ í”Œë«í¼',
                link: 'https://huggingface.co/autotrain'
              },
              {
                title: 'Inference Endpoints',
                authors: 'Hugging Face',
                year: '2025',
                description: 'í”„ë¡œë•ì…˜ AI API ì„œë¹„ìŠ¤',
                link: 'https://huggingface.co/inference-endpoints'
              },
              {
                title: 'Transformers Examples',
                authors: 'Hugging Face',
                year: '2025',
                description: 'ê³µì‹ ì˜ˆì œ ì½”ë“œ ëª¨ìŒ',
                link: 'https://github.com/huggingface/transformers/tree/main/examples'
              }
            ]
          }
        ]}
      />
    </div>
  )
}

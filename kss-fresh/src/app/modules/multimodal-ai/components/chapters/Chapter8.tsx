'use client'

import React from 'react'
import { MessageSquare, ImageIcon, Film, Eye, BookOpen, Sparkles, Target, TrendingUp } from 'lucide-react'
import References from '@/components/common/References'

export default function Chapter8() {
  return (
    <div className="min-h-screen bg-gradient-to-br from-slate-50 to-purple-50 dark:from-gray-900 dark:to-purple-900">
      <div className="max-w-4xl mx-auto px-6 py-12">
        {/* Header */}
        <div className="mb-12">
          <div className="flex items-center gap-3 mb-4">
            <div className="p-3 bg-gradient-to-br from-violet-500 to-purple-600 rounded-xl">
              <Target className="w-8 h-8 text-white" />
            </div>
            <div>
              <h1 className="text-4xl font-bold bg-gradient-to-r from-violet-600 to-purple-600 bg-clip-text text-transparent">
                ë©€í‹°ëª¨ë‹¬ ì‘ìš©
              </h1>
              <p className="text-gray-600 dark:text-gray-400 mt-1">
                VQA, ì´ë¯¸ì§€ ìº¡ì…”ë‹, ë¹„ë””ì˜¤ ì´í•´
              </p>
            </div>
          </div>
        </div>

        {/* Introduction */}
        <section className="mb-12 bg-white dark:bg-gray-800 rounded-2xl p-8 shadow-lg">
          <div className="flex items-center gap-3 mb-6">
            <BookOpen className="w-6 h-6 text-violet-600" />
            <h2 className="text-2xl font-bold text-gray-900 dark:text-white">
              ë©€í‹°ëª¨ë‹¬ AI ì‘ìš© ë¶„ì•¼
            </h2>
          </div>

          <div className="prose dark:prose-invert max-w-none">
            <p className="text-lg text-gray-700 dark:text-gray-300 leading-relaxed mb-6">
              ë©€í‹°ëª¨ë‹¬ AIëŠ” ì‹¤ì„¸ê³„ì˜ ë‹¤ì–‘í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ê°•ë ¥í•œ ë„êµ¬ì…ë‹ˆë‹¤.
              ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ë¥¼ ë™ì‹œì— ì´í•´í•˜ëŠ” VQA(Visual Question Answering),
              ì´ë¯¸ì§€ë¥¼ ìì—°ì–´ë¡œ ì„¤ëª…í•˜ëŠ” ì´ë¯¸ì§€ ìº¡ì…”ë‹,
              ë¹„ë””ì˜¤ì˜ ì‹œê³µê°„ ì •ë³´ë¥¼ íŒŒì•…í•˜ëŠ” ë¹„ë””ì˜¤ ì´í•´ ë“±
              ì¸ê°„ì˜ ì¸ì§€ ëŠ¥ë ¥ì„ ëª¨ë°©í•˜ëŠ” í˜ì‹ ì  ì‘ìš© ë¶„ì•¼ê°€ íƒ„ìƒí–ˆìŠµë‹ˆë‹¤.
            </p>

            <div className="bg-gradient-to-r from-violet-50 to-purple-50 dark:from-violet-900/20 dark:to-purple-900/20 rounded-xl p-6 mb-6 border border-violet-200 dark:border-violet-800">
              <p className="text-violet-900 dark:text-violet-100 font-semibold mb-2">
                ğŸ’¡ ì™œ ë©€í‹°ëª¨ë‹¬ ì‘ìš©ì´ ì¤‘ìš”í•œê°€?
              </p>
              <p className="text-violet-800 dark:text-violet-200">
                ë‹¨ì¼ ëª¨ë‹¬ë¦¬í‹°ë§Œìœ¼ë¡œëŠ” í•´ê²°í•  ìˆ˜ ì—†ëŠ” ë³µì¡í•œ íƒœìŠ¤í¬ë¥¼ ë©€í‹°ëª¨ë‹¬ AIê°€ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.
                ì‹œê° ì¥ì• ì¸ì„ ìœ„í•œ ì´ë¯¸ì§€ ì„¤ëª…, ì˜ë£Œ ì˜ìƒ ì§„ë‹¨, ììœ¨ì£¼í–‰ ì¸ì§€ ì‹œìŠ¤í…œ ë“±
                <strong>ì‹¤ì„¸ê³„ ë¬¸ì œ í•´ê²°</strong>ì— ì§ì ‘ì ìœ¼ë¡œ ê¸°ì—¬í•©ë‹ˆë‹¤.
              </p>
            </div>
          </div>
        </section>

        {/* VQA (Visual Question Answering) */}
        <section className="mb-12">
          <h2 className="text-2xl font-bold text-gray-900 dark:text-white mb-6 flex items-center gap-3">
            <MessageSquare className="w-6 h-6 text-violet-600" />
            Visual Question Answering (VQA)
          </h2>

          <div className="bg-white dark:bg-gray-800 rounded-2xl p-8 shadow-lg mb-6">
            <h3 className="text-xl font-bold text-gray-900 dark:text-white mb-4">
              VQAë€ ë¬´ì—‡ì¸ê°€?
            </h3>
            <p className="text-gray-700 dark:text-gray-300 mb-4">
              VQAëŠ” ì´ë¯¸ì§€ì™€ ìì—°ì–´ ì§ˆë¬¸ì„ ì…ë ¥ë°›ì•„ ì •í™•í•œ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” íƒœìŠ¤í¬ì…ë‹ˆë‹¤.
              ì´ë¯¸ì§€ ì´í•´(ê°ì²´, ì¥ë©´, ê´€ê³„), ì–¸ì–´ ì´í•´(ì§ˆë¬¸ ì˜ë„), ì¶”ë¡ (ë‹µë³€ ë„ì¶œ)ì„ ëª¨ë‘ í•„ìš”ë¡œ í•©ë‹ˆë‹¤.
            </p>

            <div className="grid md:grid-cols-3 gap-4 mb-6">
              {[
                {
                  type: 'ê°ì²´ ì¸ì‹',
                  question: '"ì´ ì‚¬ì§„ì— ëª‡ ëª…ì´ ìˆë‚˜ìš”?"',
                  answer: '"3ëª…"',
                  difficulty: 'ì‰¬ì›€',
                  color: 'blue'
                },
                {
                  type: 'ê³µê°„ ê´€ê³„',
                  question: '"ê³ ì–‘ì´ê°€ ì–´ë””ì— ìˆë‚˜ìš”?"',
                  answer: '"ì†ŒíŒŒ ìœ„ì—"',
                  difficulty: 'ì¤‘ê°„',
                  color: 'purple'
                },
                {
                  type: 'ì¶”ìƒì  ì¶”ë¡ ',
                  question: '"ì´ ì‚¬ëŒì˜ ê¸°ë¶„ì€ ì–´ë•Œ ë³´ì´ë‚˜ìš”?"',
                  answer: '"í–‰ë³µí•´ ë³´ì…ë‹ˆë‹¤"',
                  difficulty: 'ì–´ë ¤ì›€',
                  color: 'red'
                }
              ].map((example, idx) => (
                <div key={idx} className={`bg-${example.color}-50 dark:bg-${example.color}-900/20 rounded-xl p-4 border border-${example.color}-200 dark:border-${example.color}-800`}>
                  <div className={`inline-block px-2 py-1 rounded bg-${example.color}-500 text-white text-xs font-bold mb-2`}>
                    {example.type}
                  </div>
                  <p className="text-sm text-gray-700 dark:text-gray-300 mb-1">
                    <span className="font-semibold">Q:</span> {example.question}
                  </p>
                  <p className="text-sm text-gray-700 dark:text-gray-300 mb-2">
                    <span className="font-semibold">A:</span> {example.answer}
                  </p>
                  <p className={`text-xs text-${example.color}-700 dark:text-${example.color}-300`}>
                    ë‚œì´ë„: {example.difficulty}
                  </p>
                </div>
              ))}
            </div>

            <div className="bg-gray-50 dark:bg-gray-700/50 rounded-xl p-6">
              <h4 className="font-bold text-gray-900 dark:text-white mb-4">
                VQA ëª¨ë¸ ì•„í‚¤í…ì²˜
              </h4>
              <div className="space-y-4">
                {[
                  {
                    step: '1',
                    title: 'Image Encoding',
                    desc: 'ResNet/ViTë¡œ ì´ë¯¸ì§€ë¥¼ íŠ¹ì§• ë§µ ì¶”ì¶œ (ì˜ˆ: [196, 768] - 14Ã—14 íŒ¨ì¹˜)',
                    model: 'Vision Encoder'
                  },
                  {
                    step: '2',
                    title: 'Question Encoding',
                    desc: 'BERT/GPTë¡œ ì§ˆë¬¸ì„ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜ (ì˜ˆ: [seq_len, 768])',
                    model: 'Language Encoder'
                  },
                  {
                    step: '3',
                    title: 'Cross-Modal Fusion',
                    desc: 'ì§ˆë¬¸ ì„ë² ë”©ì´ ì´ë¯¸ì§€ íŠ¹ì§•ì— Cross-Attentioní•˜ì—¬ ê´€ë ¨ ì˜ì—­ ì§‘ì¤‘',
                    model: 'Attention Module'
                  },
                  {
                    step: '4',
                    title: 'Answer Generation',
                    desc: 'í†µí•© í‘œí˜„ì„ MLP ë˜ëŠ” Decoderë¡œ ì²˜ë¦¬í•˜ì—¬ ë‹µë³€ ìƒì„±',
                    model: 'Classification Head / Decoder'
                  }
                ].map((stage, idx) => (
                  <div key={idx} className="flex gap-4 items-start">
                    <div className="flex-shrink-0 w-10 h-10 rounded-lg bg-gradient-to-br from-violet-500 to-purple-600 flex items-center justify-center text-white font-bold">
                      {stage.step}
                    </div>
                    <div className="flex-1">
                      <div className="flex items-center gap-2 mb-1">
                        <p className="font-semibold text-gray-900 dark:text-white">{stage.title}</p>
                        <span className="text-xs text-gray-500 dark:text-gray-400">({stage.model})</span>
                      </div>
                      <p className="text-sm text-gray-600 dark:text-gray-400">{stage.desc}</p>
                    </div>
                  </div>
                ))}
              </div>
            </div>
          </div>

          <div className="grid md:grid-cols-2 gap-6">
            {[
              {
                model: 'BLIP (Salesforce, 2022)',
                description: 'Bootstrapping Language-Image Pre-training',
                features: [
                  'VQA, ì´ë¯¸ì§€ ìº¡ì…”ë‹, ê²€ìƒ‰ì„ ë‹¨ì¼ ëª¨ë¸ë¡œ',
                  'CapFiltë¡œ ë…¸ì´ì¦ˆ ë°ì´í„° ìë™ ì •ì œ',
                  'VQAv2ì—ì„œ 78.3% ì •í™•ë„'
                ],
                innovation: 'Unified Vision-Language Understanding',
                color: 'from-blue-500 to-cyan-500'
              },
              {
                model: 'GPT-4V (OpenAI, 2023)',
                description: 'Multimodal Large Language Model',
                features: [
                  'ë³µì¡í•œ ì¶”ë¡ ê³¼ ëŒ€í™”í˜• VQA',
                  'ì°¨íŠ¸, ë‹¤ì´ì–´ê·¸ë¨, ìˆ˜ì‹ ì´í•´',
                  'Few-shot í•™ìŠµìœ¼ë¡œ ìƒˆ íƒœìŠ¤í¬ ì ì‘'
                ],
                innovation: 'Human-level Visual Reasoning',
                color: 'from-purple-500 to-pink-500'
              }
            ].map((model, idx) => (
              <div
                key={idx}
                className="bg-white dark:bg-gray-800 rounded-xl p-6 shadow-lg"
              >
                <div className={`inline-flex p-3 rounded-lg bg-gradient-to-br ${model.color} text-white mb-4`}>
                  <Eye className="w-6 h-6" />
                </div>
                <h3 className="text-lg font-bold text-gray-900 dark:text-white mb-1">
                  {model.model}
                </h3>
                <p className="text-sm text-gray-600 dark:text-gray-400 mb-4">
                  {model.description}
                </p>
                <div className="bg-gray-50 dark:bg-gray-700/50 rounded-lg p-4 mb-3">
                  <p className="text-xs font-semibold text-gray-700 dark:text-gray-300 mb-2">ì£¼ìš” íŠ¹ì§•</p>
                  <ul className="space-y-1">
                    {model.features.map((feature, i) => (
                      <li key={i} className="text-sm text-gray-600 dark:text-gray-400 flex gap-2">
                        <span className="text-violet-600">â€¢</span>
                        <span>{feature}</span>
                      </li>
                    ))}
                  </ul>
                </div>
                <div className="bg-violet-50 dark:bg-violet-900/20 rounded-lg p-3 border-l-4 border-violet-500">
                  <p className="text-sm text-violet-900 dark:text-violet-100">
                    <span className="font-semibold">í˜ì‹ :</span> {model.innovation}
                  </p>
                </div>
              </div>
            ))}
          </div>
        </section>

        {/* Image Captioning */}
        <section className="mb-12 bg-white dark:bg-gray-800 rounded-2xl p-8 shadow-lg">
          <h2 className="text-2xl font-bold text-gray-900 dark:text-white mb-6 flex items-center gap-3">
            <ImageIcon className="w-6 h-6 text-violet-600" />
            ì´ë¯¸ì§€ ìº¡ì…”ë‹ (Image Captioning)
          </h2>

          <div className="space-y-6">
            <p className="text-gray-700 dark:text-gray-300">
              ì´ë¯¸ì§€ ìº¡ì…”ë‹ì€ ì´ë¯¸ì§€ë¥¼ ì…ë ¥ë°›ì•„ ìì—°ì–´ë¡œ ì„¤ëª…ì„ ìƒì„±í•˜ëŠ” íƒœìŠ¤í¬ì…ë‹ˆë‹¤.
              VQAì™€ ë‹¬ë¦¬ ì§ˆë¬¸ ì—†ì´ ì´ë¯¸ì§€ì˜ ì „ì²´ì ì¸ ë‚´ìš©ì„ ìë™ìœ¼ë¡œ ì„¤ëª…í•©ë‹ˆë‹¤.
            </p>

            <div className="bg-gray-50 dark:bg-gray-700/50 rounded-xl p-6">
              <h3 className="font-bold text-gray-900 dark:text-white mb-4">
                ì´ë¯¸ì§€ ìº¡ì…”ë‹ ì ‘ê·¼ë²• ë°œì „
              </h3>

              <div className="space-y-4">
                {[
                  {
                    generation: '1ì„¸ëŒ€ (2015)',
                    model: 'Show and Tell (Google)',
                    approach: 'CNN (Inception) + LSTM Decoder',
                    description: 'CNNìœ¼ë¡œ ì´ë¯¸ì§€ íŠ¹ì§• ì¶”ì¶œ í›„ LSTMì´ ë‹¨ì–´ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ìƒì„±',
                    limitation: 'ë‹¨ìˆœí•œ ë¬¸ì¥, ë°˜ë³µì  í‘œí˜„',
                    color: 'blue'
                  },
                  {
                    generation: '2ì„¸ëŒ€ (2017)',
                    model: 'Show, Attend and Tell',
                    approach: 'CNN + Attention + LSTM',
                    description: 'ë§¤ ë‹¨ì–´ ìƒì„± ì‹œ ì´ë¯¸ì§€ì˜ ê´€ë ¨ ì˜ì—­ì— Attentioní•˜ì—¬ ë””í…Œì¼ í–¥ìƒ',
                    limitation: 'ì—¬ì „íˆ RNN ê¸°ë°˜ìœ¼ë¡œ ê¸´ ë¬¸ì¥ì— ì•½í•¨',
                    color: 'purple'
                  },
                  {
                    generation: '3ì„¸ëŒ€ (2020+)',
                    model: 'Transformer Captioning (COCO, Oscar)',
                    approach: 'ViT + GPT-style Decoder',
                    description: 'Transformerë¡œ ë³‘ë ¬ ì²˜ë¦¬, Self-Attentionìœ¼ë¡œ ë¬¸ë§¥ ì¼ê´€ì„± í–¥ìƒ',
                    limitation: 'ëŒ€ê·œëª¨ ë°ì´í„°ì™€ ê³„ì‚° ìì› í•„ìš”',
                    color: 'green'
                  },
                  {
                    generation: '4ì„¸ëŒ€ (2022+)',
                    model: 'BLIP, GIT (Generative Image-to-text)',
                    approach: 'Unified VLP + Auto-regressive Decoder',
                    description: 'ìº¡ì…”ë‹, VQA, ê²€ìƒ‰ì„ ë‹¨ì¼ ëª¨ë¸ë¡œ í†µí•©, ë…¸ì´ì¦ˆ ë°ì´í„° ìë™ ì •ì œ',
                    limitation: 'í™˜ê°(Hallucination) ë¬¸ì œ ì—¬ì „íˆ ì¡´ì¬',
                    color: 'orange'
                  }
                ].map((gen, idx) => (
                  <div key={idx} className={`bg-${gen.color}-50 dark:bg-${gen.color}-900/20 rounded-lg p-5 border-l-4 border-${gen.color}-500`}>
                    <div className="flex items-center gap-3 mb-2">
                      <div className={`w-8 h-8 rounded-full bg-${gen.color}-500 text-white flex items-center justify-center font-bold text-sm`}>
                        {idx + 1}
                      </div>
                      <div>
                        <p className="font-bold text-gray-900 dark:text-white">{gen.generation}</p>
                        <p className="text-sm text-gray-600 dark:text-gray-400">{gen.model}</p>
                      </div>
                    </div>
                    <p className="text-sm text-gray-700 dark:text-gray-300 mb-2">
                      <span className="font-semibold">ì ‘ê·¼ë²•:</span> {gen.approach}
                    </p>
                    <p className="text-sm text-gray-700 dark:text-gray-300 mb-2">
                      {gen.description}
                    </p>
                    <p className="text-xs text-gray-500 dark:text-gray-400">
                      <span className="font-semibold">í•œê³„:</span> {gen.limitation}
                    </p>
                  </div>
                ))}
              </div>
            </div>

            <div className="bg-violet-50 dark:bg-violet-900/20 rounded-xl p-6 border border-violet-200 dark:border-violet-800">
              <h4 className="font-bold text-violet-900 dark:text-violet-100 mb-3">
                ğŸ’» ê°„ë‹¨í•œ ìº¡ì…”ë‹ ì½”ë“œ (BLIP)
              </h4>
              <div className="bg-gray-900 rounded-lg p-6 overflow-x-auto">
                <pre className="text-sm text-gray-100">
{`from transformers import BlipProcessor, BlipForConditionalGeneration
from PIL import Image

# ëª¨ë¸ê³¼ í”„ë¡œì„¸ì„œ ë¡œë“œ
processor = BlipProcessor.from_pretrained("Salesforce/blip-image-captioning-base")
model = BlipForConditionalGeneration.from_pretrained("Salesforce/blip-image-captioning-base")

# ì´ë¯¸ì§€ ë¡œë“œ
image = Image.open("photo.jpg")

# ìº¡ì…˜ ìƒì„±
inputs = processor(image, return_tensors="pt")
out = model.generate(**inputs, max_length=50)
caption = processor.decode(out[0], skip_special_tokens=True)

print(caption)  # "A dog sitting on a bench in a park"`}
                </pre>
              </div>
            </div>

            <div className="grid md:grid-cols-2 gap-6">
              <div className="bg-green-50 dark:bg-green-900/20 rounded-xl p-5 border border-green-200 dark:border-green-800">
                <h4 className="font-bold text-green-900 dark:text-green-100 mb-3">
                  âœ… ì‘ìš© ë¶„ì•¼
                </h4>
                <ul className="space-y-2 text-green-800 dark:text-green-200">
                  <li className="flex gap-2">
                    <span>â€¢</span>
                    <span>ì‹œê° ì¥ì• ì¸ì„ ìœ„í•œ ì´ë¯¸ì§€ ì„¤ëª… (Accessibility)</span>
                  </li>
                  <li className="flex gap-2">
                    <span>â€¢</span>
                    <span>ì†Œì…œ ë¯¸ë””ì–´ ìë™ íƒœê¹… (Instagram, Pinterest)</span>
                  </li>
                  <li className="flex gap-2">
                    <span>â€¢</span>
                    <span>ì˜ë£Œ ì˜ìƒ ë¦¬í¬íŠ¸ ìë™ ìƒì„±</span>
                  </li>
                  <li className="flex gap-2">
                    <span>â€¢</span>
                    <span>ë¡œë´‡ì˜ í™˜ê²½ ì´í•´ ë° ì„¤ëª…</span>
                  </li>
                </ul>
              </div>

              <div className="bg-amber-50 dark:bg-amber-900/20 rounded-xl p-5 border border-amber-200 dark:border-amber-800">
                <h4 className="font-bold text-amber-900 dark:text-amber-100 mb-3">
                  âš ï¸ ì£¼ìš” ë„ì „ ê³¼ì œ
                </h4>
                <ul className="space-y-2 text-amber-800 dark:text-amber-200">
                  <li className="flex gap-2">
                    <span>â€¢</span>
                    <span>í™˜ê°(Hallucination): ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ê°ì²´ ìƒì„±</span>
                  </li>
                  <li className="flex gap-2">
                    <span>â€¢</span>
                    <span>í¸í–¥(Bias): í•™ìŠµ ë°ì´í„°ì˜ ê³ ì •ê´€ë… ë°˜ì˜</span>
                  </li>
                  <li className="flex gap-2">
                    <span>â€¢</span>
                    <span>ë””í…Œì¼ ë¶€ì¡±: "ì‚¬ëŒì´ ìˆë‹¤" vs "30ëŒ€ ë‚¨ì„±ì´ ì •ì¥ ì…ê³ "</span>
                  </li>
                  <li className="flex gap-2">
                    <span>â€¢</span>
                    <span>í‰ê°€ ì–´ë ¤ì›€: BLEU/CIDEr ì ìˆ˜ê°€ ì¸ê°„ í‰ê°€ì™€ ë¶ˆì¼ì¹˜</span>
                  </li>
                </ul>
              </div>
            </div>
          </div>
        </section>

        {/* Video Understanding */}
        <section className="mb-12">
          <h2 className="text-2xl font-bold text-gray-900 dark:text-white mb-6 flex items-center gap-3">
            <Film className="w-6 h-6 text-violet-600" />
            ë¹„ë””ì˜¤ ì´í•´ (Video Understanding)
          </h2>

          <div className="bg-white dark:bg-gray-800 rounded-2xl p-8 shadow-lg mb-6">
            <h3 className="text-xl font-bold text-gray-900 dark:text-white mb-4">
              ë¹„ë””ì˜¤ ì´í•´ì˜ íŠ¹ìˆ˜ì„±
            </h3>
            <p className="text-gray-700 dark:text-gray-300 mb-6">
              ë¹„ë””ì˜¤ëŠ” ì´ë¯¸ì§€ì™€ ë‹¬ë¦¬ ì‹œê°„ì  ì°¨ì›(Temporal Dimension)ì„ ê°€ì§‘ë‹ˆë‹¤.
              ë‹¨ìˆœíˆ í”„ë ˆì„ì„ ë…ë¦½ì ìœ¼ë¡œ ë¶„ì„í•˜ëŠ” ê²ƒì„ ë„˜ì–´,
              í”„ë ˆì„ ê°„ì˜ <strong>ì‹œê°„ì  ê´€ê³„</strong>ì™€ <strong>ë™ì‘(Motion)</strong>ì„ ì´í•´í•´ì•¼ í•©ë‹ˆë‹¤.
            </p>

            <div className="grid md:grid-cols-3 gap-4 mb-6">
              {[
                {
                  task: 'Action Recognition',
                  description: 'ë¹„ë””ì˜¤ì—ì„œ í–‰ë™ ë¶„ë¥˜',
                  example: '"ë‹¬ë¦¬ê¸°", "ì í”„", "ì¶¤ì¶”ê¸°"',
                  model: 'I3D, TimeSformer',
                  color: 'blue'
                },
                {
                  task: 'Video Captioning',
                  description: 'ë¹„ë””ì˜¤ ì „ì²´ë¥¼ ì„¤ëª…',
                  example: '"ë‚¨ìê°€ ê³µì„ ì°¨ì„œ ê³¨ì„ ë„£ê³  ìˆë‹¤"',
                  model: 'VideoBERT, VIOLET',
                  color: 'purple'
                },
                {
                  task: 'Temporal Grounding',
                  description: 'ì§ˆë¬¸ì— í•´ë‹¹í•˜ëŠ” ì‹œê°„ êµ¬ê°„ ì°¾ê¸°',
                  example: 'Q: "ì–¸ì œ ê³ ì–‘ì´ê°€ ì í”„í–ˆë‚˜ìš”?" â†’ 3.2s-5.1s',
                  model: 'Moment-DETR',
                  color: 'green'
                }
              ].map((task, idx) => (
                <div key={idx} className={`bg-${task.color}-50 dark:bg-${task.color}-900/20 rounded-xl p-4 border border-${task.color}-200 dark:border-${task.color}-800`}>
                  <div className={`inline-block px-3 py-1 rounded-full bg-${task.color}-500 text-white text-xs font-bold mb-3`}>
                    {task.task}
                  </div>
                  <p className="text-sm text-gray-700 dark:text-gray-300 mb-2">
                    {task.description}
                  </p>
                  <div className="bg-white dark:bg-gray-800 rounded p-2 mb-2">
                    <p className="text-xs text-gray-600 dark:text-gray-400 italic">
                      {task.example}
                    </p>
                  </div>
                  <p className="text-xs text-gray-500 dark:text-gray-400">
                    <span className="font-semibold">ëª¨ë¸:</span> {task.model}
                  </p>
                </div>
              ))}
            </div>

            <div className="bg-gray-50 dark:bg-gray-700/50 rounded-xl p-6">
              <h4 className="font-bold text-gray-900 dark:text-white mb-4">
                ë¹„ë””ì˜¤ ì²˜ë¦¬ ì•„í‚¤í…ì²˜ ë°œì „
              </h4>
              <div className="space-y-4">
                {[
                  {
                    approach: '2D CNN + Temporal Pooling',
                    description: 'ê° í”„ë ˆì„ì„ ë…ë¦½ì ìœ¼ë¡œ ì²˜ë¦¬ í›„ í‰ê· /ìµœëŒ€ í’€ë§',
                    limitation: 'ì‹œê°„ì  ê´€ê³„ ë¬´ì‹œ',
                    example: 'Two-Stream Networks'
                  },
                  {
                    approach: '3D CNN',
                    description: 'ê³µê°„ê³¼ ì‹œê°„ì„ ë™ì‹œì— ì»¨ë³¼ë£¨ì…˜ (3D ì»¤ë„)',
                    limitation: 'ê³„ì‚°ëŸ‰ í­ì¦ (O(TÃ—HÃ—W))',
                    example: 'C3D, I3D'
                  },
                  {
                    approach: 'RNN/LSTM',
                    description: 'í”„ë ˆì„ ì‹œí€€ìŠ¤ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì²˜ë¦¬',
                    limitation: 'ê¸´ ë¹„ë””ì˜¤ì—ì„œ vanishing gradient',
                    example: 'LRCN'
                  },
                  {
                    approach: 'Video Transformer',
                    description: 'Self-Attentionìœ¼ë¡œ í”„ë ˆì„ ê°„ ê´€ê³„ í•™ìŠµ',
                    limitation: 'O(TÂ²) ë³µì¡ë„ë¡œ ë©”ëª¨ë¦¬ ë¶€ë‹´',
                    example: 'TimeSformer, ViViT, VideoMAE'
                  }
                ].map((arch, idx) => (
                  <div key={idx} className="flex gap-3 items-start">
                    <div className="flex-shrink-0 w-8 h-8 rounded-lg bg-gradient-to-br from-violet-500 to-purple-600 flex items-center justify-center text-white font-bold">
                      {idx + 1}
                    </div>
                    <div className="flex-1">
                      <p className="font-semibold text-gray-900 dark:text-white mb-1">{arch.approach}</p>
                      <p className="text-sm text-gray-600 dark:text-gray-400 mb-1">{arch.description}</p>
                      <p className="text-xs text-red-600 dark:text-red-400 mb-1">
                        <span className="font-semibold">í•œê³„:</span> {arch.limitation}
                      </p>
                      <p className="text-xs text-violet-700 dark:text-violet-300">
                        <span className="font-semibold">ì˜ˆì‹œ:</span> {arch.example}
                      </p>
                    </div>
                  </div>
                ))}
              </div>
            </div>
          </div>

          <div className="grid gap-6">
            {[
              {
                application: 'YouTube ì½˜í…ì¸  ì¶”ì²œ',
                description: 'ë¹„ë””ì˜¤ ë‚´ìš©ì„ ì´í•´í•˜ì—¬ ê´€ë ¨ ì½˜í…ì¸  ì¶”ì²œ',
                tech: 'Video Embeddings + Collaborative Filtering',
                impact: 'ì‹œì²­ ì‹œê°„ 20% ì¦ê°€, ì‚¬ìš©ì ë§Œì¡±ë„ í–¥ìƒ',
                metric: 'ì¼ì¼ 10ì–µ+ ë¹„ë””ì˜¤ ì²˜ë¦¬',
                color: 'from-blue-500 to-cyan-500'
              },
              {
                application: 'ìŠ¤í¬ì¸  í•˜ì´ë¼ì´íŠ¸ ìë™ ìƒì„±',
                description: 'ì¶•êµ¬ ê²½ê¸°ì—ì„œ ê³¨, íŒŒìš¸ ë“± ì£¼ìš” ì¥ë©´ ìë™ ì¶”ì¶œ',
                tech: 'Action Detection + Temporal Segmentation',
                impact: 'í¸ì§‘ ì‹œê°„ 90% ë‹¨ì¶•, ì‹¤ì‹œê°„ í•˜ì´ë¼ì´íŠ¸',
                metric: 'ESPN, NBA ë“± ì£¼ìš” ìŠ¤í¬ì¸  ë¦¬ê·¸ ì±„íƒ',
                color: 'from-purple-500 to-pink-500'
              },
              {
                application: 'ë³´ì•ˆ ê°ì‹œ ì‹œìŠ¤í…œ',
                description: 'ì´ìƒ í–‰ë™ ìë™ íƒì§€ (ì¹¨ì…, í­ë ¥, ì‚¬ê³ )',
                tech: 'Anomaly Detection + Real-time Alerting',
                impact: 'ë³´ì•ˆ ìš”ì› ì—…ë¬´ íš¨ìœ¨ 2ë°°, ì˜¤íƒë¥  50% ê°ì†Œ',
                metric: 'ê³µí•­, ì§€í•˜ì² , ì‡¼í•‘ëª° ë“± ëŒ€ê·œëª¨ ë°°ì¹˜',
                color: 'from-green-500 to-emerald-500'
              },
              {
                application: 'ì˜ë£Œ: ìˆ˜ìˆ  ë¹„ë””ì˜¤ ë¶„ì„',
                description: 'ìˆ˜ìˆ  ë‹¨ê³„ ìë™ ì¸ì‹ ë° ìœ„í—˜ ìƒí™© ê²½ê³ ',
                tech: 'Surgical Workflow Recognition + Phase Detection',
                impact: 'ìˆ˜ìˆ  ì‹œê°„ 15% ë‹¨ì¶•, í•©ë³‘ì¦ 20% ê°ì†Œ',
                metric: 'Johns Hopkins ë“± ì£¼ìš” ë³‘ì› ì„ìƒ ì‹œí—˜',
                color: 'from-orange-500 to-red-500'
              }
            ].map((app, idx) => (
              <div
                key={idx}
                className="bg-white dark:bg-gray-800 rounded-xl p-6 shadow-lg hover:shadow-xl transition-shadow"
              >
                <div className="flex items-start gap-4">
                  <div className={`flex-shrink-0 w-12 h-12 rounded-lg bg-gradient-to-br ${app.color} flex items-center justify-center text-white font-bold text-xl`}>
                    {idx + 1}
                  </div>
                  <div className="flex-1">
                    <h3 className="text-xl font-bold text-gray-900 dark:text-white mb-2">
                      {app.application}
                    </h3>
                    <p className="text-gray-600 dark:text-gray-400 mb-3">
                      {app.description}
                    </p>
                    <div className="space-y-2">
                      <div className="bg-gray-50 dark:bg-gray-700/50 rounded-lg p-3">
                        <p className="text-sm text-gray-700 dark:text-gray-300">
                          <span className="font-semibold">ê¸°ìˆ :</span> {app.tech}
                        </p>
                      </div>
                      <div className="bg-blue-50 dark:bg-blue-900/20 rounded-lg p-3">
                        <p className="text-sm text-blue-900 dark:text-blue-100">
                          <span className="font-semibold">ì˜í–¥:</span> {app.impact}
                        </p>
                      </div>
                      <div className="bg-violet-50 dark:bg-violet-900/20 rounded-lg p-3 border-l-4 border-violet-500">
                        <p className="text-sm text-violet-900 dark:text-violet-100">
                          <span className="font-semibold">ê·œëª¨:</span> {app.metric}
                        </p>
                      </div>
                    </div>
                  </div>
                </div>
              </div>
            ))}
          </div>
        </section>

        {/* Future Trends */}
        <section className="mb-12 bg-gradient-to-br from-cyan-50 to-blue-50 dark:from-cyan-900/20 dark:to-blue-900/20 rounded-2xl p-8 border border-cyan-200 dark:border-cyan-800">
          <h2 className="text-2xl font-bold text-gray-900 dark:text-white mb-6 flex items-center gap-3">
            <TrendingUp className="w-6 h-6 text-cyan-600" />
            ë¯¸ë˜ íŠ¸ë Œë“œ ë° ì—°êµ¬ ë°©í–¥
          </h2>

          <div className="space-y-4">
            {[
              {
                trend: 'Embodied AI',
                description: 'ë¡œë´‡ì´ ë¬¼ë¦¬ ì„¸ê³„ì—ì„œ ë©€í‹°ëª¨ë‹¬ ì…ë ¥(ì¹´ë©”ë¼, ì„¼ì„œ, ìŒì„±)ì„ í†µí•©í•˜ì—¬ í–‰ë™ ê²°ì •',
                impact: 'ììœ¨ì£¼í–‰, ê°€ì •ìš© ë¡œë´‡, ì°½ê³  ìë™í™”'
              },
              {
                trend: 'Unified Multi-Task Models',
                description: 'ë‹¨ì¼ ëª¨ë¸ì´ VQA, ìº¡ì…”ë‹, ê²€ìƒ‰, ìƒì„±ì„ ëª¨ë‘ ìˆ˜í–‰ (ì˜ˆ: Unified-IO, Flamingo)',
                impact: 'ë²”ìš© ë©€í‹°ëª¨ë‹¬ AI ì—ì´ì „íŠ¸ íƒ„ìƒ'
              },
              {
                trend: 'Zero-Shot Generalization',
                description: 'í•™ìŠµ ë°ì´í„° ì—†ì´ë„ ìƒˆë¡œìš´ ëª¨ë‹¬ë¦¬í‹° ì¡°í•© ì²˜ë¦¬ (ì˜ˆ: 3D â†’ Text, Audio â†’ 3D)',
                impact: 'ë°ì´í„° ë¶€ì¡± ì˜ì—­ ëŒíŒŒêµ¬'
              },
              {
                trend: 'Multimodal Chain-of-Thought',
                description: 'LLMì˜ ì‚¬ê³  ì—°ì‡„ë¥¼ ë©€í‹°ëª¨ë‹¬ë¡œ í™•ì¥í•˜ì—¬ ë³µì¡í•œ ì¶”ë¡  ê°€ëŠ¥',
                impact: 'ì˜ë£Œ ì§„ë‹¨, ê³¼í•™ ì—°êµ¬, ë²•ë¥  ë¶„ì„'
              },
              {
                trend: 'Efficient Multimodal Models',
                description: 'ëª¨ë°”ì¼/ì—£ì§€ ë””ë°”ì´ìŠ¤ì—ì„œ ì‹¤í–‰ ê°€ëŠ¥í•œ ê²½ëŸ‰ ë©€í‹°ëª¨ë‹¬ ëª¨ë¸',
                impact: 'AR ê¸€ë˜ìŠ¤, ìŠ¤ë§ˆíŠ¸ì›Œì¹˜, IoT ë””ë°”ì´ìŠ¤'
              }
            ].map((item, idx) => (
              <div key={idx} className="bg-white dark:bg-gray-800 rounded-lg p-5 shadow">
                <div className="flex items-start gap-3">
                  <div className="flex-shrink-0 w-8 h-8 rounded-full bg-gradient-to-br from-cyan-500 to-blue-500 text-white flex items-center justify-center font-bold">
                    {idx + 1}
                  </div>
                  <div className="flex-1">
                    <h4 className="font-bold text-gray-900 dark:text-white mb-2">
                      {item.trend}
                    </h4>
                    <p className="text-sm text-gray-600 dark:text-gray-400 mb-2">
                      {item.description}
                    </p>
                    <div className="bg-cyan-50 dark:bg-cyan-900/20 rounded p-2">
                      <p className="text-xs text-cyan-900 dark:text-cyan-100">
                        <span className="font-semibold">ì˜í–¥:</span> {item.impact}
                      </p>
                    </div>
                  </div>
                </div>
              </div>
            ))}
          </div>
        </section>

        {/* í•™ìŠµ ëª©í‘œ ìš”ì•½ */}
        <section className="bg-gradient-to-br from-violet-600 to-purple-600 rounded-2xl p-8 text-white">
          <h2 className="text-2xl font-bold mb-6">ğŸ“š ì´ ì±•í„°ì—ì„œ ë°°ìš´ ë‚´ìš©</h2>
          <ul className="space-y-3">
            {[
              'VQA: ì´ë¯¸ì§€+ì§ˆë¬¸ â†’ ë‹µë³€ ìƒì„± (BLIP, GPT-4V)',
              'VQA ì•„í‚¤í…ì²˜: Image Encoding + Question Encoding + Cross-Modal Fusion',
              'ì´ë¯¸ì§€ ìº¡ì…”ë‹: CNN+LSTM â†’ Attention â†’ Transformer â†’ Unified VLP',
              'ì´ë¯¸ì§€ ìº¡ì…”ë‹ ì‘ìš©: ì‹œê° ì¥ì• ì¸ ì§€ì›, ì˜ë£Œ ë¦¬í¬íŠ¸ ìë™ ìƒì„±',
              'ë¹„ë””ì˜¤ ì´í•´: Action Recognition, Video Captioning, Temporal Grounding',
              'ë¹„ë””ì˜¤ ì²˜ë¦¬: 2D CNN â†’ 3D CNN â†’ RNN â†’ Video Transformer',
              'ì‹¤ì „ ì‘ìš©: YouTube ì¶”ì²œ, ìŠ¤í¬ì¸  í•˜ì´ë¼ì´íŠ¸, ë³´ì•ˆ ê°ì‹œ, ìˆ˜ìˆ  ë¶„ì„',
              'ë¯¸ë˜ íŠ¸ë Œë“œ: Embodied AI, Unified Models, Zero-Shot, Chain-of-Thought'
            ].map((item, idx) => (
              <li key={idx} className="flex items-start gap-3">
                <span className="text-violet-200 mt-1">âœ“</span>
                <span>{item}</span>
              </li>
            ))}
          </ul>

          <div className="mt-8 pt-6 border-t border-violet-400">
            <p className="text-violet-100 mb-4">
              <span className="font-semibold">ì¶•í•˜í•©ë‹ˆë‹¤!</span> ë©€í‹°ëª¨ë‹¬ AI ì‹œìŠ¤í…œì˜ ì „ì²´ ì—¬ì •ì„ ì™„ì£¼í•˜ì…¨ìŠµë‹ˆë‹¤.
            </p>
            <p className="text-violet-100">
              ì´ì œ ë©€í‹°ëª¨ë‹¬ AIì˜ ê¸°ë³¸ ê°œë…ë¶€í„° ìµœì‹  ëª¨ë¸, ì‹¤ì‹œê°„ ë°°í¬, ì‹¤ì „ ì‘ìš©ê¹Œì§€
              ì²´ê³„ì ìœ¼ë¡œ ì´í•´í•˜ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ ì§€ì‹ì„ ë°”íƒ•ìœ¼ë¡œ í˜ì‹ ì ì¸ ë©€í‹°ëª¨ë‹¬ AI í”„ë¡œì íŠ¸ë¥¼ ì‹œì‘í•´ë³´ì„¸ìš”!
            </p>
          </div>
        </section>

        {/* References */}
        <References
          sections={[
            {
              title: 'ğŸ“š ê³µì‹ ë¬¸ì„œ & í”Œë«í¼',
              icon: 'web' as const,
              color: 'border-purple-500',
              items: [
                {
                  title: 'OpenAI Vision API',
                  authors: 'OpenAI',
                  year: '2024',
                  description: 'GPT-4V API ê³µì‹ ë¬¸ì„œ - VQAì™€ ì´ë¯¸ì§€ ìº¡ì…”ë‹ ì‹¤ì „ êµ¬í˜„',
                  link: 'https://platform.openai.com/docs/guides/vision'
                },
                {
                  title: 'Google Gemini Multimodal',
                  authors: 'Google DeepMind',
                  year: '2024',
                  description: 'Gemini ë©€í‹°ëª¨ë‹¬ ê¸°ëŠ¥ ê°€ì´ë“œ - í…ìŠ¤íŠ¸, ì´ë¯¸ì§€, ë¹„ë””ì˜¤ í†µí•© ì²˜ë¦¬',
                  link: 'https://ai.google.dev/gemini-api/docs/vision'
                },
                {
                  title: 'Anthropic Claude Vision',
                  authors: 'Anthropic',
                  year: '2024',
                  description: 'Claude 3ì˜ Vision ê¸°ëŠ¥ - ì°¨íŠ¸, ë‹¤ì´ì–´ê·¸ë¨, ì´ë¯¸ì§€ ë¶„ì„',
                  link: 'https://docs.anthropic.com/claude/docs/vision'
                },
                {
                  title: 'Meta AI Multimodal',
                  authors: 'Meta',
                  year: '2024',
                  description: 'ImageBind, SAM, CLIP í†µí•© í”Œë«í¼',
                  link: 'https://ai.meta.com/blog/imagebind-six-modalities-binding-ai/'
                },
                {
                  title: 'Hugging Face Multimodal',
                  authors: 'Hugging Face',
                  year: '2024',
                  description: 'BLIP, CLIP, ViT ë“± ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ í†µí•© ë¼ì´ë¸ŒëŸ¬ë¦¬',
                  link: 'https://huggingface.co/docs/transformers/tasks/image_text_to_text'
                }
              ]
            },
            {
              title: 'ğŸ“– í•µì‹¬ ë…¼ë¬¸',
              icon: 'research' as const,
              color: 'border-purple-500',
              items: [
                {
                  title: 'CLIP: Connecting Text and Images',
                  authors: 'Radford et al.',
                  year: '2021',
                  description: 'Contrastive Learningìœ¼ë¡œ í…ìŠ¤íŠ¸-ì´ë¯¸ì§€ ì •ë ¬ - ë©€í‹°ëª¨ë‹¬ AIì˜ ê¸°ì´ˆ',
                  link: 'https://arxiv.org/abs/2103.00020'
                },
                {
                  title: 'Hierarchical Text-Conditional Image Generation with CLIP Latents (DALL-E 2)',
                  authors: 'Ramesh et al.',
                  year: '2022',
                  description: 'Diffusion Model ê¸°ë°˜ Text-to-Image ìƒì„±',
                  link: 'https://arxiv.org/abs/2204.06125'
                },
                {
                  title: 'Flamingo: a Visual Language Model for Few-Shot Learning',
                  authors: 'Alayrac et al.',
                  year: '2022',
                  description: 'Few-shot ë©€í‹°ëª¨ë‹¬ í•™ìŠµì˜ íšê¸°ì  ì§„ì „',
                  link: 'https://arxiv.org/abs/2204.14198'
                },
                {
                  title: 'GPT-4 Technical Report',
                  authors: 'OpenAI',
                  year: '2023',
                  description: 'GPT-4Vì˜ ë©€í‹°ëª¨ë‹¬ ëŠ¥ë ¥ - ì°¨íŠ¸, ìˆ˜ì‹, ë³µì¡í•œ ì¶”ë¡ ',
                  link: 'https://arxiv.org/abs/2303.08774'
                }
              ]
            },
            {
              title: 'ğŸ› ï¸ ì‹¤ì „ ë„êµ¬',
              icon: 'tools' as const,
              color: 'border-purple-500',
              items: [
                {
                  title: 'Hugging Face Transformers (Multimodal)',
                  authors: 'Hugging Face',
                  year: '2024',
                  description: 'BLIP, CLIP, ViT í†µí•© ë¼ì´ë¸ŒëŸ¬ë¦¬ - VQAì™€ ìº¡ì…”ë‹ ë¹ ë¥¸ êµ¬í˜„',
                  link: 'https://huggingface.co/docs/transformers/index'
                },
                {
                  title: 'LangChain Multimodal',
                  authors: 'LangChain',
                  year: '2024',
                  description: 'GPT-4V, Gemini Vision í†µí•© - ë©€í‹°ëª¨ë‹¬ ì²´ì¸ êµ¬ì¶•',
                  link: 'https://python.langchain.com/docs/integrations/chat/openai#multimodal-inputs'
                },
                {
                  title: 'LlamaIndex Multimodal',
                  authors: 'LlamaIndex',
                  year: '2024',
                  description: 'ë©€í‹°ëª¨ë‹¬ RAG - ì´ë¯¸ì§€/ë¹„ë””ì˜¤ ê²€ìƒ‰ ë° ì§ˆì˜ì‘ë‹µ',
                  link: 'https://docs.llamaindex.ai/en/stable/examples/multi_modal/'
                },
                {
                  title: 'OpenCLIP',
                  authors: 'laion-ai',
                  year: '2024',
                  description: 'CLIP ì˜¤í”ˆì†ŒìŠ¤ êµ¬í˜„ - ë‹¤ì–‘í•œ í¬ê¸°ì™€ í•™ìŠµ ë°ì´í„°ì…‹',
                  link: 'https://github.com/mlfoundations/open_clip'
                },
                {
                  title: 'Video-LLaVA',
                  authors: 'PKU-YuanGroup',
                  year: '2024',
                  description: 'ë¹„ë””ì˜¤ ì´í•´ ì˜¤í”ˆì†ŒìŠ¤ ëª¨ë¸ - Video QA, Captioning',
                  link: 'https://github.com/PKU-YuanGroup/Video-LLaVA'
                }
              ]
            }
          ]}
        />
      </div>
    </div>
  )
}

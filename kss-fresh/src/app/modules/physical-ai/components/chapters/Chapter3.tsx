'use client';

import React from 'react';
import { Eye, Camera, Layers, Zap, Maximize, Grid3x3, Box } from 'lucide-react';

export default function Chapter3() {
  return (
    <div className="prose prose-lg dark:prose-invert max-w-none">
      {/* Hero Section */}
      <div className="bg-gradient-to-r from-teal-50 to-cyan-50 dark:from-teal-900/20 dark:to-cyan-900/20 rounded-2xl p-8 mb-8 border border-teal-200 dark:border-teal-800">
        <div className="flex items-center gap-4 mb-4">
          <div className="w-12 h-12 bg-teal-500 rounded-xl flex items-center justify-center">
            <Eye className="w-6 h-6 text-white" />
          </div>
          <h1 className="text-3xl font-bold text-gray-900 dark:text-white m-0">ì»´í“¨í„° ë¹„ì „ê³¼ ì¸ì‹ ì‹œìŠ¤í…œ</h1>
        </div>
        <p className="text-xl text-gray-700 dark:text-gray-300 m-0">
          ë¡œë´‡ì˜ ëˆˆ - í˜„ì‹¤ ì„¸ê³„ë¥¼ ì´í•´í•˜ëŠ” AIì˜ ì‹œê° ëŠ¥ë ¥
        </p>
      </div>

      {/* Introduction */}
      <section className="my-8">
        <h2 className="flex items-center gap-2">
          <Camera className="text-teal-600" />
          Physical AIì—ì„œ ì»´í“¨í„° ë¹„ì „ì˜ ì¤‘ìš”ì„±
        </h2>

        <div className="bg-gradient-to-r from-teal-50 to-blue-50 dark:from-teal-900/20 dark:to-blue-900/20 p-6 rounded-lg border-l-4 border-teal-500 mb-6">
          <h3 className="text-xl font-bold mb-4">ğŸ‘ï¸ ì¸ê°„ì˜ 80%ëŠ” ì‹œê° ì •ë³´</h3>
          <p className="mb-4">
            ì¸ê°„ì´ ì„¸ìƒì„ ì´í•´í•˜ëŠ” ì •ë³´ì˜ <strong>80%ê°€ ì‹œê°</strong>ì—ì„œ ì˜µë‹ˆë‹¤.
            Physical AIë„ ë§ˆì°¬ê°€ì§€ì…ë‹ˆë‹¤. ë¡œë´‡ì´ ë¬¼ì²´ë¥¼ ì¡ê³ , ì¥ì• ë¬¼ì„ í”¼í•˜ê³ ,
            ì‚¬ëŒê³¼ í˜‘ì—…í•˜ë ¤ë©´ <strong>ì •í™•í•˜ê³  ë¹ ë¥¸ ì‹œê° ì¸ì‹</strong>ì´ í•„ìˆ˜ì…ë‹ˆë‹¤.
          </p>

          <div className="grid md:grid-cols-3 gap-4">
            <div className="bg-white dark:bg-gray-800 p-4 rounded-lg text-center">
              <div className="text-3xl mb-2">ğŸ¯</div>
              <h4 className="font-bold text-sm mb-2">ê°ì²´ íƒì§€</h4>
              <p className="text-xs">What: ë¬´ì—‡ì´ ìˆëŠ”ê°€?</p>
            </div>
            <div className="bg-white dark:bg-gray-800 p-4 rounded-lg text-center">
              <div className="text-3xl mb-2">ğŸ“</div>
              <h4 className="font-bold text-sm mb-2">ìœ„ì¹˜ ì¶”ì •</h4>
              <p className="text-xs">Where: ì–´ë””ì— ìˆëŠ”ê°€?</p>
            </div>
            <div className="bg-white dark:bg-gray-800 p-4 rounded-lg text-center">
              <div className="text-3xl mb-2">ğŸ“</div>
              <h4 className="font-bold text-sm mb-2">ê¹Šì´ ì¸ì‹</h4>
              <p className="text-xs">How far: ì–¼ë§ˆë‚˜ ë©€ë¦¬?</p>
            </div>
          </div>
        </div>
      </section>

      {/* 1. Real-time Object Detection */}
      <section className="my-8">
        <h2 className="flex items-center gap-2">
          <Box className="text-blue-600" />
          1. ì‹¤ì‹œê°„ ê°ì²´ íƒì§€ (Object Detection)
        </h2>

        <div className="bg-white dark:bg-gray-800 rounded-lg p-6 shadow-lg mb-6">
          <h3 className="text-xl font-bold mb-4">ğŸ¯ YOLO (You Only Look Once) - ì‹¤ì‹œê°„ íƒì§€ì˜ ì •ì„</h3>

          <div className="bg-blue-50 dark:bg-blue-900/20 p-5 rounded-lg mb-6">
            <h4 className="font-bold mb-3">ì™œ YOLOì¸ê°€?</h4>
            <div className="grid md:grid-cols-2 gap-4">
              <div>
                <h5 className="font-bold text-sm mb-2 text-blue-600">ì „í†µì  ë°©ì‹ (R-CNN)</h5>
                <ul className="text-sm space-y-1">
                  <li>âŒ ì†ë„: ì´ˆë‹¹ 5-10 í”„ë ˆì„</li>
                  <li>âŒ ì²˜ë¦¬: ì˜ì—­ ì œì•ˆ â†’ ë¶„ë¥˜ (2ë‹¨ê³„)</li>
                  <li>âŒ ì‹¤ì‹œê°„ ë¶ˆê°€ëŠ¥</li>
                </ul>
              </div>
              <div className="border-l-2 border-blue-300 pl-4">
                <h5 className="font-bold text-sm mb-2 text-green-600">YOLO</h5>
                <ul className="text-sm space-y-1">
                  <li>âœ… ì†ë„: ì´ˆë‹¹ 30-60 í”„ë ˆì„</li>
                  <li>âœ… ì²˜ë¦¬: ë‹¨ì¼ ì‹ ê²½ë§ (1ë‹¨ê³„)</li>
                  <li>âœ… ì‹¤ì‹œê°„ ê°€ëŠ¥</li>
                </ul>
              </div>
            </div>
          </div>

          <div className="bg-gray-900 text-gray-100 p-4 rounded-lg overflow-x-auto mb-4">
            <pre className="text-sm">
{`# YOLOv8 ì‹¤ì‹œê°„ ê°ì²´ íƒì§€ (Ultralytics)
from ultralytics import YOLO
import cv2

class RobotVision:
    def __init__(self):
        # YOLOv8 ëª¨ë¸ ë¡œë“œ
        self.model = YOLO('yolov8n.pt')  # nano ë²„ì „ (ë¹ ë¦„)
        self.confidence_threshold = 0.5

    def detect_objects(self, frame):
        # ë‹¨ì¼ í”„ë ˆì„ ì¶”ë¡ 
        results = self.model(frame, conf=self.confidence_threshold)

        objects = []
        for result in results:
            boxes = result.boxes  # ë°”ìš´ë”© ë°•ìŠ¤
            for box in boxes:
                # ì¢Œí‘œ ë° ì •ë³´ ì¶”ì¶œ
                x1, y1, x2, y2 = box.xyxy[0].tolist()
                confidence = box.conf[0].item()
                class_id = int(box.cls[0].item())
                class_name = self.model.names[class_id]

                objects.append({
                    'class': class_name,
                    'confidence': confidence,
                    'bbox': (x1, y1, x2, y2),
                    'center': ((x1+x2)/2, (y1+y2)/2)
                })

        return objects

    def real_time_detection(self):
        cap = cv2.VideoCapture(0)  # ì›¹ìº 

        while True:
            ret, frame = cap.read()
            if not ret:
                break

            # ê°ì²´ íƒì§€ (30 FPS ì´ìƒ)
            objects = self.detect_objects(frame)

            # ì‹œê°í™”
            annotated_frame = self.model(frame)[0].plot()
            cv2.imshow('Robot Vision', annotated_frame)

            # ë¡œë´‡ ì œì–´ ë¡œì§
            self.robot_decision(objects)

            if cv2.waitKey(1) & 0xFF == ord('q'):
                break

        cap.release()
        cv2.destroyAllWindows()

    def robot_decision(self, objects):
        # íƒì§€ëœ ê°ì²´ ê¸°ë°˜ ë¡œë´‡ í–‰ë™ ê²°ì •
        for obj in objects:
            if obj['class'] == 'person':
                print(f"ì‚¬ëŒ ê°ì§€! ì•ˆì „ ê±°ë¦¬ ìœ ì§€")
            elif obj['class'] == 'bottle':
                print(f"ë³‘ ë°œê²¬ at {obj['center']}")
                # ë¡œë´‡ íŒ” ì´ë™ ëª…ë ¹`}
            </pre>
          </div>

          <div className="bg-green-50 dark:bg-green-900/20 p-4 rounded-lg border-l-4 border-green-500">
            <h4 className="font-bold mb-2">ğŸš€ YOLOv8 (2023) - ìµœì‹  ë²„ì „ì˜ ê°œì„ ì </h4>
            <ul className="text-sm space-y-2">
              <li>âœ… <strong>Anchor-Free ì„¤ê³„</strong>: ì‚¬ì „ ì •ì˜ëœ ì•µì»¤ ë°•ìŠ¤ ë¶ˆí•„ìš”, ë” ìœ ì—°í•œ íƒì§€</li>
              <li>âœ… <strong>í–¥ìƒëœ ì •í™•ë„</strong>: YOLOv5 ëŒ€ë¹„ mAP 10% í–¥ìƒ</li>
              <li>âœ… <strong>ë” ì‘ì€ ëª¨ë¸</strong>: Nano ëª¨ë¸ 6MB (ëª¨ë°”ì¼/ì—£ì§€ ìµœì í™”)</li>
              <li>âœ… <strong>ë‹¤ì¤‘ ì‘ì—…</strong>: íƒì§€ + ì„¸ê·¸ë©˜í…Œì´ì…˜ + ìì„¸ ì¶”ì • í†µí•©</li>
            </ul>
          </div>
        </div>
      </section>

      {/* 2. Depth Estimation */}
      <section className="my-8">
        <h2 className="flex items-center gap-2">
          <Layers className="text-purple-600" />
          2. ê¹Šì´ ì¶”ì • (Depth Estimation)
        </h2>

        <div className="bg-white dark:bg-gray-800 rounded-lg p-6 shadow-lg mb-6">
          <h3 className="text-xl font-bold mb-4">ğŸ“ 3D ê³µê°„ ì´í•´ - ë‹¨ì•ˆ vs ìŠ¤í…Œë ˆì˜¤</h3>

          <div className="grid md:grid-cols-2 gap-6 mb-6">
            <div className="bg-blue-50 dark:bg-blue-900/20 p-5 rounded-lg">
              <h4 className="font-bold mb-3 text-blue-600">ë‹¨ì•ˆ ê¹Šì´ ì¶”ì • (Monocular)</h4>
              <p className="text-sm mb-3">
                <strong>ë‹¨ì¼ ì¹´ë©”ë¼</strong>ë¡œ ê¹Šì´ë¥¼ ì¶”ì •í•©ë‹ˆë‹¤.
                AIê°€ ì´ë¯¸ì§€ ì† ë‹¨ì„œ (í¬ê¸°, ê°€ë¦¼, ì›ê·¼)ë¥¼ í•™ìŠµí•´ ê±°ë¦¬ë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤.
              </p>
              <ul className="text-sm space-y-2">
                <li>âœ… <strong>ì¥ì </strong>: ì €ë ´, ì»´íŒ©íŠ¸, 1ê°œ ì¹´ë©”ë¼ë§Œ í•„ìš”</li>
                <li>âŒ <strong>ë‹¨ì </strong>: ì •í™•ë„ ë‚®ìŒ (Â±10-20% ì˜¤ì°¨)</li>
                <li>ğŸ¯ <strong>ì‚¬ìš©ì²˜</strong>: Tesla FSD, ìŠ¤ë§ˆíŠ¸í° ì¹´ë©”ë¼</li>
              </ul>
            </div>

            <div className="bg-green-50 dark:bg-green-900/20 p-5 rounded-lg border-2 border-green-500">
              <h4 className="font-bold mb-3 text-green-600">ìŠ¤í…Œë ˆì˜¤ ë¹„ì „ (Stereo Vision)</h4>
              <p className="text-sm mb-3">
                <strong>2ê°œ ì¹´ë©”ë¼</strong>ë¡œ ì–‘ì•ˆ ì‹œì°¨ë¥¼ ê³„ì‚°í•´ ì •í™•í•œ 3D ë§µ ìƒì„±.
                ì¸ê°„ ëˆˆê³¼ ë™ì¼í•œ ì›ë¦¬ì…ë‹ˆë‹¤.
              </p>
              <ul className="text-sm space-y-2">
                <li>âœ… <strong>ì¥ì </strong>: ë†’ì€ ì •í™•ë„ (Â±1-2% ì˜¤ì°¨)</li>
                <li>âŒ <strong>ë‹¨ì </strong>: 2ê°œ ì¹´ë©”ë¼, ìº˜ë¦¬ë¸Œë ˆì´ì…˜ í•„ìš”</li>
                <li>ğŸ¯ <strong>ì‚¬ìš©ì²˜</strong>: ììœ¨ì£¼í–‰, ë¡œë´‡ íŒ”, ë“œë¡ </li>
              </ul>
            </div>
          </div>

          <div className="bg-gray-900 text-gray-100 p-4 rounded-lg overflow-x-auto mb-4">
            <pre className="text-sm">
{`# MiDaS - ë‹¨ì•ˆ ê¹Šì´ ì¶”ì • (Intel)
import torch
import cv2
import numpy as np

class DepthEstimator:
    def __init__(self):
        # MiDaS ëª¨ë¸ ë¡œë“œ
        self.model = torch.hub.load('intel-isl/MiDaS', 'MiDaS_small')
        self.model.eval()

        # Transform
        midas_transforms = torch.hub.load('intel-isl/MiDaS', 'transforms')
        self.transform = midas_transforms.small_transform

    def estimate_depth(self, frame):
        # ì „ì²˜ë¦¬
        input_batch = self.transform(frame).unsqueeze(0)

        # ì¶”ë¡  (GPU ì‚¬ìš©)
        with torch.no_grad():
            prediction = self.model(input_batch)
            prediction = torch.nn.functional.interpolate(
                prediction.unsqueeze(1),
                size=frame.shape[:2],
                mode='bicubic',
                align_corners=False
            ).squeeze()

        # Depth map (0-255 ìŠ¤ì¼€ì¼)
        depth_map = prediction.cpu().numpy()
        depth_map = cv2.normalize(depth_map, None, 0, 255, cv2.NORM_MINMAX)
        depth_map = depth_map.astype(np.uint8)

        return depth_map

    def get_distance_to_object(self, depth_map, bbox):
        # ë°”ìš´ë”© ë°•ìŠ¤ ë‚´ í‰ê·  ê¹Šì´ ê³„ì‚°
        x1, y1, x2, y2 = [int(coord) for coord in bbox]
        roi = depth_map[y1:y2, x1:x2]
        avg_depth = np.mean(roi)

        # ì‹¤ì œ ê±°ë¦¬ë¡œ ë³€í™˜ (ìº˜ë¦¬ë¸Œë ˆì´ì…˜ í•„ìš”)
        # ì—¬ê¸°ì„œëŠ” ìƒëŒ€ì  ê¹Šì´ë§Œ ì œê³µ
        return avg_depth

# ì‚¬ìš© ì˜ˆì‹œ
depth_estimator = DepthEstimator()
yolo_detector = RobotVision()

frame = cv2.imread('scene.jpg')
objects = yolo_detector.detect_objects(frame)
depth_map = depth_estimator.estimate_depth(frame)

# ê° ê°ì²´ê¹Œì§€ì˜ ê±°ë¦¬ ê³„ì‚°
for obj in objects:
    distance = depth_estimator.get_distance_to_object(depth_map, obj['bbox'])
    print(f"{obj['class']}: ìƒëŒ€ ê±°ë¦¬ {distance:.2f}")`}
            </pre>
          </div>

          <div className="bg-purple-50 dark:bg-purple-900/20 p-4 rounded-lg border-l-4 border-purple-500">
            <h4 className="font-bold mb-2">ğŸŒŸ ìµœì‹  ê¸°ìˆ : LiDAR + Vision ìœµí•©</h4>
            <p className="text-sm mb-3">
              ê³ ê¸‰ Physical AIëŠ” <strong>ì¹´ë©”ë¼ + LiDAR</strong>ë¥¼ ê²°í•©í•´ ìµœê³  ì •í™•ë„ë¥¼ ë‹¬ì„±í•©ë‹ˆë‹¤.
            </p>
            <div className="grid md:grid-cols-2 gap-3 text-sm">
              <div className="bg-white dark:bg-gray-800 p-3 rounded">
                <strong>ì¹´ë©”ë¼</strong>: ìƒ‰ìƒ, ì§ˆê°, ê°ì²´ ë¶„ë¥˜
              </div>
              <div className="bg-white dark:bg-gray-800 p-3 rounded">
                <strong>LiDAR</strong>: ì •ë°€í•œ 3D ê±°ë¦¬ (Â±1cm)
              </div>
            </div>
            <p className="text-sm mt-3">
              <strong>ì˜ˆì‹œ</strong>: Waymo ììœ¨ì£¼í–‰ì°¨ëŠ” 5ê°œ LiDAR + 29ê°œ ì¹´ë©”ë¼ ì‚¬ìš©
            </p>
          </div>
        </div>
      </section>

      {/* 3. Semantic Segmentation */}
      <section className="my-8">
        <h2 className="flex items-center gap-2">
          <Grid3x3 className="text-orange-600" />
          3. ì˜ë¯¸ë¡ ì  ë¶„í•  (Semantic Segmentation)
        </h2>

        <div className="bg-white dark:bg-gray-800 rounded-lg p-6 shadow-lg mb-6">
          <h3 className="text-xl font-bold mb-4">ğŸ¨ í”½ì…€ ë‹¨ìœ„ ì´í•´ - ì´ë¯¸ì§€ì˜ ëª¨ë“  ì˜ì—­ ë¶„ë¥˜</h3>

          <div className="bg-gradient-to-r from-orange-50 to-yellow-50 dark:from-orange-900/20 dark:to-yellow-900/20 p-5 rounded-lg mb-6">
            <h4 className="font-bold mb-3">ê°ì²´ íƒì§€ vs ì„¸ê·¸ë©˜í…Œì´ì…˜</h4>
            <div className="grid md:grid-cols-2 gap-4">
              <div>
                <h5 className="font-bold text-sm mb-2">ê°ì²´ íƒì§€ (YOLO)</h5>
                <p className="text-sm mb-2">ë°”ìš´ë”© ë°•ìŠ¤ë¡œ ê°ì²´ ìœ„ì¹˜ë§Œ í‘œì‹œ</p>
                <div className="bg-white dark:bg-gray-800 p-2 rounded text-xs">
                  "ì´ ì‚¬ê°í˜• ì•ˆì— ì°¨ê°€ ìˆë‹¤"
                </div>
              </div>
              <div className="border-l-2 border-orange-300 pl-4">
                <h5 className="font-bold text-sm mb-2">ì„¸ê·¸ë©˜í…Œì´ì…˜ (Mask R-CNN)</h5>
                <p className="text-sm mb-2">ê°ì²´ì˜ ì •í™•í•œ ëª¨ì–‘ì„ í”½ì…€ ë‹¨ìœ„ë¡œ ë¶„ë¦¬</p>
                <div className="bg-white dark:bg-gray-800 p-2 rounded text-xs">
                  "ì´ í”½ì…€ë“¤ì´ ì°¨ì˜ ì‹¤ì œ ìœ¤ê³½ì´ë‹¤"
                </div>
              </div>
            </div>
          </div>

          <div className="bg-gray-900 text-gray-100 p-4 rounded-lg overflow-x-auto mb-4">
            <pre className="text-sm">
{`# Segment Anything Model (SAM) - Meta AI 2023
from segment_anything import sam_model_registry, SamPredictor
import cv2

class SemanticSegmenter:
    def __init__(self):
        # SAM ëª¨ë¸ ë¡œë“œ
        sam = sam_model_registry["vit_h"](checkpoint="sam_vit_h.pth")
        self.predictor = SamPredictor(sam)

    def segment_object(self, image, point_coords):
        """
        point_coords: ì‚¬ìš©ìê°€ í´ë¦­í•œ ì  ì¢Œí‘œ
        ì˜ˆ: [(100, 200)] - "ì´ ì§€ì ì˜ ë¬¼ì²´ë¥¼ ë¶„ë¦¬í•´ì¤˜"
        """
        self.predictor.set_image(image)

        # í´ë¦­í•œ ì ì„ ê¸°ë°˜ìœ¼ë¡œ ë§ˆìŠ¤í¬ ìƒì„±
        masks, scores, logits = self.predictor.predict(
            point_coords=point_coords,
            point_labels=np.array([1] * len(point_coords)),  # 1 = foreground
            multimask_output=True
        )

        # ê°€ì¥ ë†’ì€ ì ìˆ˜ì˜ ë§ˆìŠ¤í¬ ì„ íƒ
        best_mask = masks[np.argmax(scores)]
        return best_mask

    def apply_mask_to_image(self, image, mask):
        # ë§ˆìŠ¤í¬ ì˜ì—­ë§Œ ì»¬ëŸ¬ë¡œ, ë‚˜ë¨¸ì§€ëŠ” íšŒìƒ‰
        result = image.copy()
        result[~mask] = result[~mask] * 0.3  # ë°°ê²½ ì–´ë‘¡ê²Œ

        # ë§ˆìŠ¤í¬ ê²½ê³„ì„  ê·¸ë¦¬ê¸°
        contours, _ = cv2.findContours(
            mask.astype(np.uint8),
            cv2.RETR_EXTERNAL,
            cv2.CHAIN_APPROX_SIMPLE
        )
        cv2.drawContours(result, contours, -1, (0, 255, 0), 2)

        return result

# ë¡œë´‡ì´ ë¬¼ì²´ë¥¼ ì¡ê¸° ìœ„í•œ ì •í™•í•œ ìœ„ì¹˜ íŒŒì•…
segmenter = SemanticSegmenter()
image = cv2.imread('workspace.jpg')

# ë¡œë´‡ì´ ì¡ì„ ë¬¼ì²´ë¥¼ í´ë¦­ (ë˜ëŠ” ìë™ íƒì§€)
target_point = [(320, 240)]  # ì´ë¯¸ì§€ ì¤‘ì‹¬
mask = segmenter.segment_object(image, target_point)

# ë¬¼ì²´ì˜ ë¬´ê²Œì¤‘ì‹¬ ê³„ì‚° (ë¡œë´‡ ê·¸ë¦¬í¼ ìœ„ì¹˜)
moments = cv2.moments(mask.astype(np.uint8))
center_x = int(moments['m10'] / moments['m00'])
center_y = int(moments['m01'] / moments['m00'])

print(f"ê·¸ë¦¬í¼ ëª©í‘œ ìœ„ì¹˜: ({center_x}, {center_y})")`}
            </pre>
          </div>

          <div className="bg-cyan-50 dark:bg-cyan-900/20 p-4 rounded-lg border-l-4 border-cyan-500">
            <h4 className="font-bold mb-2">ğŸ¤– ë¡œë´‡ ì‘ìš© ì‚¬ë¡€</h4>
            <ul className="text-sm space-y-2">
              <li>
                <strong>â€¢ ë¡œë´‡ íŒ” ì œì–´</strong>
                <p className="mt-1">ë¬¼ì²´ì˜ ì •í™•í•œ ìœ¤ê³½ì„ íŒŒì•…í•´ ìµœì ì˜ ê·¸ë¦¬í¼ ìœ„ì¹˜ ê³„ì‚°</p>
              </li>
              <li>
                <strong>â€¢ ììœ¨ì£¼í–‰</strong>
                <p className="mt-1">ë„ë¡œ, ë³´ë„, ì°¨ì„ , ì‹ í˜¸ë“±ì„ í”½ì…€ ë‹¨ìœ„ë¡œ ë¶„ë¥˜</p>
              </li>
              <li>
                <strong>â€¢ ì˜ë£Œ ë¡œë´‡</strong>
                <p className="mt-1">ìˆ˜ìˆ  ì¤‘ ì •ë°€í•œ ì¡°ì§ êµ¬ë¶„ (ì¢…ì–‘ vs ì •ìƒ ì¡°ì§)</p>
              </li>
            </ul>
          </div>
        </div>
      </section>

      {/* 4. Pose Estimation */}
      <section className="my-8">
        <h2 className="flex items-center gap-2">
          <Maximize className="text-green-600" />
          4. ìì„¸ ì¶”ì • (Pose Estimation)
        </h2>

        <div className="bg-white dark:bg-gray-800 rounded-lg p-6 shadow-lg mb-6">
          <h3 className="text-xl font-bold mb-4">ğŸ¤¸ ì¸ê°„ ë° ë¡œë´‡ì˜ ê´€ì ˆ ìœ„ì¹˜ ì¶”ì </h3>

          <div className="bg-green-50 dark:bg-green-900/20 p-5 rounded-lg mb-6">
            <h4 className="font-bold mb-3">ì™œ ìì„¸ ì¶”ì •ì´ ì¤‘ìš”í•œê°€?</h4>
            <p className="text-sm mb-3">
              íœ´ë¨¸ë…¸ì´ë“œ ë¡œë´‡ì´ <strong>ì‚¬ëŒê³¼ í˜‘ì—…</strong>í•˜ë ¤ë©´ ì‚¬ëŒì˜ í–‰ë™ì„ ì´í•´í•´ì•¼ í•©ë‹ˆë‹¤.
              ìì„¸ ì¶”ì •ì€ 17ê°œ ê´€ì ˆ (ì†ëª©, íŒ”ê¿ˆì¹˜, ì–´ê¹¨, ë¬´ë¦ ë“±)ì˜ 3D ìœ„ì¹˜ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ì¶”ì í•©ë‹ˆë‹¤.
            </p>
            <div className="grid md:grid-cols-3 gap-3 text-sm">
              <div className="bg-white dark:bg-gray-800 p-3 rounded">
                <strong>ì œìŠ¤ì²˜ ì¸ì‹</strong><br/>
                <span className="text-xs">ì†ì„ ë“¤ë©´ ë¡œë´‡ì—ê²Œ ì‹ í˜¸</span>
              </div>
              <div className="bg-white dark:bg-gray-800 p-3 rounded">
                <strong>ì•ˆì „ ê°ì§€</strong><br/>
                <span className="text-xs">ì‚¬ëŒì´ ë„˜ì–´ì§€ë©´ ì¦‰ì‹œ ë„ì›€</span>
              </div>
              <div className="bg-white dark:bg-gray-800 p-3 rounded">
                <strong>ë™ì‘ ëª¨ë°©</strong><br/>
                <span className="text-xs">ì‚¬ëŒì˜ í–‰ë™ì„ ë³´ê³  í•™ìŠµ</span>
              </div>
            </div>
          </div>

          <div className="bg-gray-900 text-gray-100 p-4 rounded-lg overflow-x-auto mb-4">
            <pre className="text-sm">
{`# MediaPipe Pose - Googleì˜ ì‹¤ì‹œê°„ ìì„¸ ì¶”ì •
import mediapipe as mp
import cv2

class HumanPoseTracker:
    def __init__(self):
        self.mp_pose = mp.solutions.pose
        self.pose = self.mp_pose.Pose(
            min_detection_confidence=0.5,
            min_tracking_confidence=0.5
        )
        self.mp_drawing = mp.solutions.drawing_utils

    def track_pose(self, frame):
        # RGB ë³€í™˜
        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        results = self.pose.process(rgb_frame)

        if results.pose_landmarks:
            # 33ê°œ ê´€ì ˆ ì¢Œí‘œ ì¶”ì¶œ
            landmarks = results.pose_landmarks.landmark

            # ì£¼ìš” ê´€ì ˆ ìœ„ì¹˜
            left_wrist = landmarks[self.mp_pose.PoseLandmark.LEFT_WRIST]
            right_wrist = landmarks[self.mp_pose.PoseLandmark.RIGHT_WRIST]
            nose = landmarks[self.mp_pose.PoseLandmark.NOSE]

            # ì œìŠ¤ì²˜ ê°ì§€ ì˜ˆì‹œ: ì–‘ì†ì„ ë¨¸ë¦¬ ìœ„ë¡œ
            if (left_wrist.y < nose.y and right_wrist.y < nose.y):
                return "HANDS_UP"  # ë¡œë´‡ì—ê²Œ ì •ì§€ ì‹ í˜¸

            # ìŠ¤ì¼ˆë ˆí†¤ ì‹œê°í™”
            self.mp_drawing.draw_landmarks(
                frame,
                results.pose_landmarks,
                self.mp_pose.POSE_CONNECTIONS
            )

        return frame, results.pose_landmarks

    def calculate_joint_angle(self, p1, p2, p3):
        """
        3ê°œ ê´€ì ˆë¡œ ê°ë„ ê³„ì‚° (ì˜ˆ: íŒ”ê¿ˆì¹˜ ê°ë„)
        p1: ì–´ê¹¨, p2: íŒ”ê¿ˆì¹˜, p3: ì†ëª©
        """
        import numpy as np

        v1 = np.array([p1.x - p2.x, p1.y - p2.y])
        v2 = np.array([p3.x - p2.x, p3.y - p2.y])

        angle = np.arccos(
            np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))
        )
        return np.degrees(angle)

# í˜‘ì—… ë¡œë´‡ ì‘ìš©
tracker = HumanPoseTracker()
cap = cv2.VideoCapture(0)

while True:
    ret, frame = cap.read()
    gesture, landmarks = tracker.track_pose(frame)

    if gesture == "HANDS_UP":
        print("ğŸš¨ ê¸´ê¸‰ ì •ì§€ ì‹ í˜¸ ê°ì§€! ë¡œë´‡ ë™ì‘ ì¤‘ì§€")
        # robot.emergency_stop()

    cv2.imshow('Human-Robot Collaboration', frame)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break`}
            </pre>
          </div>

          <div className="bg-blue-50 dark:bg-blue-900/20 p-4 rounded-lg border-l-4 border-blue-500">
            <h4 className="font-bold mb-2">ğŸ­ ì‚°ì—… ì‘ìš© ì‚¬ë¡€</h4>
            <div className="space-y-3 text-sm">
              <div>
                <strong>â€¢ BMW ê³µì¥ (Figure AI)</strong>
                <p className="mt-1">ì‘ì—…ìì˜ ìì„¸ë¥¼ ë¶„ì„í•´ ë¡œë´‡ì´ ì ì ˆí•œ ìœ„ì¹˜ì—ì„œ ë¶€í’ˆ ì „ë‹¬</p>
              </div>
              <div>
                <strong>â€¢ Amazon ë¬¼ë¥˜ì„¼í„°</strong>
                <p className="mt-1">ì‘ì—…ì í”¼ë¡œë„ ê°ì§€ (êµ¬ë¶€ë¦° ìì„¸ ì§€ì† ì‹œ ê²½ê³ )</p>
              </div>
              <div>
                <strong>â€¢ ì¬í™œ ë¡œë´‡</strong>
                <p className="mt-1">í™˜ìì˜ ê´€ì ˆ ê°ë„ë¥¼ ì‹¤ì‹œê°„ ì¶”ì í•˜ë©° ë¬¼ë¦¬ì¹˜ë£Œ ë³´ì¡°</p>
              </div>
            </div>
          </div>
        </div>
      </section>

      {/* 5. Sensor Fusion */}
      <section className="my-8">
        <h2 className="flex items-center gap-2">
          <Zap className="text-indigo-600" />
          5. ì„¼ì„œ ìœµí•© (Sensor Fusion)
        </h2>

        <div className="bg-white dark:bg-gray-800 rounded-lg p-6 shadow-lg">
          <h3 className="text-xl font-bold mb-4">ğŸ”— ì—¬ëŸ¬ ì„¼ì„œë¥¼ í†µí•©í•´ ì™„ë²½í•œ ì¸ì§€</h3>

          <div className="bg-gradient-to-r from-indigo-50 to-purple-50 dark:from-indigo-900/20 dark:to-purple-900/20 p-5 rounded-lg mb-6">
            <h4 className="font-bold mb-3">ì™œ í•˜ë‚˜ì˜ ì„¼ì„œë¡œëŠ” ë¶€ì¡±í•œê°€?</h4>
            <p className="text-sm mb-4">
              ê° ì„¼ì„œëŠ” <strong>ì¥ì ê³¼ í•œê³„</strong>ê°€ ìˆìŠµë‹ˆë‹¤. ì—¬ëŸ¬ ì„¼ì„œë¥¼ ê²°í•©í•˜ë©´ ì•½ì ì„ ë³´ì™„í•˜ê³ 
              <strong>ì‹ ë¢°ì„±ê³¼ ì •í™•ë„</strong>ë¥¼ ê·¹ëŒ€í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
            </p>

            <div className="grid md:grid-cols-3 gap-3 text-sm">
              <div className="bg-white dark:bg-gray-800 p-3 rounded">
                <strong>ì¹´ë©”ë¼</strong><br/>
                <span className="text-xs text-green-600">âœ… ìƒ‰ìƒ, ì§ˆê° í’ë¶€</span><br/>
                <span className="text-xs text-red-600">âŒ ì–´ë‘ ì— ì•½í•¨</span>
              </div>
              <div className="bg-white dark:bg-gray-800 p-3 rounded">
                <strong>LiDAR</strong><br/>
                <span className="text-xs text-green-600">âœ… ì •ë°€ ê±°ë¦¬ ì¸¡ì •</span><br/>
                <span className="text-xs text-red-600">âŒ ë¹„, ëˆˆì— ì·¨ì•½</span>
              </div>
              <div className="bg-white dark:bg-gray-800 p-3 rounded">
                <strong>ë ˆì´ë”</strong><br/>
                <span className="text-xs text-green-600">âœ… ë‚ ì”¨ ë¬´ê´€</span><br/>
                <span className="text-xs text-red-600">âŒ í•´ìƒë„ ë‚®ìŒ</span>
              </div>
            </div>

            <div className="mt-4 p-3 bg-green-100 dark:bg-green-900/30 rounded">
              <strong className="text-green-700 dark:text-green-300">ì„¼ì„œ ìœµí•© ê²°ê³¼</strong>
              <p className="text-sm mt-2">
                ì¹´ë©”ë¼ (ê°ì²´ ë¶„ë¥˜) + LiDAR (ê±°ë¦¬) + ë ˆì´ë” (ì†ë„) =
                <strong>ì™„ë²½í•œ 3D ì¸ì§€ ì‹œìŠ¤í…œ</strong>
              </p>
            </div>
          </div>

          <div className="bg-gray-900 text-gray-100 p-4 rounded-lg overflow-x-auto">
            <pre className="text-sm">
{`# Kalman Filter ê¸°ë°˜ ì„¼ì„œ ìœµí•©
import numpy as np

class SensorFusion:
    def __init__(self):
        # ì¹¼ë§Œ í•„í„° ìƒíƒœ (ìœ„ì¹˜, ì†ë„)
        self.state = np.array([0.0, 0.0])  # [position, velocity]
        self.P = np.eye(2)  # ê³µë¶„ì‚° í–‰ë ¬

        # í”„ë¡œì„¸ìŠ¤ ë…¸ì´ì¦ˆ
        self.Q = np.array([[0.01, 0], [0, 0.01]])

    def predict(self, dt):
        # ìƒíƒœ ì˜ˆì¸¡ (ë“±ì†ë„ ëª¨ë¸)
        F = np.array([[1, dt], [0, 1]])  # ìƒíƒœ ì „ì´ í–‰ë ¬
        self.state = F @ self.state
        self.P = F @ self.P @ F.T + self.Q

    def update_camera(self, measured_position):
        # ì¹´ë©”ë¼ ì¸¡ì •ê°’ìœ¼ë¡œ ì—…ë°ì´íŠ¸
        H = np.array([[1, 0]])  # ì¸¡ì • í–‰ë ¬ (ìœ„ì¹˜ë§Œ)
        R = np.array([[0.5]])   # ì¹´ë©”ë¼ ë…¸ì´ì¦ˆ (ì •í™•ë„ ì¤‘ê°„)

        y = measured_position - (H @ self.state)
        S = H @ self.P @ H.T + R
        K = self.P @ H.T @ np.linalg.inv(S)

        self.state = self.state + K @ y
        self.P = (np.eye(2) - K @ H) @ self.P

    def update_lidar(self, measured_position):
        # LiDAR ì¸¡ì •ê°’ìœ¼ë¡œ ì—…ë°ì´íŠ¸ (ë” ì •í™•í•¨)
        H = np.array([[1, 0]])
        R = np.array([[0.1]])  # LiDAR ë…¸ì´ì¦ˆ (ì •í™•ë„ ë†’ìŒ)

        y = measured_position - (H @ self.state)
        S = H @ self.P @ H.T + R
        K = self.P @ H.T @ np.linalg.inv(S)

        self.state = self.state + K @ y
        self.P = (np.eye(2) - K @ H) @ self.P

    def get_fused_position(self):
        return self.state[0]

# ì‹¤ì‹œê°„ ì„¼ì„œ ìœµí•© ì˜ˆì‹œ
fusion = SensorFusion()

while robot.is_running():
    dt = 0.1  # 100ms

    # ì˜ˆì¸¡ ë‹¨ê³„
    fusion.predict(dt)

    # ì¹´ë©”ë¼ ë°ì´í„° ìˆ˜ì‹  ì‹œ
    if camera.has_data():
        camera_pos = camera.get_object_position()
        fusion.update_camera(camera_pos)

    # LiDAR ë°ì´í„° ìˆ˜ì‹  ì‹œ
    if lidar.has_data():
        lidar_pos = lidar.get_distance()
        fusion.update_lidar(lidar_pos)

    # ìœµí•©ëœ ìœ„ì¹˜ ì‚¬ìš©
    fused_position = fusion.get_fused_position()
    robot.move_to(fused_position)`}
            </pre>
          </div>
        </div>
      </section>

      {/* Summary */}
      <div className="bg-gradient-to-r from-teal-50 to-cyan-50 dark:from-teal-900/20 dark:to-cyan-900/20 border-l-4 border-teal-500 p-6 rounded-lg my-8">
        <h3 className="text-xl font-bold mb-3">ğŸ“Œ í•µì‹¬ ìš”ì•½</h3>
        <ul className="space-y-2 text-sm">
          <li>âœ… <strong>ê°ì²´ íƒì§€ (YOLO)</strong>: ì‹¤ì‹œê°„ 30-60 FPS, ë°”ìš´ë”© ë°•ìŠ¤</li>
          <li>âœ… <strong>ê¹Šì´ ì¶”ì •</strong>: ë‹¨ì•ˆ (ì €ë ´) vs ìŠ¤í…Œë ˆì˜¤ (ì •í™•) vs LiDAR (ìµœê³ )</li>
          <li>âœ… <strong>ì„¸ê·¸ë©˜í…Œì´ì…˜</strong>: í”½ì…€ ë‹¨ìœ„ ê°ì²´ ë¶„ë¦¬, ì •ë°€ ì œì–´</li>
          <li>âœ… <strong>ìì„¸ ì¶”ì •</strong>: 33ê°œ ê´€ì ˆ ì¶”ì , ì¸ê°„-ë¡œë´‡ í˜‘ì—…</li>
          <li>âœ… <strong>ì„¼ì„œ ìœµí•©</strong>: ì¹´ë©”ë¼ + LiDAR + ë ˆì´ë” = ì™„ë²½í•œ ì¸ì§€</li>
        </ul>
      </div>

      {/* Next Chapter */}
      <div className="bg-blue-50 dark:bg-blue-900/20 border-l-4 border-blue-500 p-6 rounded-lg">
        <h3 className="text-xl font-bold mb-2">ë‹¤ìŒ ë‹¨ê³„: ê°•í™”í•™ìŠµê³¼ ë¡œë´‡ ì œì–´</h3>
        <p className="text-gray-700 dark:text-gray-300">
          ë‹¤ìŒ ì±•í„°ì—ì„œëŠ” ë¡œë´‡ì´ <strong>ì‹œí–‰ì°©ì˜¤ë¥¼ í†µí•´ ìŠ¤ìŠ¤ë¡œ í•™ìŠµ</strong>í•˜ëŠ”
          ê°•í™”í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ê³¼ ì •ë°€í•œ ëª¨í„° ì œì–´ ê¸°ìˆ ì„ ë°°ì›ë‹ˆë‹¤.
        </p>
      </div>
    </div>
  )
}
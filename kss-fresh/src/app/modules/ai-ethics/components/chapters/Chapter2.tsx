import React from 'react';
import { Scale, TrendingUp, AlertCircle, Users, BarChart } from 'lucide-react';
import References from '../References';

export default function Chapter2() {
  return (
    <div className="max-w-4xl mx-auto px-4 py-8">
      <h1 className="text-4xl font-bold mb-6 text-gray-900 dark:text-white">í¸í–¥ê³¼ ê³µì •ì„±</h1>

      <div className="bg-gradient-to-r from-rose-100 to-pink-100 dark:from-rose-900/30 dark:to-pink-900/30 p-6 rounded-lg mb-8">
        <p className="text-lg text-gray-800 dark:text-gray-200 leading-relaxed">
          AI ì‹œìŠ¤í…œì˜ í¸í–¥ì€ í›ˆë ¨ ë°ì´í„°, ì•Œê³ ë¦¬ì¦˜ ì„¤ê³„, ì‚¬íšŒì  ë§¥ë½ì´ ë³µí•©ì ìœ¼ë¡œ ì‘ìš©í•œ ê²°ê³¼ì…ë‹ˆë‹¤.
          ê³µì •ì„±(Fairness)ì€ ë‹¨ìˆœíˆ "ë˜‘ê°™ì´ ëŒ€ìš°"í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, ì—­ì‚¬ì Â·êµ¬ì¡°ì  ë¶ˆí‰ë“±ì„ ê³ ë ¤í•œ
          ì •ì˜ë¡œìš´ ê²°ê³¼ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤.
        </p>
      </div>

      {/* ê³µì •ì„±ì˜ 3ëŒ€ ì •ì˜ */}
      <section className="mb-12">
        <h2 className="text-3xl font-bold mb-6 text-gray-900 dark:text-white flex items-center gap-2">
          <Scale className="w-8 h-8 text-rose-600" />
          ê³µì •ì„±ì˜ 3ëŒ€ ìˆ˜í•™ì  ì •ì˜
        </h2>

        <div className="space-y-6">
          <div className="bg-white dark:bg-gray-800 p-6 rounded-lg shadow-lg border-l-4 border-blue-500">
            <h3 className="text-2xl font-bold mb-3 text-gray-900 dark:text-white">1. Statistical Parity (í†µê³„ì  ë™ë“±ì„±)</h3>
            <p className="text-gray-700 dark:text-gray-300 mb-4">
              ëª¨ë“  ê·¸ë£¹ì´ ë™ì¼í•œ ë¹„ìœ¨ë¡œ ê¸ì •ì  ê²°ê³¼ë¥¼ ë°›ì•„ì•¼ í•¨
            </p>

            <div className="bg-blue-50 dark:bg-blue-900/20 p-4 rounded mb-4">
              <p className="font-mono text-sm text-gray-800 dark:text-gray-200">
                P(Å¶ = 1 | A = 0) = P(Å¶ = 1 | A = 1)
              </p>
              <p className="text-sm text-gray-700 dark:text-gray-300 mt-2">
                Å¶: ì˜ˆì¸¡ ê²°ê³¼, A: ë³´í˜¸ ì†ì„± (ì˜ˆ: ì„±ë³„, ì¸ì¢…)
              </p>
            </div>

            <div className="bg-gray-50 dark:bg-gray-900/50 p-4 rounded">
              <p className="font-semibold text-gray-900 dark:text-white mb-2">ì˜ˆì‹œ: ëŒ€ì¶œ ìŠ¹ì¸</p>
              <ul className="list-disc list-inside text-sm text-gray-700 dark:text-gray-300 space-y-1">
                <li>ë‚¨ì„± ê·¸ë£¹ ëŒ€ì¶œ ìŠ¹ì¸ìœ¨: 60%</li>
                <li>ì—¬ì„± ê·¸ë£¹ ëŒ€ì¶œ ìŠ¹ì¸ìœ¨: 60% â† Statistical Parity ë§Œì¡±</li>
              </ul>
              <p className="text-sm text-gray-600 dark:text-gray-400 mt-2 italic">
                ë¬¸ì œì : ì‹¤ì œ ì‹ ìš©ë„ ì°¨ì´ë¥¼ ë¬´ì‹œí•  ìˆ˜ ìˆìŒ
              </p>
            </div>
          </div>

          <div className="bg-white dark:bg-gray-800 p-6 rounded-lg shadow-lg border-l-4 border-green-500">
            <h3 className="text-2xl font-bold mb-3 text-gray-900 dark:text-white">2. Equal Opportunity (ê¸°íšŒ í‰ë“±)</h3>
            <p className="text-gray-700 dark:text-gray-300 mb-4">
              ì‹¤ì œ ê¸ì • ì¼€ì´ìŠ¤(Y=1)ì—ì„œ ëª¨ë“  ê·¸ë£¹ì˜ True Positive Rateì´ ë™ì¼í•´ì•¼ í•¨
            </p>

            <div className="bg-green-50 dark:bg-green-900/20 p-4 rounded mb-4">
              <p className="font-mono text-sm text-gray-800 dark:text-gray-200">
                P(Å¶ = 1 | Y = 1, A = 0) = P(Å¶ = 1 | Y = 1, A = 1)
              </p>
              <p className="text-sm text-gray-700 dark:text-gray-300 mt-2">
                Y: ì‹¤ì œ ê°’ (Ground Truth)
              </p>
            </div>

            <div className="bg-gray-50 dark:bg-gray-900/50 p-4 rounded">
              <p className="font-semibold text-gray-900 dark:text-white mb-2">ì˜ˆì‹œ: ì±„ìš© AI</p>
              <ul className="list-disc list-inside text-sm text-gray-700 dark:text-gray-300 space-y-1">
                <li>ì‹¤ì œ ìê²© ìˆëŠ” ë‚¨ì„± í›„ë³´ ì¤‘ í•©ê²©: 80%</li>
                <li>ì‹¤ì œ ìê²© ìˆëŠ” ì—¬ì„± í›„ë³´ ì¤‘ í•©ê²©: 80% â† Equal Opportunity ë§Œì¡±</li>
              </ul>
              <p className="text-sm text-gray-600 dark:text-gray-400 mt-2 italic">
                ì¥ì : ìê²© ìˆëŠ” ì‚¬ëŒì—ê²Œ ê³µí‰í•œ ê¸°íšŒ ë³´ì¥
              </p>
            </div>
          </div>

          <div className="bg-white dark:bg-gray-800 p-6 rounded-lg shadow-lg border-l-4 border-purple-500">
            <h3 className="text-2xl font-bold mb-3 text-gray-900 dark:text-white">3. Predictive Parity (ì˜ˆì¸¡ ë™ë“±ì„±)</h3>
            <p className="text-gray-700 dark:text-gray-300 mb-4">
              ê¸ì • ì˜ˆì¸¡(Å¶=1)ì˜ ì •í™•ë„(Precision)ê°€ ëª¨ë“  ê·¸ë£¹ì—ì„œ ë™ì¼í•´ì•¼ í•¨
            </p>

            <div className="bg-purple-50 dark:bg-purple-900/20 p-4 rounded mb-4">
              <p className="font-mono text-sm text-gray-800 dark:text-gray-200">
                P(Y = 1 | Å¶ = 1, A = 0) = P(Y = 1 | Å¶ = 1, A = 1)
              </p>
            </div>

            <div className="bg-gray-50 dark:bg-gray-900/50 p-4 rounded">
              <p className="font-semibold text-gray-900 dark:text-white mb-2">ì˜ˆì‹œ: ì¬ë²” ì˜ˆì¸¡ (COMPAS)</p>
              <ul className="list-disc list-inside text-sm text-gray-700 dark:text-gray-300 space-y-1">
                <li>ë°±ì¸ ê·¸ë£¹: ê³ ìœ„í—˜ ì˜ˆì¸¡ ì¤‘ ì‹¤ì œ ì¬ë²”ë¥  63%</li>
                <li>í‘ì¸ ê·¸ë£¹: ê³ ìœ„í—˜ ì˜ˆì¸¡ ì¤‘ ì‹¤ì œ ì¬ë²”ë¥  63% â† Predictive Parity ë§Œì¡±</li>
              </ul>
              <p className="text-sm text-gray-600 dark:text-gray-400 mt-2 italic">
                ì¤‘ìš”: ì„¸ ê°€ì§€ ì •ì˜ë¥¼ ë™ì‹œì— ë§Œì¡±í•˜ëŠ” ê²ƒì€ ìˆ˜í•™ì ìœ¼ë¡œ ë¶ˆê°€ëŠ¥ (Impossibility Theorem)
              </p>
            </div>
          </div>
        </div>
      </section>

      {/* COMPAS ì•Œê³ ë¦¬ì¦˜ ì‚¬ë¡€ */}
      <section className="mb-12">
        <h2 className="text-3xl font-bold mb-6 text-gray-900 dark:text-white flex items-center gap-2">
          <AlertCircle className="w-8 h-8 text-red-600" />
          COMPAS ì•Œê³ ë¦¬ì¦˜: í¸í–¥ì˜ ê³ ì „ì  ì‚¬ë¡€
        </h2>

        <div className="bg-red-50 dark:bg-red-900/20 p-6 rounded-lg mb-6">
          <h3 className="text-xl font-bold mb-3 text-gray-900 dark:text-white">ì‚¬ê±´ ê°œìš” (ProPublica ì¡°ì‚¬, 2016)</h3>
          <p className="text-gray-700 dark:text-gray-300 mb-4">
            ë¯¸êµ­ ë²•ì›ì—ì„œ ì‚¬ìš©í•˜ëŠ” ì¬ë²” ìœ„í—˜ ì˜ˆì¸¡ ì•Œê³ ë¦¬ì¦˜ COMPASê°€ í‘ì¸ì—ê²Œ ì²´ê³„ì ìœ¼ë¡œ ë¶ˆë¦¬í•œ ê²°ê³¼ë¥¼ ìƒì„±.
            ProPublicaì˜ ë¶„ì„ ê²°ê³¼, ì•Œê³ ë¦¬ì¦˜ì´ "Predictive Parity"ëŠ” ë§Œì¡±í•˜ì§€ë§Œ "Equal Opportunity"ë¥¼ ìœ„ë°˜í•¨ì´ ë°í˜€ì§.
          </p>

          <div className="grid md:grid-cols-2 gap-4">
            <div className="bg-white dark:bg-gray-800 p-4 rounded">
              <h4 className="font-bold text-gray-900 dark:text-white mb-2">í‘ì¸ í”¼ê³ ì¸</h4>
              <ul className="text-sm text-gray-700 dark:text-gray-300 space-y-1">
                <li>False Positive Rate (ë¬´ê³ í•œë° ê³ ìœ„í—˜): <strong className="text-red-600">44.9%</strong></li>
                <li>False Negative Rate (ìœ„í—˜í•œë° ì €ìœ„í—˜): 28.0%</li>
                <li>ì‹¤ì œ ì¬ë²”í•˜ì§€ ì•Šì•˜ëŠ”ë° ê³ ìœ„í—˜ íŒì •ë°›ì€ ë¹„ìœ¨ì´ ë°±ì¸ì˜ 2ë°°</li>
              </ul>
            </div>
            <div className="bg-white dark:bg-gray-800 p-4 rounded">
              <h4 className="font-bold text-gray-900 dark:text-white mb-2">ë°±ì¸ í”¼ê³ ì¸</h4>
              <ul className="text-sm text-gray-700 dark:text-gray-300 space-y-1">
                <li>False Positive Rate: <strong className="text-green-600">23.5%</strong></li>
                <li>False Negative Rate (ìœ„í—˜í•œë° ì €ìœ„í—˜): 47.7%</li>
                <li>ì‹¤ì œ ì¬ë²”í–ˆëŠ”ë° ì €ìœ„í—˜ íŒì •ë°›ì€ ë¹„ìœ¨ì´ í‘ì¸ì˜ 1.7ë°°</li>
              </ul>
            </div>
          </div>
        </div>

        <div className="bg-yellow-50 dark:bg-yellow-900/20 p-4 rounded-lg">
          <p className="text-sm font-semibold text-gray-900 dark:text-white mb-2">í•µì‹¬ êµí›ˆ:</p>
          <ul className="list-disc list-inside text-sm text-gray-700 dark:text-gray-300 space-y-1">
            <li>ì•Œê³ ë¦¬ì¦˜ì´ "ê°ê´€ì "ì´ë¼ëŠ” ì£¼ì¥ì€ ìœ„í—˜ (ë°ì´í„° ìì²´ì— í¸í–¥ ì¡´ì¬)</li>
            <li>ì—¬ëŸ¬ ê³µì •ì„± ì§€í‘œë¥¼ ë™ì‹œì— ë§Œì¡±í•˜ëŠ” ê²ƒì€ ë¶ˆê°€ëŠ¥í•  ìˆ˜ ìˆìŒ</li>
            <li>ì—­ì‚¬ì  ì°¨ë³„ì´ ë°ì´í„°ì— ë°˜ì˜ë˜ì–´ AIê°€ ì´ë¥¼ í•™ìŠµí•˜ê³  ê°•í™”</li>
            <li>High-stakes ê²°ì •(í˜•ì‚¬ì‚¬ë²•)ì—ì„œ AI ë³´ì¡° ë„êµ¬ëŠ” ì‹ ì¤‘íˆ ì‚¬ìš©í•´ì•¼ í•¨</li>
          </ul>
        </div>
      </section>

      {/* ì‹¤ì „ ì½”ë“œ: Fairlearn & IBM AIF360 */}
      <section className="mb-12">
        <h2 className="text-3xl font-bold mb-6 text-gray-900 dark:text-white">ì‹¤ì „ ì½”ë“œ: í¸í–¥ íƒì§€ ë° ì™„í™”</h2>

        <div className="mb-6">
          <h3 className="text-xl font-bold mb-3 text-gray-900 dark:text-white">1. Fairlearn - Microsoft ê³µì •ì„± ë¼ì´ë¸ŒëŸ¬ë¦¬</h3>
          <div className="bg-gray-900 dark:bg-gray-950 p-6 rounded-lg overflow-x-auto">
            <pre className="text-sm text-gray-100">
              <code>{`from fairlearn.metrics import MetricFrame, selection_rate, false_positive_rate
from fairlearn.reductions import ExponentiatedGradient, DemographicParity
from sklearn.linear_model import LogisticRegression
import pandas as pd

# ì˜ˆì‹œ: ëŒ€ì¶œ ìŠ¹ì¸ ë°ì´í„°
# X: íŠ¹ì„± (ì†Œë“, ë¶€ì±„ ë“±), y: ìŠ¹ì¸ ì—¬ë¶€ (0/1), sensitive: ì„±ë³„
X_train, X_test = ...  # í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë°ì´í„°
y_train, y_test = ...  # ë ˆì´ë¸”
sensitive_train = ...  # ë³´í˜¸ ì†ì„± (ì˜ˆ: ['male', 'female', ...])
sensitive_test = ...

# 1ë‹¨ê³„: ê¸°ë³¸ ëª¨ë¸ í•™ìŠµ
base_model = LogisticRegression()
base_model.fit(X_train, y_train)
y_pred_base = base_model.predict(X_test)

# 2ë‹¨ê³„: ê³µì •ì„± ì§€í‘œ ì¸¡ì •
metrics = {
    'selection_rate': selection_rate,
    'false_positive_rate': false_positive_rate,
    'accuracy': lambda y_true, y_pred: (y_true == y_pred).mean()
}

metric_frame = MetricFrame(
    metrics=metrics,
    y_true=y_test,
    y_pred=y_pred_base,
    sensitive_features=sensitive_test
)

print("=== ê¸°ë³¸ ëª¨ë¸ ê³µì •ì„± ì§€í‘œ ===")
print(metric_frame.by_group)
# ì¶œë ¥ ì˜ˆì‹œ:
#                selection_rate  false_positive_rate  accuracy
# sensitive_features
# female                   0.45                 0.28      0.82
# male                     0.62                 0.15      0.85
# â†’ ë‚¨ì„± ê·¸ë£¹ì´ ì—¬ì„±ë³´ë‹¤ 17%p ë†’ì€ ìŠ¹ì¸ìœ¨ (í¸í–¥ ì¡´ì¬!)

# 3ë‹¨ê³„: í¸í–¥ ì™„í™” (Demographic Parity ì œì•½)
mitigator = ExponentiatedGradient(
    estimator=LogisticRegression(),
    constraints=DemographicParity()  # Statistical Parity ê°•ì œ
)

mitigator.fit(X_train, y_train, sensitive_features=sensitive_train)
y_pred_mitigated = mitigator.predict(X_test)

# 4ë‹¨ê³„: ì™„í™” í›„ ê³µì •ì„± ì¬ì¸¡ì •
metric_frame_mitigated = MetricFrame(
    metrics=metrics,
    y_true=y_test,
    y_pred=y_pred_mitigated,
    sensitive_features=sensitive_test
)

print("\\n=== í¸í–¥ ì™„í™” í›„ ===")
print(metric_frame_mitigated.by_group)
# ì¶œë ¥ ì˜ˆì‹œ:
#                selection_rate  false_positive_rate  accuracy
# sensitive_features
# female                   0.53                 0.22      0.80
# male                     0.54                 0.21      0.81
# â†’ ìŠ¹ì¸ìœ¨ ì°¨ì´ 1%pë¡œ ê°ì†Œ! (ì •í™•ë„ ì•½ê°„ ê°ì†Œ trade-off ì¡´ì¬)

# 5ë‹¨ê³„: ê³µì •ì„±-ì •í™•ë„ Trade-off ì‹œê°í™”
import matplotlib.pyplot as plt

disparities = []
accuracies = []

for constraint_weight in [0.01, 0.05, 0.1, 0.5, 1.0]:
    mitigator = ExponentiatedGradient(
        estimator=LogisticRegression(),
        constraints=DemographicParity(difference_bound=constraint_weight)
    )
    mitigator.fit(X_train, y_train, sensitive_features=sensitive_train)
    y_pred = mitigator.predict(X_test)

    mf = MetricFrame(
        metrics={'selection_rate': selection_rate},
        y_true=y_test,
        y_pred=y_pred,
        sensitive_features=sensitive_test
    )
    disparity = mf.by_group['selection_rate'].max() - mf.by_group['selection_rate'].min()
    accuracy = (y_test == y_pred).mean()

    disparities.append(disparity)
    accuracies.append(accuracy)

plt.plot(disparities, accuracies, 'o-')
plt.xlabel('Selection Rate Disparity (ì°¨ì´)')
plt.ylabel('Overall Accuracy')
plt.title('Fairness-Accuracy Trade-off')
plt.show()`}</code>
            </pre>
          </div>
        </div>

        <div className="mb-6">
          <h3 className="text-xl font-bold mb-3 text-gray-900 dark:text-white">2. IBM AI Fairness 360 - ê³ ê¸‰ í¸í–¥ ì™„í™”</h3>
          <div className="bg-gray-900 dark:bg-gray-950 p-6 rounded-lg overflow-x-auto">
            <pre className="text-sm text-gray-100">
              <code>{`from aif360.datasets import BinaryLabelDataset
from aif360.metrics import BinaryLabelDatasetMetric, ClassificationMetric
from aif360.algorithms.preprocessing import Reweighing
from aif360.algorithms.inprocessing import PrejudiceRemover

# 1ë‹¨ê³„: ë°ì´í„° í¸í–¥ ë¶„ì„ (Pre-processing)
dataset = BinaryLabelDataset(
    df=df,
    label_names=['approved'],
    protected_attribute_names=['gender']
)

metric = BinaryLabelDatasetMetric(
    dataset,
    unprivileged_groups=[{'gender': 0}],  # ì—¬ì„±
    privileged_groups=[{'gender': 1}]      # ë‚¨ì„±
)

print("=== ë°ì´í„° í¸í–¥ ì§€í‘œ ===")
print(f"Mean Difference: {metric.mean_difference():.3f}")
# ì–‘ìˆ˜: privileged ê·¸ë£¹ì´ ë” ë§ì€ ê¸ì • ë ˆì´ë¸”
print(f"Disparate Impact: {metric.disparate_impact():.3f}")
# 1.0ì—ì„œ ë©€ìˆ˜ë¡ í¸í–¥ ì‹¬í•¨ (0.8 ë¯¸ë§Œì´ë©´ ë²•ì  ë¬¸ì œ ê°€ëŠ¥)

# 2ë‹¨ê³„: ë°ì´í„° ì¬ê°€ì¤‘ì¹˜ (Reweighing)
# ì†Œìˆ˜ ê·¸ë£¹ ìƒ˜í”Œì— ë” í° ê°€ì¤‘ì¹˜ ë¶€ì—¬
RW = Reweighing(
    unprivileged_groups=[{'gender': 0}],
    privileged_groups=[{'gender': 1}]
)
dataset_transformed = RW.fit_transform(dataset)

metric_transformed = BinaryLabelDatasetMetric(
    dataset_transformed,
    unprivileged_groups=[{'gender': 0}],
    privileged_groups=[{'gender': 1}]
)
print(f"\\nì¬ê°€ì¤‘ì¹˜ í›„ Disparate Impact: {metric_transformed.disparate_impact():.3f}")
# â†’ 1.0ì— ê°€ê¹Œì›Œì§ (í¸í–¥ ê°ì†Œ)

# 3ë‹¨ê³„: In-processing í¸í–¥ ì™„í™” (í•™ìŠµ ì¤‘ ê³µì •ì„± í†µí•©)
prejudice_remover = PrejudiceRemover(
    sensitive_attr='gender',
    eta=1.0  # ê³µì •ì„± ì •ê·œí™” ê°•ë„ (ë†’ì„ìˆ˜ë¡ ê³µì •ì„± ìš°ì„ )
)
prejudice_remover.fit(dataset_transformed)

# 4ë‹¨ê³„: ì˜ˆì¸¡ ë° ê³µì •ì„± í‰ê°€
dataset_pred = prejudice_remover.predict(dataset_test)

classification_metric = ClassificationMetric(
    dataset_test,
    dataset_pred,
    unprivileged_groups=[{'gender': 0}],
    privileged_groups=[{'gender': 1}]
)

print("\\n=== ìµœì¢… ê³µì •ì„± ì§€í‘œ ===")
print(f"Equal Opportunity Difference: {classification_metric.equal_opportunity_difference():.3f}")
# 0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ê³µì • (TPR ì°¨ì´)
print(f"Average Odds Difference: {classification_metric.average_odds_difference():.3f}")
# 0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ê³µì • (TPR + FPR ì°¨ì´)
print(f"Disparate Impact: {classification_metric.disparate_impact():.3f}")
print(f"Statistical Parity Difference: {classification_metric.statistical_parity_difference():.3f}")

# 5ë‹¨ê³„: ê³µì •ì„± ëŒ€ì‹œë³´ë“œ (ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§)
from aif360.explainers import MetricTextExplainer

explainer = MetricTextExplainer(classification_metric)
print("\\n" + explainer.explain())`}</code>
            </pre>
          </div>
        </div>

        <div className="bg-blue-50 dark:bg-blue-900/20 p-4 rounded-lg">
          <p className="text-sm font-semibold text-gray-900 dark:text-white mb-2">ë„êµ¬ ì„ íƒ ê°€ì´ë“œ:</p>
          <ul className="list-disc list-inside text-sm text-gray-700 dark:text-gray-300 space-y-1">
            <li><strong>Fairlearn</strong>: ë¹ ë¥¸ ì ìš©, scikit-learn í†µí•©, Microsoft ì§€ì›</li>
            <li><strong>IBM AIF360</strong>: 70+ í¸í–¥ ì§€í‘œ, Pre/In/Post-processing ì•Œê³ ë¦¬ì¦˜, ë²•ë¥  ì¤€ìˆ˜</li>
            <li><strong>Google What-If Tool</strong>: ì‹œê°ì  íƒìƒ‰, TensorFlow/Keras ëª¨ë¸</li>
          </ul>
        </div>
      </section>

      {/* ì„±ë³„/ì¸ì¢… í¸í–¥ ì™„í™” ê¸°ë²• */}
      <section className="mb-12">
        <h2 className="text-3xl font-bold mb-6 text-gray-900 dark:text-white">í¸í–¥ ì™„í™” 3ë‹¨ê³„ ì „ëµ</h2>

        <div className="grid md:grid-cols-3 gap-6">
          <div className="bg-green-50 dark:bg-green-900/20 p-6 rounded-lg">
            <h3 className="text-lg font-bold mb-3 text-gray-900 dark:text-white">Pre-processing</h3>
            <p className="text-sm text-gray-700 dark:text-gray-300 mb-3">
              ë°ì´í„° ìˆ˜ì§‘Â·ì¤€ë¹„ ë‹¨ê³„ì—ì„œ í¸í–¥ ì œê±°
            </p>
            <ul className="text-sm text-gray-700 dark:text-gray-300 space-y-2">
              <li><strong>Reweighing</strong>: ì†Œìˆ˜ ê·¸ë£¹ ìƒ˜í”Œ ê°€ì¤‘ì¹˜ ì¦ê°€</li>
              <li><strong>Sampling</strong>: ê· í˜• ì¡íŒ ë°ì´í„°ì…‹ êµ¬ì„±</li>
              <li><strong>Data Augmentation</strong>: ë¶€ì¡±í•œ ê·¸ë£¹ ë°ì´í„° ìƒì„±</li>
            </ul>
          </div>

          <div className="bg-blue-50 dark:bg-blue-900/20 p-6 rounded-lg">
            <h3 className="text-lg font-bold mb-3 text-gray-900 dark:text-white">In-processing</h3>
            <p className="text-sm text-gray-700 dark:text-gray-300 mb-3">
              ëª¨ë¸ í•™ìŠµ ì‹œ ê³µì •ì„± ì œì•½ ì¶”ê°€
            </p>
            <ul className="text-sm text-gray-700 dark:text-gray-300 space-y-2">
              <li><strong>Adversarial Debiasing</strong>: GAN ê¸°ë°˜ í¸í–¥ ì œê±°</li>
              <li><strong>Prejudice Remover</strong>: ì •ê·œí™” ì†ì‹¤ í•¨ìˆ˜</li>
              <li><strong>Constraint Optimization</strong>: ê³µì •ì„± ì œì•½ ì¡°ê±´</li>
            </ul>
          </div>

          <div className="bg-purple-50 dark:bg-purple-900/20 p-6 rounded-lg">
            <h3 className="text-lg font-bold mb-3 text-gray-900 dark:text-white">Post-processing</h3>
            <p className="text-sm text-gray-700 dark:text-gray-300 mb-3">
              ì˜ˆì¸¡ ê²°ê³¼ í›„ì²˜ë¦¬ë¡œ ê³µì •ì„± ë‹¬ì„±
            </p>
            <ul className="text-sm text-gray-700 dark:text-gray-300 space-y-2">
              <li><strong>Threshold Optimization</strong>: ê·¸ë£¹ë³„ ì„ê³„ê°’ ì¡°ì •</li>
              <li><strong>Equalized Odds</strong>: TPR/FPR ê· ë“±í™”</li>
              <li><strong>Calibration</strong>: ê·¸ë£¹ë³„ í™•ë¥  ë³´ì •</li>
            </ul>
          </div>
        </div>
      </section>

      {/* References */}
      <References
        sections={[
          {
            title: 'ğŸ“š ê³µì •ì„± ì§€í‘œ & í”„ë ˆì„ì›Œí¬',
            icon: 'docs' as const,
            color: 'border-rose-500',
            items: [
              {
                title: 'Fairness Definitions Explained (NIST)',
                url: 'https://pages.nist.gov/privacy_collaborative_research/fairness/definitions.html',
                description: '21ê°œ ê³µì •ì„± ì •ì˜ ë¹„êµ ë¶„ì„ (NIST ë¯¸êµ­ í‘œì¤€ê¸°ìˆ ì—°êµ¬ì†Œ)'
              },
              {
                title: 'Fairness Indicators (Google)',
                url: 'https://www.tensorflow.org/responsible_ai/fairness_indicators/guide',
                description: 'TensorFlow ê¸°ë°˜ ê³µì •ì„± í‰ê°€ ë„êµ¬'
              },
              {
                title: 'Aequitas Toolkit',
                url: 'http://aequitas.dssg.io/',
                description: 'ê°ì‚¬Â·í¸í–¥ í‰ê°€ ì˜¤í”ˆì†ŒìŠ¤ (ì‹œì¹´ê³ ëŒ€ DSSG)'
              },
              {
                title: 'EU AI Act Fairness Requirements',
                url: 'https://artificialintelligenceact.eu/',
                description: 'EU AI Actì˜ ê³ ìœ„í—˜ ì‹œìŠ¤í…œ ê³µì •ì„± ìš”êµ¬ì‚¬í•­ (2024.08 ë°œíš¨)'
              }
            ]
          },
          {
            title: 'ğŸ“– í•µì‹¬ ì—°êµ¬ ë…¼ë¬¸',
            icon: 'research' as const,
            color: 'border-blue-500',
            items: [
              {
                title: 'Machine Bias (ProPublica, 2016)',
                url: 'https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing',
                description: 'COMPAS ì•Œê³ ë¦¬ì¦˜ í¸í–¥ ì¡°ì‚¬ - AI ê³µì •ì„± ë…¼ì˜ì˜ ì‹œë°œì '
              },
              {
                title: 'Fairness and Machine Learning (Book)',
                url: 'https://fairmlbook.org/',
                description: 'Barocas, Hardt, Narayananì˜ ê³µì •ì„± êµê³¼ì„œ (ë¬´ë£Œ ê³µê°œ)'
              },
              {
                title: 'Fairness Constraints: Mechanisms for Fair Classification',
                url: 'https://arxiv.org/abs/1507.05259',
                description: 'Microsoft Research - ê³µì •ì„± ì œì•½ ìµœì í™” ë°©ë²•ë¡ '
              },
              {
                title: 'Inherent Trade-Offs in Algorithmic Fairness',
                url: 'https://arxiv.org/abs/1609.05807',
                description: 'ê³µì •ì„± ì •ì˜ ê°„ ìˆ˜í•™ì  ë¶ˆê°€ëŠ¥ì„± ì¦ëª… (Impossibility Theorem)'
              },
              {
                title: 'Gender Shades: Intersectional Accuracy Disparities',
                url: 'http://gendershades.org/',
                description: 'MIT - ì–¼êµ´ ì¸ì‹ AIì˜ ì„±ë³„Â·ì¸ì¢… í¸í–¥ ì—°êµ¬ (Joy Buolamwini)'
              }
            ]
          },
          {
            title: 'ğŸ› ï¸ ì‹¤ì „ ë„êµ¬',
            icon: 'tools' as const,
            color: 'border-purple-500',
            items: [
              {
                title: 'Fairlearn Documentation',
                url: 'https://fairlearn.org/',
                description: 'Microsoft Fairlearn ê³µì‹ ë¬¸ì„œ ë° íŠœí† ë¦¬ì–¼'
              },
              {
                title: 'IBM AI Fairness 360',
                url: 'https://aif360.mybluemix.net/',
                description: '70+ ê³µì •ì„± ì§€í‘œ, 10+ ì™„í™” ì•Œê³ ë¦¬ì¦˜'
              },
              {
                title: 'Google What-If Tool',
                url: 'https://pair-code.github.io/what-if-tool/',
                description: 'TensorBoard í†µí•© ê³µì •ì„± ì‹œê°í™” ë„êµ¬'
              },
              {
                title: 'LinkedIn Fairness Toolkit (LiFT)',
                url: 'https://github.com/linkedin/lift',
                description: 'Spark ê¸°ë°˜ ëŒ€ê·œëª¨ ê³µì •ì„± ì¸¡ì • (LinkedIn ì˜¤í”ˆì†ŒìŠ¤)'
              },
              {
                title: 'Fairness Gym',
                url: 'https://github.com/google/ml-fairness-gym',
                description: 'Google - ì¥ê¸°ì  ê³µì •ì„± ì˜í–¥ ì‹œë®¬ë ˆì´ì…˜'
              }
            ]
          }
        ]}
      />
    </div>
  );
}

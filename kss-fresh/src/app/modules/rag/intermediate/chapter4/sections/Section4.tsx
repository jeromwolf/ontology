'use client'

import { Cloud } from 'lucide-react'

export default function Section4() {
  return (
    <section className="bg-white dark:bg-gray-800 rounded-2xl p-8 shadow-sm border border-gray-200 dark:border-gray-700">
      <div className="flex items-center gap-3 mb-6">
        <div className="w-12 h-12 rounded-xl bg-green-100 dark:bg-green-900/20 flex items-center justify-center">
          <Cloud className="text-green-600" size={24} />
        </div>
        <div>
          <h2 className="text-2xl font-bold text-gray-900 dark:text-white">4.4 ì—£ì§€ ë””ë°”ì´ìŠ¤ RAG êµ¬í˜„</h2>
          <p className="text-gray-600 dark:text-gray-400">ëª¨ë°”ì¼ê³¼ IoT ë””ë°”ì´ìŠ¤ì—ì„œì˜ RAG</p>
        </div>
      </div>

      <div className="space-y-6">
        <div className="bg-green-50 dark:bg-green-900/20 p-6 rounded-xl border border-green-200 dark:border-green-700">
          <h3 className="font-bold text-green-800 dark:text-green-200 mb-4">ê²½ëŸ‰í™” RAG ì•„í‚¤í…ì²˜</h3>

          <div className="prose prose-sm dark:prose-invert mb-4">
            <p className="text-gray-700 dark:text-gray-300">
              <strong>ëª¨ë°”ì¼ê³¼ IoT í™˜ê²½ì—ì„œ RAGë¥¼ ì‹¤í–‰í•˜ë ¤ë©´ ê·¹ë„ì˜ ìµœì í™”ê°€ í•„ìš”í•©ë‹ˆë‹¤.</strong>
              ì œí•œëœ ë©”ëª¨ë¦¬(~2GB)ì™€ ë°°í„°ë¦¬ë¡œ ë™ì‘í•˜ëŠ” ë””ë°”ì´ìŠ¤ì—ì„œë„ íš¨ìœ¨ì ìœ¼ë¡œ ì‘ë™í•˜ëŠ” ì‹œìŠ¤í…œì„ êµ¬ì¶•í•´ì•¼ í•©ë‹ˆë‹¤.
            </p>
            <p className="text-gray-700 dark:text-gray-300">
              <strong>ì—£ì§€ RAGì˜ í•µì‹¬ ì „ëµ:</strong>
            </p>
            <ul className="list-disc list-inside text-gray-700 dark:text-gray-300 space-y-1">
              <li><strong>SQLite ê¸°ë°˜ ë²¡í„° ì €ì¥</strong>: ì„œë²„ ì—†ì´ ë¡œì»¬ íŒŒì¼ ì‹œìŠ¤í…œ í™œìš©</li>
              <li><strong>ë²¡í„° ì••ì¶•</strong>: Float32 â†’ Float16 + gzipìœ¼ë¡œ 75% ìš©ëŸ‰ ì ˆê°</li>
              <li><strong>ì¤‘ìš”ë„ ê¸°ë°˜ í•„í„°ë§</strong>: ëª¨ë“  ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ì§€ ì•Šê³  ìƒìœ„ Nê°œë§Œ ì²˜ë¦¬</li>
              <li><strong>ì˜¤í”„ë¼ì¸ ìš°ì„ </strong>: ë„¤íŠ¸ì›Œí¬ ì—°ê²° ì—†ì´ë„ ê¸°ë³¸ ê¸°ëŠ¥ ë™ì‘</li>
            </ul>
            <div className="bg-blue-100 dark:bg-blue-900/20 p-3 rounded-lg mt-3">
              <p className="text-sm text-blue-800 dark:text-blue-200">
                <strong>ğŸš€ ì„±ëŠ¥ ì˜ˆì‹œ:</strong> ì•„ë˜ ì½”ë“œëŠ” ë¼ì¦ˆë² ë¦¬ íŒŒì´ 4 (4GB RAM)ì—ì„œ
                10,000ê°œ ë¬¸ì„œë¥¼ 100ms ì´ë‚´ì— ê²€ìƒ‰í•  ìˆ˜ ìˆë„ë¡ ìµœì í™”ë˜ì—ˆìŠµë‹ˆë‹¤.
              </p>
            </div>
          </div>

          <div className="bg-slate-50 dark:bg-slate-800 p-4 rounded-lg overflow-hidden border border-slate-200 dark:border-slate-700">
            <pre className="text-sm text-slate-800 dark:text-slate-200 overflow-x-auto max-h-96 overflow-y-auto font-mono">
{`import sqlite3
import numpy as np
from typing import List, Dict
import json
import gzip

class EdgeRAGSystem:
    """ì—£ì§€ ë””ë°”ì´ìŠ¤ìš© ê²½ëŸ‰í™” RAG ì‹œìŠ¤í…œ"""

    def __init__(self, db_path: str = "edge_rag.db"):
        self.db_path = db_path
        self.init_database()
        self.cache = {}  # ë¡œì»¬ ìºì‹œ
        self.max_cache_size = 100

    def init_database(self):
        """SQLite ê¸°ë°˜ ë¡œì»¬ ë²¡í„° DB ì´ˆê¸°í™”"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        # ì••ì¶•ëœ ë²¡í„°ì™€ ë©”íƒ€ë°ì´í„° ì €ì¥
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS documents (
                id INTEGER PRIMARY KEY,
                content TEXT,
                compressed_vector BLOB,  -- gzip ì••ì¶•ëœ ë²¡í„°
                metadata TEXT,
                category TEXT,
                importance_score REAL,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')

        # ë¹ ë¥¸ ê²€ìƒ‰ì„ ìœ„í•œ ì¸ë±ìŠ¤
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_category ON documents(category)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_importance ON documents(importance_score)')

        conn.commit()
        conn.close()

    def compress_vector(self, vector: np.ndarray) -> bytes:
        """ë²¡í„° ì••ì¶• ì €ì¥"""
        # Float32 -> Float16ìœ¼ë¡œ ì •ë°€ë„ ì¤„ì„
        vector_f16 = vector.astype(np.float16)

        # JSON ì§ë ¬í™” í›„ gzip ì••ì¶•
        vector_bytes = json.dumps(vector_f16.tolist()).encode()
        compressed = gzip.compress(vector_bytes, compresslevel=9)

        return compressed

    def decompress_vector(self, compressed: bytes) -> np.ndarray:
        """ì••ì¶•ëœ ë²¡í„° ë³µì›"""
        decompressed = gzip.decompress(compressed)
        vector_list = json.loads(decompressed.decode())
        return np.array(vector_list, dtype=np.float32)

    def add_document(self, content: str, vector: np.ndarray,
                    metadata: dict, category: str = "general"):
        """ë¬¸ì„œì™€ ë²¡í„° ì¶”ê°€"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        # ì¤‘ìš”ë„ ì ìˆ˜ ê³„ì‚° (ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±)
        importance_score = self.calculate_importance(content, metadata)

        cursor.execute('''
            INSERT INTO documents
            (content, compressed_vector, metadata, category, importance_score)
            VALUES (?, ?, ?, ?, ?)
        ''', (
            content,
            self.compress_vector(vector),
            json.dumps(metadata),
            category,
            importance_score
        ))

        conn.commit()
        conn.close()

    def calculate_importance(self, content: str, metadata: dict) -> float:
        """ë¬¸ì„œ ì¤‘ìš”ë„ ì ìˆ˜ ê³„ì‚°"""
        score = 0.0

        # í…ìŠ¤íŠ¸ ê¸¸ì´ ê¸°ë°˜
        score += min(len(content) / 1000, 1.0) * 0.3

        # ë©”íƒ€ë°ì´í„° ê¸°ë°˜
        if metadata.get('is_primary', False):
            score += 0.5

        # ì¹´í…Œê³ ë¦¬ë³„ ê°€ì¤‘ì¹˜
        category_weights = {
            'faq': 1.0,
            'tutorial': 0.8,
            'reference': 0.6,
            'general': 0.4
        }

        category = metadata.get('category', 'general')
        score += category_weights.get(category, 0.4) * 0.2

        return min(score, 1.0)

    def lightweight_search(self, query_vector: np.ndarray,
                          k: int = 5, category: str = None) -> List[Dict]:
        """ê²½ëŸ‰í™”ëœ ë²¡í„° ê²€ìƒ‰"""
        # ìºì‹œ í™•ì¸
        cache_key = f"{hash(query_vector.tobytes())}_{k}_{category}"
        if cache_key in self.cache:
            return self.cache[cache_key]

        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        # ì¹´í…Œê³ ë¦¬ í•„í„°ë§
        if category:
            cursor.execute('''
                SELECT id, content, compressed_vector, metadata, importance_score
                FROM documents
                WHERE category = ?
                ORDER BY importance_score DESC
                LIMIT 50  -- ìƒìœ„ ë¬¸ì„œë§Œ ê²€ìƒ‰
            ''', (category,))
        else:
            cursor.execute('''
                SELECT id, content, compressed_vector, metadata, importance_score
                FROM documents
                ORDER BY importance_score DESC
                LIMIT 50
            ''')

        rows = cursor.fetchall()
        conn.close()

        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
        similarities = []
        for row in rows:
            doc_id, content, compressed_vector, metadata, importance = row

            # ë²¡í„° ì••ì¶• í•´ì œ
            doc_vector = self.decompress_vector(compressed_vector)

            # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ (ë¹ ë¥¸ ê³„ì‚°)
            similarity = np.dot(query_vector, doc_vector) / (
                np.linalg.norm(query_vector) * np.linalg.norm(doc_vector)
            )

            # ì¤‘ìš”ë„ ì ìˆ˜ì™€ ê²°í•©
            final_score = similarity * 0.8 + importance * 0.2

            similarities.append({
                'id': doc_id,
                'content': content,
                'metadata': json.loads(metadata),
                'similarity': similarity,
                'importance': importance,
                'final_score': final_score
            })

        # ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬ í›„ ìƒìœ„ kê°œ ì„ íƒ
        results = sorted(similarities, key=lambda x: x['final_score'], reverse=True)[:k]

        # ìºì‹œì— ì €ì¥
        self.update_cache(cache_key, results)

        return results

    def update_cache(self, key: str, value: List[Dict]):
        """LRU ìºì‹œ ì—…ë°ì´íŠ¸"""
        if len(self.cache) >= self.max_cache_size:
            # ê°€ì¥ ì˜¤ë˜ëœ í•­ëª© ì œê±°
            oldest_key = next(iter(self.cache))
            del self.cache[oldest_key]

        self.cache[key] = value

    def get_storage_stats(self) -> Dict:
        """ì €ì¥ì†Œ í†µê³„"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        cursor.execute('SELECT COUNT(*) FROM documents')
        doc_count = cursor.fetchone()[0]

        cursor.execute('SELECT AVG(LENGTH(compressed_vector)) FROM documents')
        avg_vector_size = cursor.fetchone()[0] or 0

        # íŒŒì¼ í¬ê¸°
        import os
        db_size = os.path.getsize(self.db_path) if os.path.exists(self.db_path) else 0

        conn.close()

        return {
            'document_count': doc_count,
            'database_size_mb': db_size / (1024**2),
            'avg_compressed_vector_size': avg_vector_size,
            'cache_size': len(self.cache)
        }

# ì‚¬ìš© ì˜ˆì‹œ
edge_rag = EdgeRAGSystem("mobile_rag.db")

# ë¬¸ì„œ ì¶”ê°€ (ì••ì¶•ëœ ë²¡í„°ì™€ í•¨ê»˜)
sample_vector = np.random.randn(384).astype(np.float32)  # ì‘ì€ ì„ë² ë”© ì°¨ì›
edge_rag.add_document(
    content="íŒŒì´ì¬ì€ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì…ë‹ˆë‹¤.",
    vector=sample_vector,
    metadata={"category": "programming", "is_primary": True},
    category="tutorial"
)

# ê²€ìƒ‰
query_vector = np.random.randn(384).astype(np.float32)
results = edge_rag.lightweight_search(query_vector, k=3)

# ì €ì¥ì†Œ í†µê³„
stats = edge_rag.get_storage_stats()
print(f"ì €ì¥ì†Œ í†µê³„: {stats}")`}
            </pre>
          </div>
        </div>
      </div>
    </section>
  )
}

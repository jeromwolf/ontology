'use client'

import { AudioLines } from 'lucide-react'

export default function Section3() {
  return (
    <section className="bg-white dark:bg-gray-800 rounded-2xl p-8 shadow-sm border border-gray-200 dark:border-gray-700">
      <div className="flex items-center gap-3 mb-6">
        <div className="w-12 h-12 rounded-xl bg-green-100 dark:bg-green-900/20 flex items-center justify-center">
          <AudioLines className="text-green-600" size={24} />
        </div>
        <div>
          <h2 className="text-2xl font-bold text-gray-900 dark:text-white">5.3 ì˜¤ë””ì˜¤/ìŒì„± ë°ì´í„° ì²˜ë¦¬</h2>
          <p className="text-gray-600 dark:text-gray-400">ìŒì„± ì¸ì‹ ë° ì˜¤ë””ì˜¤ ê¸°ë°˜ ê²€ìƒ‰</p>
        </div>
      </div>

      <div className="space-y-6">
        <div className="bg-green-50 dark:bg-green-900/20 p-6 rounded-xl border border-green-200 dark:border-green-700">
          <h3 className="font-bold text-green-800 dark:text-green-200 mb-4">ì˜¤ë””ì˜¤ RAG ì‹œìŠ¤í…œ</h3>

          <div className="prose prose-sm dark:prose-invert mb-4">
            <p className="text-gray-700 dark:text-gray-300">
              <strong>ì˜¤ë””ì˜¤ RAGëŠ” ìŒì„± ì¸ì‹ê³¼ ìì—°ì–´ ì²˜ë¦¬ë¥¼ ê²°í•©í•œ ìŒí–¥ ê¸°ë°˜ ì •ë³´ ê²€ìƒ‰ ì‹œìŠ¤í…œì…ë‹ˆë‹¤.</strong>
              OpenAIì˜ Whisper ëª¨ë¸ì„ í™œìš©í•˜ì—¬ 99% ì •í™•ë„ì˜ ë‹¤êµ­ì–´ ìŒì„± ì¸ì‹ì„ êµ¬í˜„í•˜ë©°,
              ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°ê³¼ ë°°ì¹˜ ì²˜ë¦¬ ëª¨ë‘ë¥¼ ì§€ì›í•©ë‹ˆë‹¤.
            </p>
            <p className="text-gray-700 dark:text-gray-300">
              <strong>ì˜¤ë””ì˜¤ RAG í•µì‹¬ ê¸°ìˆ :</strong>
            </p>
            <ul className="list-disc list-inside text-gray-700 dark:text-gray-300 space-y-1">
              <li><strong>Whisper ASR</strong>: 680,000ì‹œê°„ ë‹¤êµ­ì–´ ë°ì´í„°ë¡œ í›ˆë ¨ëœ ìµœê³  ì„±ëŠ¥ ëª¨ë¸</li>
              <li><strong>ë‹¨ì–´ë³„ íƒ€ì„ìŠ¤íƒ¬í”„</strong>: ì •í™•í•œ ì‹œê°„ ë™ê¸°í™”ë¡œ êµ¬ê°„ë³„ ê²€ìƒ‰ ê°€ëŠ¥</li>
              <li><strong>MFCC íŠ¹ì„± ì¶”ì¶œ</strong>: 13ì°¨ì› ë©œ-ì¼‘ìŠ¤íŠ¸ëŸ¼ ê³„ìˆ˜ë¡œ ìŒí–¥ íŠ¹ì„± ë¶„ì„</li>
              <li><strong>í™”ì ë¶„ë¦¬</strong>: ë‹¤ì¤‘ í™”ì í™˜ê²½ì—ì„œ ê°œë³„ ë°œì–¸ì êµ¬ë¶„</li>
            </ul>

            <div className="bg-emerald-50 dark:bg-emerald-900/20 p-4 rounded-lg border border-emerald-200 dark:border-emerald-700 mt-4">
              <h4 className="font-bold text-emerald-800 dark:text-emerald-200 mb-2">ğŸ¯ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬</h4>
              <div className="overflow-x-auto">
                <table className="min-w-full text-sm">
                  <thead>
                    <tr className="border-b border-emerald-300 dark:border-emerald-600">
                      <th className="text-left py-2 text-emerald-800 dark:text-emerald-200">ëª¨ë¸</th>
                      <th className="text-left py-2 text-emerald-800 dark:text-emerald-200">WER</th>
                      <th className="text-left py-2 text-emerald-800 dark:text-emerald-200">ì²˜ë¦¬ì†ë„</th>
                      <th className="text-left py-2 text-emerald-800 dark:text-emerald-200">ì–¸ì–´ì§€ì›</th>
                    </tr>
                  </thead>
                  <tbody className="text-emerald-700 dark:text-emerald-300">
                    <tr>
                      <td className="py-1">Whisper-base</td>
                      <td className="py-1">5.1%</td>
                      <td className="py-1">~6xì‹¤ì‹œê°„</td>
                      <td className="py-1">99ê°œ ì–¸ì–´</td>
                    </tr>
                    <tr>
                      <td className="py-1">Whisper-large</td>
                      <td className="py-1">2.8%</td>
                      <td className="py-1">~2xì‹¤ì‹œê°„</td>
                      <td className="py-1">99ê°œ ì–¸ì–´</td>
                    </tr>
                    <tr>
                      <td className="py-1">Google STT</td>
                      <td className="py-1">4.2%</td>
                      <td className="py-1">ì‹¤ì‹œê°„</td>
                      <td className="py-1">125ê°œ ì–¸ì–´</td>
                    </tr>
                  </tbody>
                </table>
              </div>
            </div>

            <div className="bg-blue-50 dark:bg-blue-900/20 p-4 rounded-lg border border-blue-200 dark:border-blue-700 mt-4">
              <h4 className="font-bold text-blue-800 dark:text-blue-200 mb-2">ğŸ”Š ì‹¤ì œ ì ìš© ë¶„ì•¼</h4>
              <div className="grid md:grid-cols-3 gap-3 text-sm">
                <div>
                  <strong className="text-blue-800 dark:text-blue-200">ì½œì„¼í„° ë¶„ì„</strong>
                  <ul className="list-disc list-inside ml-2 text-blue-700 dark:text-blue-300 mt-1">
                    <li>ê³ ê° ë¶ˆë§Œ í‚¤ì›Œë“œ ê²€ì¶œ</li>
                    <li>ìƒë‹´ì› ìŠ¤í¬ë¦½íŠ¸ ì¤€ìˆ˜ ì²´í¬</li>
                    <li>ê°ì • ë¶„ì„ ë° í’ˆì§ˆ ê´€ë¦¬</li>
                  </ul>
                </div>
                <div>
                  <strong className="text-blue-800 dark:text-blue-200">íšŒì˜ ìŠ¤ë§ˆíŠ¸ ìš”ì•½</strong>
                  <ul className="list-disc list-inside ml-2 text-blue-700 dark:text-blue-300 mt-1">
                    <li>í•µì‹¬ ê²°ì •ì‚¬í•­ ìë™ ì¶”ì¶œ</li>
                    <li>ì•¡ì…˜ ì•„ì´í…œ í• ë‹¹ ì¶”ì </li>
                    <li>ë‹¤ìŒ íšŒì˜ ì–´ì  ë‹¤ ìƒì„±</li>
                  </ul>
                </div>
                <div>
                  <strong className="text-blue-800 dark:text-blue-200">ë°©ì†¡ ì•„ì¹´ì´ë¹™</strong>
                  <ul className="list-disc list-inside ml-2 text-blue-700 dark:text-blue-300 mt-1">
                    <li>ë‰´ìŠ¤ ìë™ ìƒ‰ì¸ ìƒì„±</li>
                    <li>ì¸ë¬¼ ë°œì–¸ ê²€ìƒ‰ ì‹œìŠ¤í…œ</li>
                    <li>ì‹¤ì‹œê°„ ìë§‰ ë° ë²ˆì—­</li>
                  </ul>
                </div>
              </div>
            </div>
          </div>

          <div className="bg-slate-50 dark:bg-slate-800 p-4 rounded-lg overflow-hidden border border-slate-200 dark:border-slate-700">
            <pre className="text-sm text-slate-800 dark:text-slate-200 overflow-x-auto max-h-96 overflow-y-auto font-mono">
{`import whisper
import torch
import librosa
import numpy as np
from typing import List, Dict
from datetime import timedelta
import re

class AudioRAGSystem:
    def __init__(self, whisper_model_size: str = "base"):
        # Whisper ëª¨ë¸ ë¡œë“œ (ìŒì„± ì¸ì‹ìš©)
        self.whisper_model = whisper.load_model(whisper_model_size)

        # ì˜¤ë””ì˜¤ ì„¸ê·¸ë¨¼íŠ¸ ì €ì¥
        self.audio_segments = []
        self.transcripts = []

    def transcribe_audio(self, audio_path: str, language: str = "ko") -> Dict:
        """ì˜¤ë””ì˜¤ íŒŒì¼ ì „ì‚¬"""
        print(f"ì˜¤ë””ì˜¤ ì „ì‚¬ ì‹œì‘: {audio_path}")

        try:
            # Whisperë¡œ ì „ì‚¬
            result = self.whisper_model.transcribe(
                audio_path,
                language=language,
                word_timestamps=True  # ë‹¨ì–´ë³„ íƒ€ì„ìŠ¤íƒ¬í”„
            )

            return {
                'text': result['text'],
                'language': result['language'],
                'segments': result['segments'],
                'audio_path': audio_path,
                'success': True
            }

        except Exception as e:
            print(f"ì „ì‚¬ ì‹¤íŒ¨: {e}")
            return {
                'text': '',
                'error': str(e),
                'success': False
            }

    def extract_audio_features(self, audio_path: str) -> Dict:
        """ì˜¤ë””ì˜¤ íŠ¹ì„± ì¶”ì¶œ"""
        try:
            # ì˜¤ë””ì˜¤ ë¡œë“œ
            y, sr = librosa.load(audio_path)

            # ê¸°ë³¸ íŠ¹ì„±ë“¤
            features = {
                'duration': librosa.get_duration(y=y, sr=sr),
                'sample_rate': sr,
                'rms_energy': float(np.mean(librosa.feature.rms(y=y))),
                'zero_crossing_rate': float(np.mean(librosa.feature.zero_crossing_rate(y))),
                'spectral_centroid': float(np.mean(librosa.feature.spectral_centroid(y=y, sr=sr))),
                'tempo': float(librosa.beat.tempo(y=y, sr=sr)[0])
            }

            # MFCC íŠ¹ì„± (ìŒì„± ì¸ì‹ì— ì¤‘ìš”)
            mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)
            features['mfcc_mean'] = np.mean(mfccs, axis=1).tolist()
            features['mfcc_std'] = np.std(mfccs, axis=1).tolist()

            return features

        except Exception as e:
            print(f"íŠ¹ì„± ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return {}

    def segment_transcript(self, transcript_data: Dict, segment_duration: int = 30) -> List[Dict]:
        """ì „ì‚¬ í…ìŠ¤íŠ¸ë¥¼ ì˜ë¯¸ìˆëŠ” ì„¸ê·¸ë¨¼íŠ¸ë¡œ ë¶„í• """
        segments = []

        if not transcript_data.get('segments'):
            return segments

        current_segment = {
            'start_time': 0,
            'end_time': segment_duration,
            'text': '',
            'words': [],
            'speaker_changes': 0
        }

        for segment in transcript_data['segments']:
            segment_start = segment['start']
            segment_end = segment['end']
            segment_text = segment['text'].strip()

            # ì„¸ê·¸ë¨¼íŠ¸ ì‹œê°„ ë²”ìœ„ í™•ì¸
            if segment_start < current_segment['end_time']:
                current_segment['text'] += ' ' + segment_text
                current_segment['words'].extend(segment.get('words', []))
            else:
                # í˜„ì¬ ì„¸ê·¸ë¨¼íŠ¸ ì €ì¥
                if current_segment['text'].strip():
                    current_segment['word_count'] = len(current_segment['text'].split())
                    current_segment['summary'] = self.summarize_audio_segment(current_segment['text'])
                    segments.append(current_segment.copy())

                # ìƒˆ ì„¸ê·¸ë¨¼íŠ¸ ì‹œì‘
                segment_num = int(segment_start // segment_duration)
                current_segment = {
                    'start_time': segment_num * segment_duration,
                    'end_time': (segment_num + 1) * segment_duration,
                    'text': segment_text,
                    'words': segment.get('words', []),
                    'speaker_changes': 0
                }

        # ë§ˆì§€ë§‰ ì„¸ê·¸ë¨¼íŠ¸
        if current_segment['text'].strip():
            current_segment['word_count'] = len(current_segment['text'].split())
            current_segment['summary'] = self.summarize_audio_segment(current_segment['text'])
            segments.append(current_segment)

        return segments

    def summarize_audio_segment(self, text: str) -> str:
        """ì˜¤ë””ì˜¤ ì„¸ê·¸ë¨¼íŠ¸ ìš”ì•½"""
        if len(text) < 50:
            return text

        # ë¬¸ì¥ ë¶„ë¦¬
        sentences = re.split(r'[.!?]+', text)
        sentences = [s.strip() for s in sentences if len(s.strip()) > 10]

        if len(sentences) <= 2:
            return text

        # ì²« ë¬¸ì¥ê³¼ ë§ˆì§€ë§‰ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½ êµ¬ì„±
        summary = f"{sentences[0]}... {sentences[-1]}"
        return summary[:150]  # 150ìë¡œ ì œí•œ

    def search_audio_content(self, query: str, audio_segments: List[Dict]) -> List[Dict]:
        """ì˜¤ë””ì˜¤ ë‚´ìš©ì—ì„œ ê²€ìƒ‰"""
        results = []
        query_words = query.lower().split()

        for segment in audio_segments:
            segment_text = segment.get('text', '').lower()

            # í‚¤ì›Œë“œ ë§¤ì¹­ ì ìˆ˜
            matches = sum(1 for word in query_words if word in segment_text)
            keyword_score = matches / len(query_words) if query_words else 0

            # í…ìŠ¤íŠ¸ í¬í•¨ ì ìˆ˜ (ë¶€ë¶„ ë¬¸ìì—´)
            substring_score = 0.5 if query.lower() in segment_text else 0

            # ìµœì¢… ì ìˆ˜
            final_score = max(keyword_score, substring_score)

            if final_score > 0.2:  # 20% ì´ìƒ ë§¤ì¹­ì‹œ í¬í•¨
                # ê´€ë ¨ êµ¬ë¬¸ ì¶”ì¶œ
                relevant_phrases = self.extract_relevant_phrases(
                    segment_text, query_words
                )

                results.append({
                    'segment': segment,
                    'score': final_score,
                    'start_time': segment['start_time'],
                    'end_time': segment['end_time'],
                    'relevant_text': relevant_phrases,
                    'context': segment.get('summary', '')
                })

        # ì ìˆ˜ìˆœ ì •ë ¬
        results.sort(key=lambda x: x['score'], reverse=True)
        return results

    def extract_relevant_phrases(self, text: str, query_words: List[str],
                                context_window: int = 50) -> List[str]:
        """ì¿¼ë¦¬ ê´€ë ¨ êµ¬ë¬¸ ì¶”ì¶œ"""
        phrases = []
        text_lower = text.lower()

        for word in query_words:
            if word in text_lower:
                # ë‹¨ì–´ ìœ„ì¹˜ ì°¾ê¸°
                start_pos = text_lower.find(word)

                # ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš° ì ìš©
                start = max(0, start_pos - context_window)
                end = min(len(text), start_pos + len(word) + context_window)

                phrase = text[start:end].strip()
                if phrase and phrase not in phrases:
                    phrases.append(phrase)

        return phrases[:3]  # ìµœëŒ€ 3ê°œ êµ¬ë¬¸

    def process_audio_file(self, audio_path: str) -> Dict:
        """ì˜¤ë””ì˜¤ íŒŒì¼ ì „ì²´ ì²˜ë¦¬"""
        print("1. ì˜¤ë””ì˜¤ ì „ì‚¬ ì¤‘...")
        transcript = self.transcribe_audio(audio_path)

        if not transcript['success']:
            return {'error': 'ì „ì‚¬ ì‹¤íŒ¨', 'transcript': transcript}

        print("2. ì˜¤ë””ì˜¤ íŠ¹ì„± ì¶”ì¶œ ì¤‘...")
        features = self.extract_audio_features(audio_path)

        print("3. ì„¸ê·¸ë¨¼íŠ¸ ìƒì„± ì¤‘...")
        segments = self.segment_transcript(transcript, segment_duration=30)

        return {
            'audio_path': audio_path,
            'transcript': transcript,
            'features': features,
            'segments': segments,
            'total_duration': features.get('duration', 0),
            'segment_count': len(segments)
        }

# ì‚¬ìš© ì˜ˆì‹œ
audio_rag = AudioRAGSystem(whisper_model_size="small")

# ì˜¤ë””ì˜¤ íŒŒì¼ ì²˜ë¦¬
# audio_data = audio_rag.process_audio_file('/path/to/lecture.mp3')

# if 'error' not in audio_data:
#     print(f"ì²˜ë¦¬ ì™„ë£Œ:")
#     print(f"  ì´ ê¸¸ì´: {audio_data['total_duration']:.1f}ì´ˆ")
#     print(f"  ì„¸ê·¸ë¨¼íŠ¸ ìˆ˜: {audio_data['segment_count']}ê°œ")
#     print(f"  ì „ì²´ í…ìŠ¤íŠ¸: {len(audio_data['transcript']['text'])}ì")
#
#     # ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
#     results = audio_rag.search_audio_content("ë¨¸ì‹ ëŸ¬ë‹", audio_data['segments'])
#
#     print(f"\\nê²€ìƒ‰ ê²°ê³¼: {len(results)}ê±´")
#     for i, result in enumerate(results[:3]):
#         print(f"{i+1}. ì‹œê°„: {result['start_time']}s-{result['end_time']}s")
#         print(f"   ì ìˆ˜: {result['score']:.3f}")
#         print(f"   ë‚´ìš©: {result['context'][:100]}...")
# else:
#     print(f"ì²˜ë¦¬ ì‹¤íŒ¨: {audio_data['error']}")`}
            </pre>
          </div>
        </div>
      </div>
    </section>
  )
}

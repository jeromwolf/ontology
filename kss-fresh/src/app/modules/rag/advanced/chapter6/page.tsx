'use client'

import Link from 'next/link'
import { ArrowLeft, ArrowRight, Sparkles, Brain, Rocket, TrendingUp, Layers, Eye } from 'lucide-react'

export default function Chapter6Page() {
  return (
    <div className="max-w-4xl mx-auto py-8 px-4">
      {/* Header */}
      <div className="mb-8">
        <Link
          href="/modules/rag/advanced"
          className="inline-flex items-center gap-2 text-emerald-600 hover:text-emerald-700 mb-4 transition-colors"
        >
          <ArrowLeft size={20} />
          ê³ ê¸‰ ê³¼ì •ìœ¼ë¡œ ëŒì•„ê°€ê¸°
        </Link>
        
        <div className="bg-gradient-to-r from-violet-500 to-purple-600 rounded-2xl p-8 text-white">
          <div className="flex items-center gap-4 mb-4">
            <div className="w-16 h-16 rounded-xl bg-white/20 flex items-center justify-center">
              <Sparkles size={32} />
            </div>
            <div>
              <h1 className="text-3xl font-bold">Chapter 6: RAGì˜ ìµœì‹  ì—°êµ¬ ë™í–¥</h1>
              <p className="text-violet-100 text-lg">2024ë…„ ìµœì‹  ë…¼ë¬¸ê³¼ ë¯¸ë˜ ê¸°ìˆ  ì „ë§</p>
            </div>
          </div>
        </div>
      </div>

      {/* Content */}
      <div className="space-y-8">
        {/* Section 1: Self-RAG - ìê¸° ì„±ì°°í•˜ëŠ” RAG */}
        <section className="bg-white dark:bg-gray-800 rounded-2xl p-8 shadow-sm border border-gray-200 dark:border-gray-700">
          <div className="flex items-center gap-3 mb-6">
            <div className="w-12 h-12 rounded-xl bg-violet-100 dark:bg-violet-900/20 flex items-center justify-center">
              <Brain className="text-violet-600" size={24} />
            </div>
            <div>
              <h2 className="text-2xl font-bold text-gray-900 dark:text-white">6.1 Self-RAG: ìê¸° ì„±ì°°í•˜ëŠ” ê²€ìƒ‰ ì¦ê°• ìƒì„±</h2>
              <p className="text-gray-600 dark:text-gray-400">Washington Universityì˜ í˜ì‹ ì  ì—°êµ¬ (2023.10)</p>
            </div>
          </div>

          <div className="space-y-6">
            <div className="bg-violet-50 dark:bg-violet-900/20 p-6 rounded-xl border border-violet-200 dark:border-violet-700">
              <h3 className="font-bold text-violet-800 dark:text-violet-200 mb-4">Self-RAGì˜ í˜ì‹ ì  ì ‘ê·¼ë²•</h3>
              
              <div className="prose prose-sm dark:prose-invert mb-4">
                <p className="text-gray-700 dark:text-gray-300">
                  <strong>Self-RAGëŠ” ê¸°ì¡´ RAGì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ëŠ” íŒ¨ëŸ¬ë‹¤ì„ ì „í™˜ì…ë‹ˆë‹¤.</strong>
                  ëª¨ë¸ì´ ìŠ¤ìŠ¤ë¡œ ê²€ìƒ‰ í•„ìš”ì„±ì„ íŒë‹¨í•˜ê³ , ê²€ìƒ‰ëœ ì •ë³´ì˜ ê´€ë ¨ì„±ì„ í‰ê°€í•˜ë©°,
                  ìƒì„±ëœ ë‹µë³€ì˜ í’ˆì§ˆì„ ìì²´ì ìœ¼ë¡œ ê²€ì¦í•©ë‹ˆë‹¤. ì´ëŠ” ì¸ê°„ì˜ ë¹„íŒì  ì‚¬ê³  ê³¼ì •ì„
                  ëª¨ë°©í•œ ê²ƒìœ¼ë¡œ, RAG ì‹œìŠ¤í…œì˜ ì‹ ë¢°ì„±ê³¼ íš¨ìœ¨ì„±ì„ í¬ê²Œ í–¥ìƒì‹œí‚µë‹ˆë‹¤.
                </p>
              </div>

              <div className="grid md:grid-cols-3 gap-4">
                <div className="bg-white dark:bg-gray-800 p-4 rounded-lg border">
                  <h4 className="font-medium text-violet-600 dark:text-violet-400 mb-2">ğŸ¤” Retrieval Decision</h4>
                  <p className="text-sm text-gray-700 dark:text-gray-300">
                    ì¿¼ë¦¬ ë¶„ì„ì„ í†µí•´ ì™¸ë¶€ ì§€ì‹ì´ í•„ìš”í•œì§€ ìŠ¤ìŠ¤ë¡œ íŒë‹¨
                  </p>
                </div>
                
                <div className="bg-white dark:bg-gray-800 p-4 rounded-lg border">
                  <h4 className="font-medium text-blue-600 dark:text-blue-400 mb-2">âœ… Relevance Check</h4>
                  <p className="text-sm text-gray-700 dark:text-gray-300">
                    ê²€ìƒ‰ëœ ê° ë¬¸ì„œì˜ ê´€ë ¨ì„±ì„ ìì²´ í‰ê°€í•˜ì—¬ í•„í„°ë§
                  </p>
                </div>
                
                <div className="bg-white dark:bg-gray-800 p-4 rounded-lg border">
                  <h4 className="font-medium text-green-600 dark:text-green-400 mb-2">ğŸ“Š Self-Reflection</h4>
                  <p className="text-sm text-gray-700 dark:text-gray-300">
                    ìƒì„±ëœ ë‹µë³€ì˜ í’ˆì§ˆê³¼ ì •í™•ì„±ì„ ìŠ¤ìŠ¤ë¡œ ê²€ì¦
                  </p>
                </div>
              </div>
            </div>

            <div className="bg-blue-50 dark:bg-blue-900/20 p-6 rounded-xl border border-blue-200 dark:border-blue-700">
              <h3 className="font-bold text-blue-800 dark:text-blue-200 mb-4">Self-RAG êµ¬í˜„ ë° í•™ìŠµ</h3>
              
              <div className="bg-slate-50 dark:bg-slate-800 p-4 rounded-lg border border-slate-200 dark:border-slate-700 overflow-x-auto">
                <pre className="text-sm text-slate-800 dark:text-slate-200 font-mono">
{`import torch
import torch.nn as nn
from typing import List, Dict, Tuple, Optional, Any
from transformers import AutoModel, AutoTokenizer
from dataclasses import dataclass
import numpy as np
from enum import Enum

class ReflectionToken(Enum):
    """Self-RAG íŠ¹ìˆ˜ í† í°"""
    RETRIEVE = "[Retrieve]"
    NO_RETRIEVE = "[No Retrieve]"
    RELEVANT = "[Relevant]"
    IRRELEVANT = "[Irrelevant]" 
    SUPPORTED = "[Supported]"
    NOT_SUPPORTED = "[Not Supported]"
    USEFUL = "[Useful]"
    NOT_USEFUL = "[Not Useful]"

@dataclass
class SelfRAGOutput:
    """Self-RAG ì¶œë ¥ êµ¬ì¡°"""
    answer: str
    retrieve_decision: bool
    relevance_scores: List[float]
    support_scores: List[float]
    utility_score: float
    retrieved_docs: List[Dict[str, Any]]
    reflection_tokens: List[str]

class SelfRAG(nn.Module):
    def __init__(self, base_model: str = "meta-llama/Llama-2-7b-hf"):
        """
        Self-RAG ëª¨ë¸ êµ¬í˜„
        - ì ì‘í˜• ê²€ìƒ‰ ê²°ì •
        - ë‹¤ì¤‘ í‰ê°€ ë©”ì»¤ë‹ˆì¦˜
        - ìê¸° ì„±ì°° ìƒì„±
        """
        super().__init__()
        
        # ê¸°ë³¸ ì–¸ì–´ ëª¨ë¸
        self.base_model = AutoModel.from_pretrained(base_model)
        self.tokenizer = AutoTokenizer.from_pretrained(base_model)
        
        # íŠ¹ìˆ˜ í† í° ì¶”ê°€
        self._add_special_tokens()
        
        # í‰ê°€ í—¤ë“œë“¤
        hidden_size = self.base_model.config.hidden_size
        self.retrieve_classifier = nn.Linear(hidden_size, 2)  # ê²€ìƒ‰ í•„ìš”ì„±
        self.relevance_classifier = nn.Linear(hidden_size, 2)  # ê´€ë ¨ì„±
        self.support_classifier = nn.Linear(hidden_size, 2)  # ì§€ì›ë„
        self.utility_classifier = nn.Linear(hidden_size, 2)  # ìœ ìš©ì„±
        
        # ê²€ìƒ‰ ì—”ì§„ (ì‹œë®¬ë ˆì´ì…˜)
        self.retriever = None  # ì‹¤ì œë¡œëŠ” Dense Retriever
        
    def _add_special_tokens(self):
        """íŠ¹ìˆ˜ í† í° ì¶”ê°€"""
        special_tokens = [token.value for token in ReflectionToken]
        self.tokenizer.add_special_tokens({'additional_special_tokens': special_tokens})
        self.base_model.resize_token_embeddings(len(self.tokenizer))
        
    def forward(self, query: str, context: Optional[str] = None) -> SelfRAGOutput:
        """
        Self-RAG ì „ì²´ íŒŒì´í”„ë¼ì¸
        """
        # 1ë‹¨ê³„: ê²€ìƒ‰ í•„ìš”ì„± íŒë‹¨
        retrieve_decision = self._decide_retrieval(query, context)
        
        retrieved_docs = []
        relevance_scores = []
        
        # 2ë‹¨ê³„: ì¡°ê±´ë¶€ ê²€ìƒ‰
        if retrieve_decision:
            # ë¬¸ì„œ ê²€ìƒ‰
            retrieved_docs = self._retrieve_documents(query)
            
            # ê° ë¬¸ì„œì˜ ê´€ë ¨ì„± í‰ê°€
            for doc in retrieved_docs:
                relevance = self._evaluate_relevance(query, doc['content'])
                relevance_scores.append(relevance)
                doc['relevance_score'] = relevance
            
            # ê´€ë ¨ì„± ë†’ì€ ë¬¸ì„œë§Œ í•„í„°ë§
            threshold = 0.5
            filtered_docs = [doc for doc, score in zip(retrieved_docs, relevance_scores) 
                           if score > threshold]
        else:
            filtered_docs = []
        
        # 3ë‹¨ê³„: ë‹µë³€ ìƒì„±
        answer, support_scores = self._generate_with_reflection(
            query, filtered_docs, context
        )
        
        # 4ë‹¨ê³„: ìµœì¢… ìœ ìš©ì„± í‰ê°€
        utility_score = self._evaluate_utility(query, answer)
        
        # 5ë‹¨ê³„: ë°˜ì˜ í† í° ìƒì„±
        reflection_tokens = self._generate_reflection_tokens(
            retrieve_decision, relevance_scores, support_scores, utility_score
        )
        
        return SelfRAGOutput(
            answer=answer,
            retrieve_decision=retrieve_decision,
            relevance_scores=relevance_scores,
            support_scores=support_scores,
            utility_score=utility_score,
            retrieved_docs=retrieved_docs,
            reflection_tokens=reflection_tokens
        )
    
    def _decide_retrieval(self, query: str, context: Optional[str] = None) -> bool:
        """ê²€ìƒ‰ í•„ìš”ì„± ê²°ì •"""
        # ì¿¼ë¦¬ ì¸ì½”ë”©
        prompt = f"Query: {query}"
        if context:
            prompt = f"Context: {context}\n{prompt}"
        
        inputs = self.tokenizer(prompt, return_tensors="pt", 
                               truncation=True, max_length=512)
        
        with torch.no_grad():
            outputs = self.base_model(**inputs)
            hidden_states = outputs.last_hidden_state
            
            # ë§ˆì§€ë§‰ í† í°ì˜ hidden state ì‚¬ìš©
            pooled = hidden_states[:, -1, :]
            
            # ê²€ìƒ‰ í•„ìš”ì„± ë¶„ë¥˜
            logits = self.retrieve_classifier(pooled)
            prob_retrieve = torch.softmax(logits, dim=-1)[0, 1].item()
        
        # ì„ê³„ê°’ ê¸°ë°˜ ê²°ì •
        return prob_retrieve > 0.5
    
    def _retrieve_documents(self, query: str, top_k: int = 5) -> List[Dict[str, Any]]:
        """ë¬¸ì„œ ê²€ìƒ‰ (ì‹œë®¬ë ˆì´ì…˜)"""
        # ì‹¤ì œë¡œëŠ” Dense Retriever ì‚¬ìš©
        sample_docs = [
            {
                'id': f'doc_{i}',
                'content': f'This is a sample document {i} related to {query}',
                'score': 0.9 - i * 0.1
            }
            for i in range(top_k)
        ]
        return sample_docs
    
    def _evaluate_relevance(self, query: str, document: str) -> float:
        """ë¬¸ì„œ ê´€ë ¨ì„± í‰ê°€"""
        prompt = f"Query: {query}\nDocument: {document}\nIs this document relevant?"
        
        inputs = self.tokenizer(prompt, return_tensors="pt", 
                               truncation=True, max_length=512)
        
        with torch.no_grad():
            outputs = self.base_model(**inputs)
            hidden_states = outputs.last_hidden_state
            pooled = hidden_states[:, -1, :]
            
            logits = self.relevance_classifier(pooled)
            prob_relevant = torch.softmax(logits, dim=-1)[0, 1].item()
        
        return prob_relevant
    
    def _generate_with_reflection(self, query: str, documents: List[Dict[str, Any]], 
                                 context: Optional[str] = None) -> Tuple[str, List[float]]:
        """ë°˜ì˜ì„ í¬í•¨í•œ ë‹µë³€ ìƒì„±"""
        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt_parts = []
        
        if context:
            prompt_parts.append(f"Context: {context}")
        
        prompt_parts.append(f"Query: {query}")
        
        if documents:
            prompt_parts.append("\nRetrieved Documents:")
            for i, doc in enumerate(documents):
                prompt_parts.append(f"[{i+1}] {doc['content']}")
        
        prompt_parts.append("\nGenerate answer with reflection:")
        prompt = "\n".join(prompt_parts)
        
        # ë‹µë³€ ìƒì„±
        inputs = self.tokenizer(prompt, return_tensors="pt", 
                               truncation=True, max_length=1024)
        
        with torch.no_grad():
            # ìƒì„± ì‹œ íŠ¹ìˆ˜ í† í° í¬í•¨
            outputs = self.base_model.generate(
                **inputs,
                max_new_tokens=200,
                temperature=0.7,
                do_sample=True,
                pad_token_id=self.tokenizer.pad_token_id
            )
        
        generated_text = self.tokenizer.decode(outputs[0], skip_special_tokens=False)
        
        # ë‹µë³€ê³¼ ì§€ì›ë„ ì ìˆ˜ ì¶”ì¶œ
        answer, support_scores = self._parse_generated_output(generated_text, documents)
        
        return answer, support_scores
    
    def _parse_generated_output(self, generated_text: str, 
                               documents: List[Dict[str, Any]]) -> Tuple[str, List[float]]:
        """ìƒì„±ëœ ì¶œë ¥ íŒŒì‹±"""
        # íŠ¹ìˆ˜ í† í° ê¸°ë°˜ìœ¼ë¡œ íŒŒì‹±
        answer_parts = []
        support_scores = []
        
        # ê°„ë‹¨í•œ íŒŒì‹± (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ ë¡œì§ í•„ìš”)
        lines = generated_text.split('\n')
        for line in lines:
            if ReflectionToken.SUPPORTED.value in line:
                support_scores.append(1.0)
            elif ReflectionToken.NOT_SUPPORTED.value in line:
                support_scores.append(0.0)
            elif not any(token.value in line for token in ReflectionToken):
                answer_parts.append(line)
        
        # ë¶€ì¡±í•œ support scoreëŠ” 0ìœ¼ë¡œ ì±„ì›€
        while len(support_scores) < len(documents):
            support_scores.append(0.0)
        
        answer = ' '.join(answer_parts).strip()
        return answer, support_scores
    
    def _evaluate_utility(self, query: str, answer: str) -> float:
        """ë‹µë³€ì˜ ìœ ìš©ì„± í‰ê°€"""
        prompt = f"Query: {query}\nAnswer: {answer}\nIs this answer useful?"
        
        inputs = self.tokenizer(prompt, return_tensors="pt", 
                               truncation=True, max_length=512)
        
        with torch.no_grad():
            outputs = self.base_model(**inputs)
            hidden_states = outputs.last_hidden_state
            pooled = hidden_states[:, -1, :]
            
            logits = self.utility_classifier(pooled)
            prob_useful = torch.softmax(logits, dim=-1)[0, 1].item()
        
        return prob_useful
    
    def _generate_reflection_tokens(self, retrieve_decision: bool,
                                   relevance_scores: List[float],
                                   support_scores: List[float],
                                   utility_score: float) -> List[str]:
        """ë°˜ì˜ í† í° ìƒì„±"""
        tokens = []
        
        # ê²€ìƒ‰ ê²°ì •
        if retrieve_decision:
            tokens.append(ReflectionToken.RETRIEVE.value)
        else:
            tokens.append(ReflectionToken.NO_RETRIEVE.value)
        
        # ê´€ë ¨ì„± í‰ê°€
        for score in relevance_scores:
            if score > 0.5:
                tokens.append(ReflectionToken.RELEVANT.value)
            else:
                tokens.append(ReflectionToken.IRRELEVANT.value)
        
        # ì§€ì›ë„ í‰ê°€
        for score in support_scores:
            if score > 0.5:
                tokens.append(ReflectionToken.SUPPORTED.value)
            else:
                tokens.append(ReflectionToken.NOT_SUPPORTED.value)
        
        # ìœ ìš©ì„± í‰ê°€
        if utility_score > 0.5:
            tokens.append(ReflectionToken.USEFUL.value)
        else:
            tokens.append(ReflectionToken.NOT_USEFUL.value)
        
        return tokens

# Self-RAG í•™ìŠµì„ ìœ„í•œ ë°ì´í„° ìƒì„±
class SelfRAGDataGenerator:
    def __init__(self):
        """Self-RAG í•™ìŠµ ë°ì´í„° ìƒì„±ê¸°"""
        self.critique_model = None  # GPT-4 ë“± ì‚¬ìš©
        
    def generate_training_data(self, qa_pairs: List[Dict[str, str]], 
                             documents: List[str]) -> List[Dict[str, Any]]:
        """í•™ìŠµ ë°ì´í„° ìƒì„±"""
        training_data = []
        
        for qa in qa_pairs:
            query = qa['question']
            answer = qa['answer']
            
            # 1. ê²€ìƒ‰ í•„ìš”ì„± ë ˆì´ë¸”
            retrieve_needed = self._label_retrieval_need(query, answer)
            
            # 2. ê´€ë ¨ ë¬¸ì„œ ìƒ˜í”Œë§
            if retrieve_needed:
                sampled_docs = self._sample_documents(query, documents)
                
                # 3. ê´€ë ¨ì„± ë ˆì´ë¸”ë§
                relevance_labels = []
                for doc in sampled_docs:
                    relevance = self._label_relevance(query, doc)
                    relevance_labels.append(relevance)
                
                # 4. ì§€ì›ë„ ë ˆì´ë¸”ë§
                support_labels = self._label_support(answer, sampled_docs)
            else:
                sampled_docs = []
                relevance_labels = []
                support_labels = []
            
            # 5. ìœ ìš©ì„± ë ˆì´ë¸”
            utility_label = self._label_utility(query, answer)
            
            training_data.append({
                'query': query,
                'answer': answer,
                'retrieve_needed': retrieve_needed,
                'documents': sampled_docs,
                'relevance_labels': relevance_labels,
                'support_labels': support_labels,
                'utility_label': utility_label
            })
        
        return training_data
    
    def _label_retrieval_need(self, query: str, answer: str) -> bool:
        """ê²€ìƒ‰ í•„ìš”ì„± ë ˆì´ë¸”ë§"""
        # íœ´ë¦¬ìŠ¤í‹±: íŒ©íŠ¸ ê¸°ë°˜ ì§ˆë¬¸ì€ ê²€ìƒ‰ í•„ìš”
        fact_keywords = ['when', 'where', 'who', 'how many', 'what year']
        return any(kw in query.lower() for kw in fact_keywords)
    
    def _sample_documents(self, query: str, documents: List[str], k: int = 5) -> List[str]:
        """ë¬¸ì„œ ìƒ˜í”Œë§ (BM25 ë“± ì‚¬ìš©)"""
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ë§¤ì¹­
        query_words = set(query.lower().split())
        scored_docs = []
        
        for doc in documents:
            doc_words = set(doc.lower().split())
            score = len(query_words.intersection(doc_words))
            scored_docs.append((doc, score))
        
        scored_docs.sort(key=lambda x: x[1], reverse=True)
        return [doc for doc, _ in scored_docs[:k]]
    
    def _label_relevance(self, query: str, document: str) -> float:
        """ê´€ë ¨ì„± ë ˆì´ë¸”ë§"""
        # ì‹¤ì œë¡œëŠ” ì¸ê°„ í‰ê°€ ë˜ëŠ” GPT-4 ì‚¬ìš©
        query_words = set(query.lower().split())
        doc_words = set(document.lower().split())
        overlap = len(query_words.intersection(doc_words))
        return min(overlap / len(query_words), 1.0) if query_words else 0.0
    
    def _label_support(self, answer: str, documents: List[str]) -> List[float]:
        """ì§€ì›ë„ ë ˆì´ë¸”ë§"""
        support_scores = []
        answer_words = set(answer.lower().split())
        
        for doc in documents:
            doc_words = set(doc.lower().split())
            overlap = len(answer_words.intersection(doc_words))
            score = min(overlap / len(answer_words), 1.0) if answer_words else 0.0
            support_scores.append(score)
        
        return support_scores
    
    def _label_utility(self, query: str, answer: str) -> float:
        """ìœ ìš©ì„± ë ˆì´ë¸”ë§"""
        # ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±: ë‹µë³€ ê¸¸ì´ì™€ ì§ˆë¬¸ ë‹¨ì–´ í¬í•¨ë„
        if len(answer.split()) < 5:
            return 0.3
        
        query_words = set(query.lower().split())
        answer_words = set(answer.lower().split())
        coverage = len(query_words.intersection(answer_words)) / len(query_words)
        
        return min(0.5 + coverage * 0.5, 1.0)

# ì‚¬ìš© ì˜ˆì œ
print("=== Self-RAG ë°ëª¨ ===\n")

# Self-RAG ëª¨ë¸ ì´ˆê¸°í™”
self_rag = SelfRAG()

# í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬
queries = [
    "What is the capital of France?",  # íŒ©íŠ¸ ì§ˆë¬¸ - ê²€ìƒ‰ í•„ìš”
    "Hello, how are you?",  # ì¼ë°˜ ëŒ€í™” - ê²€ìƒ‰ ë¶ˆí•„ìš”
    "Explain the theory of relativity",  # ë³µì¡í•œ ì„¤ëª… - ê²€ìƒ‰ ë„ì›€
]

for query in queries:
    print(f"\nQuery: {query}")
    
    # Self-RAG ì‹¤í–‰
    output = self_rag(query)
    
    print(f"Retrieve Decision: {output.retrieve_decision}")
    if output.retrieve_decision:
        print(f"Retrieved {len(output.retrieved_docs)} documents")
        print(f"Relevance Scores: {[f'{s:.2f}' for s in output.relevance_scores]}")
    print(f"Answer: {output.answer}")
    print(f"Utility Score: {output.utility_score:.2f}")
    print(f"Reflection Tokens: {' '.join(output.reflection_tokens[:5])}...")

# í•™ìŠµ ë°ì´í„° ìƒì„± ì˜ˆì œ
data_generator = SelfRAGDataGenerator()

qa_pairs = [
    {"question": "What is machine learning?", 
     "answer": "Machine learning is a subset of AI that enables systems to learn from data."},
    {"question": "How's the weather?",
     "answer": "I don't have access to real-time weather data."}
]

documents = [
    "Machine learning is a method of data analysis that automates analytical model building.",
    "AI and machine learning are transforming industries.",
    "The weather forecast requires current atmospheric data."
]

training_data = data_generator.generate_training_data(qa_pairs, documents)

print("\n\n=== Generated Training Data ===")
for i, data in enumerate(training_data):
    print(f"\nExample {i+1}:")
    print(f"Query: {data['query']}")
    print(f"Retrieve Needed: {data['retrieve_needed']}")
    print(f"Utility Label: {data['utility_label']:.2f}")`}
                </pre>
              </div>
            </div>

            <div className="bg-green-50 dark:bg-green-900/20 p-6 rounded-xl border border-green-200 dark:border-green-700">
              <h3 className="font-bold text-green-800 dark:text-green-200 mb-4">Self-RAG ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬</h3>
              
              <div className="grid md:grid-cols-2 gap-4">
                <div className="bg-white dark:bg-gray-800 p-4 rounded-lg border">
                  <h4 className="font-medium text-gray-900 dark:text-white mb-3">Open-domain QA ì„±ëŠ¥</h4>
                  <div className="space-y-2">
                    <div className="flex justify-between text-sm">
                      <span>Self-RAG (7B)</span>
                      <span className="font-bold text-green-600">54.9</span>
                    </div>
                    <div className="flex justify-between text-sm">
                      <span>ChatGPT</span>
                      <span>44.0</span>
                    </div>
                    <div className="flex justify-between text-sm">
                      <span>Llama2-chat (7B)</span>
                      <span>28.2</span>
                    </div>
                    <div className="flex justify-between text-sm">
                      <span>Alpaca (7B)</span>
                      <span>24.5</span>
                    </div>
                  </div>
                </div>
                
                <div className="bg-white dark:bg-gray-800 p-4 rounded-lg border">
                  <h4 className="font-medium text-gray-900 dark:text-white mb-3">íš¨ìœ¨ì„± ê°œì„ </h4>
                  <div className="space-y-2">
                    <div className="bg-blue-50 dark:bg-blue-900/30 p-2 rounded">
                      <p className="text-sm"><strong>ê²€ìƒ‰ íšŸìˆ˜:</strong> 60% ê°ì†Œ</p>
                    </div>
                    <div className="bg-green-50 dark:bg-green-900/30 p-2 rounded">
                      <p className="text-sm"><strong>ì •í™•ë„:</strong> 15% í–¥ìƒ</p>
                    </div>
                    <div className="bg-purple-50 dark:bg-purple-900/30 p-2 rounded">
                      <p className="text-sm"><strong>í™˜ê°ë¥ :</strong> 70% ê°ì†Œ</p>
                    </div>
                  </div>
                </div>
              </div>
            </div>
          </div>
        </section>

        {/* Section 2: RAPTOR - ê³„ì¸µì  ìš”ì•½ */}
        <section className="bg-white dark:bg-gray-800 rounded-2xl p-8 shadow-sm border border-gray-200 dark:border-gray-700">
          <div className="flex items-center gap-3 mb-6">
            <div className="w-12 h-12 rounded-xl bg-orange-100 dark:bg-orange-900/20 flex items-center justify-center">
              <Layers className="text-orange-600" size={24} />
            </div>
            <div>
              <h2 className="text-2xl font-bold text-gray-900 dark:text-white">6.2 RAPTOR: ì¬ê·€ì  íŠ¸ë¦¬ êµ¬ì¡°ì˜ ê²€ìƒ‰</h2>
              <p className="text-gray-600 dark:text-gray-400">Stanfordì˜ ê³„ì¸µì  ë¬¸ì„œ êµ¬ì¡°í™” ì—°êµ¬ (2024.01)</p>
            </div>
          </div>

          <div className="space-y-6">
            <div className="bg-orange-50 dark:bg-orange-900/20 p-6 rounded-xl border border-orange-200 dark:border-orange-700">
              <h3 className="font-bold text-orange-800 dark:text-orange-200 mb-4">RAPTORì˜ í˜ì‹ : ì¬ê·€ì  ìš”ì•½ íŠ¸ë¦¬</h3>
              
              <div className="prose prose-sm dark:prose-invert mb-4">
                <p className="text-gray-700 dark:text-gray-300">
                  <strong>RAPTOR(Recursive Abstractive Processing for Tree-Organized Retrieval)ëŠ”
                  ë¬¸ì„œë¥¼ ê³„ì¸µì ìœ¼ë¡œ ìš”ì•½í•˜ì—¬ ë‹¤ì–‘í•œ ì¶”ìƒí™” ìˆ˜ì¤€ì—ì„œ ê²€ìƒ‰ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.</strong>
                  ì´ëŠ” ê¸´ ë¬¸ì„œë‚˜ ë³µì¡í•œ ì£¼ì œì— ëŒ€í•œ ì§ˆë¬¸ì— íŠ¹íˆ íš¨ê³¼ì ì´ë©°, ì „ì²´ì ì¸ ë§¥ë½ê³¼
                  ì„¸ë¶€ ì •ë³´ë¥¼ ëª¨ë‘ í¬ì°©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
                </p>
              </div>

              <div className="bg-slate-50 dark:bg-slate-800 p-4 rounded-lg border border-slate-200 dark:border-slate-700 overflow-x-auto">
                <pre className="text-sm text-slate-800 dark:text-slate-200 font-mono">
{`from typing import List, Dict, Any, Optional, Tuple
import numpy as np
from sklearn.cluster import KMeans
from dataclasses import dataclass
import networkx as nx
from collections import defaultdict
import torch
from transformers import AutoModel, AutoTokenizer

@dataclass
class RAPTORNode:
    """RAPTOR íŠ¸ë¦¬ì˜ ë…¸ë“œ"""
    level: int
    content: str
    summary: str
    children: List['RAPTORNode']
    embedding: Optional[np.ndarray] = None
    cluster_id: Optional[int] = None

class RAPTOR:
    def __init__(self, 
                 embedding_model: str = "sentence-transformers/all-MiniLM-L12-v2",
                 summarization_model: str = "facebook/bart-large-cnn",
                 max_cluster_size: int = 10):
        """
        RAPTOR: ì¬ê·€ì  íŠ¸ë¦¬ ê¸°ë°˜ ê²€ìƒ‰
        - ê³„ì¸µì  ë¬¸ì„œ êµ¬ì¡°í™”
        - ë‹¤ì¤‘ ìˆ˜ì¤€ ìš”ì•½
        - ì ì‘ì  ê²€ìƒ‰
        """
        self.embedding_model = AutoModel.from_pretrained(embedding_model)
        self.tokenizer = AutoTokenizer.from_pretrained(embedding_model)
        self.summarizer = self._init_summarizer(summarization_model)
        self.max_cluster_size = max_cluster_size
        self.tree_root = None
        
    def build_tree(self, documents: List[str]) -> RAPTORNode:
        """ë¬¸ì„œ ì§‘í•©ìœ¼ë¡œë¶€í„° RAPTOR íŠ¸ë¦¬ êµ¬ì¶•"""
        print("Building RAPTOR tree...")
        
        # 1ë‹¨ê³„: ë¦¬í”„ ë…¸ë“œ ìƒì„± (ì›ë³¸ ë¬¸ì„œ)
        leaf_nodes = []
        for i, doc in enumerate(documents):
            node = RAPTORNode(
                level=0,
                content=doc,
                summary=doc[:200] + "...",  # ì´ˆê¸°ì—ëŠ” ì•ë¶€ë¶„ë§Œ
                children=[],
                embedding=self._get_embedding(doc)
            )
            leaf_nodes.append(node)
        
        # 2ë‹¨ê³„: ì¬ê·€ì ìœ¼ë¡œ ìƒìœ„ ë ˆë²¨ êµ¬ì¶•
        current_level_nodes = leaf_nodes
        level = 0
        
        while len(current_level_nodes) > 1:
            level += 1
            print(f"Building level {level} with {len(current_level_nodes)} nodes")
            
            # í´ëŸ¬ìŠ¤í„°ë§
            clusters = self._cluster_nodes(current_level_nodes)
            
            # ê° í´ëŸ¬ìŠ¤í„°ì— ëŒ€í•´ ë¶€ëª¨ ë…¸ë“œ ìƒì„±
            parent_nodes = []
            for cluster_id, nodes in clusters.items():
                parent_node = self._create_parent_node(nodes, level)
                parent_nodes.append(parent_node)
            
            current_level_nodes = parent_nodes
        
        # ë£¨íŠ¸ ë…¸ë“œ
        self.tree_root = current_level_nodes[0] if current_level_nodes else None
        return self.tree_root
    
    def _cluster_nodes(self, nodes: List[RAPTORNode]) -> Dict[int, List[RAPTORNode]]:
        """ë…¸ë“œ í´ëŸ¬ìŠ¤í„°ë§"""
        if len(nodes) <= self.max_cluster_size:
            return {0: nodes}
        
        # ì„ë² ë”© ì¶”ì¶œ
        embeddings = np.array([node.embedding for node in nodes])
        
        # ìµœì  í´ëŸ¬ìŠ¤í„° ìˆ˜ ê²°ì •
        n_clusters = max(2, len(nodes) // self.max_cluster_size)
        
        # K-means í´ëŸ¬ìŠ¤í„°ë§
        kmeans = KMeans(n_clusters=n_clusters, random_state=42)
        cluster_labels = kmeans.fit_predict(embeddings)
        
        # í´ëŸ¬ìŠ¤í„°ë³„ë¡œ ê·¸ë£¹í™”
        clusters = defaultdict(list)
        for node, label in zip(nodes, cluster_labels):
            node.cluster_id = label
            clusters[label].append(node)
        
        return clusters
    
    def _create_parent_node(self, children: List[RAPTORNode], level: int) -> RAPTORNode:
        """ìì‹ ë…¸ë“œë“¤ë¡œë¶€í„° ë¶€ëª¨ ë…¸ë“œ ìƒì„±"""
        # ìì‹ë“¤ì˜ ë‚´ìš© ê²°í•©
        combined_content = "\n\n".join([child.summary for child in children])
        
        # ìš”ì•½ ìƒì„±
        summary = self._generate_summary(combined_content)
        
        # ë¶€ëª¨ ë…¸ë“œ ìƒì„±
        parent = RAPTORNode(
            level=level,
            content=combined_content,
            summary=summary,
            children=children,
            embedding=self._get_embedding(summary)
        )
        
        return parent
    
    def _generate_summary(self, text: str, max_length: int = 200) -> str:
        """í…ìŠ¤íŠ¸ ìš”ì•½ ìƒì„±"""
        # ì‹¤ì œë¡œëŠ” BART ë“±ì˜ ìš”ì•½ ëª¨ë¸ ì‚¬ìš©
        # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨í•œ ì¶”ì¶œì  ìš”ì•½
        sentences = text.split('. ')
        if len(sentences) <= 3:
            return text
        
        # TF-IDF ê¸°ë°˜ ì¤‘ìš” ë¬¸ì¥ ì„ íƒ (ì‹œë®¬ë ˆì´ì…˜)
        important_sentences = sentences[:3]  # ì²˜ìŒ 3ë¬¸ì¥
        return '. '.join(important_sentences) + '.'
    
    def _get_embedding(self, text: str) -> np.ndarray:
        """í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±"""
        inputs = self.tokenizer(text, return_tensors="pt", 
                               truncation=True, max_length=512, padding=True)
        
        with torch.no_grad():
            outputs = self.embedding_model(**inputs)
            embeddings = outputs.last_hidden_state.mean(dim=1)
        
        return embeddings.numpy()[0]
    
    def search(self, query: str, top_k: int = 5, 
              collapse_threshold: float = 0.5) -> List[Tuple[RAPTORNode, float]]:
        """
        RAPTOR ê²€ìƒ‰
        - íŠ¸ë¦¬ì˜ ëª¨ë“  ë ˆë²¨ì—ì„œ ê²€ìƒ‰
        - ê´€ë ¨ì„±ì— ë”°ë¼ ë…¸ë“œ í™•ì¥/ì¶•ì†Œ
        """
        if not self.tree_root:
            return []
        
        query_embedding = self._get_embedding(query)
        
        # ëª¨ë“  ë…¸ë“œì™€ ì ìˆ˜ ê³„ì‚°
        all_nodes_scores = []
        self._collect_relevant_nodes(
            self.tree_root, query_embedding, 
            all_nodes_scores, collapse_threshold
        )
        
        # ì ìˆ˜ìˆœ ì •ë ¬
        all_nodes_scores.sort(key=lambda x: x[1], reverse=True)
        
        # ì¤‘ë³µ ì œê±° (ìì‹ì´ ì„ íƒë˜ë©´ ë¶€ëª¨ëŠ” ì œì™¸)
        selected_nodes = []
        selected_contents = set()
        
        for node, score in all_nodes_scores:
            # ì´ë¯¸ ì„ íƒëœ ë‚´ìš©ê³¼ ì¤‘ë³µë˜ì§€ ì•ŠëŠ”ì§€ í™•ì¸
            if node.content not in selected_contents:
                selected_nodes.append((node, score))
                selected_contents.add(node.content)
                
                # í•˜ìœ„ ë…¸ë“œë“¤ì˜ ë‚´ìš©ë„ ì¶”ê°€ (ì¤‘ë³µ ë°©ì§€)
                self._add_descendant_contents(node, selected_contents)
            
            if len(selected_nodes) >= top_k:
                break
        
        return selected_nodes
    
    def _collect_relevant_nodes(self, node: RAPTORNode, query_embedding: np.ndarray,
                               results: List[Tuple[RAPTORNode, float]], 
                               threshold: float):
        """ê´€ë ¨ ë…¸ë“œ ìˆ˜ì§‘ (ì¬ê·€ì )"""
        # í˜„ì¬ ë…¸ë“œì™€ì˜ ìœ ì‚¬ë„ ê³„ì‚°
        similarity = self._cosine_similarity(query_embedding, node.embedding)
        
        # ì„ê³„ê°’ ì´ìƒì´ë©´ ê²°ê³¼ì— ì¶”ê°€
        if similarity >= threshold:
            results.append((node, similarity))
            
            # ë†’ì€ ê´€ë ¨ì„±ì´ë©´ ìì‹ ë…¸ë“œë„ íƒìƒ‰
            if similarity >= threshold + 0.2:  # ë” ë†’ì€ ì„ê³„ê°’
                for child in node.children:
                    self._collect_relevant_nodes(
                        child, query_embedding, results, threshold
                    )
        else:
            # ë‚®ì€ ê´€ë ¨ì„±ì´ì–´ë„ ìì‹ ì¤‘ ì¼ë¶€ëŠ” ê´€ë ¨ë  ìˆ˜ ìˆìŒ
            # ìƒ˜í”Œë§í•˜ì—¬ íƒìƒ‰
            if node.children and np.random.random() < 0.3:
                sample_size = min(3, len(node.children))
                sampled_children = np.random.choice(
                    node.children, size=sample_size, replace=False
                )
                for child in sampled_children:
                    self._collect_relevant_nodes(
                        child, query_embedding, results, threshold
                    )
    
    def _add_descendant_contents(self, node: RAPTORNode, contents_set: set):
        """ë…¸ë“œì˜ ëª¨ë“  í•˜ìœ„ ë‚´ìš© ì¶”ê°€"""
        for child in node.children:
            contents_set.add(child.content)
            self._add_descendant_contents(child, contents_set)
    
    def _cosine_similarity(self, vec1: np.ndarray, vec2: np.ndarray) -> float:
        """ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°"""
        return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))
    
    def _init_summarizer(self, model_name: str):
        """ìš”ì•½ ëª¨ë¸ ì´ˆê¸°í™”"""
        # ì‹¤ì œë¡œëŠ” transformers pipeline ì‚¬ìš©
        from transformers import pipeline
        return pipeline("summarization", model=model_name)
    
    def visualize_tree(self, max_depth: int = 3) -> str:
        """íŠ¸ë¦¬ êµ¬ì¡° ì‹œê°í™”"""
        if not self.tree_root:
            return "Tree not built"
        
        lines = []
        self._visualize_node(self.tree_root, lines, "", True, max_depth)
        return "\n".join(lines)
    
    def _visualize_node(self, node: RAPTORNode, lines: List[str], 
                       prefix: str, is_last: bool, max_depth: int):
        """ë…¸ë“œ ì‹œê°í™” (ì¬ê·€ì )"""
        if max_depth <= 0:
            return
        
        # í˜„ì¬ ë…¸ë“œ ì¶œë ¥
        connector = "â””â”€â”€ " if is_last else "â”œâ”€â”€ "
        lines.append(f"{prefix}{connector}Level {node.level}: {node.summary[:50]}...")
        
        # ìì‹ ë…¸ë“œë“¤
        if node.children:
            extension = "    " if is_last else "â”‚   "
            for i, child in enumerate(node.children):
                is_last_child = (i == len(node.children) - 1)
                self._visualize_node(
                    child, lines, prefix + extension, 
                    is_last_child, max_depth - 1
                )

# RAPTOR ê°œì„ : ë™ì  íŠ¸ë¦¬ ì—…ë°ì´íŠ¸
class DynamicRAPTOR(RAPTOR):
    def __init__(self, *args, **kwargs):
        """ë™ì  ì—…ë°ì´íŠ¸ê°€ ê°€ëŠ¥í•œ RAPTOR"""
        super().__init__(*args, **kwargs)
        self.update_threshold = 0.3  # ì¬êµ¬ì¡°í™” ì„ê³„ê°’
        
    def add_documents(self, new_documents: List[str]):
        """ìƒˆë¡œìš´ ë¬¸ì„œ ì¶”ê°€"""
        # ìƒˆ ë¬¸ì„œë“¤ì„ ë¦¬í”„ ë…¸ë“œë¡œ ì¶”ê°€
        new_nodes = []
        for doc in new_documents:
            node = RAPTORNode(
                level=0,
                content=doc,
                summary=doc[:200] + "...",
                children=[],
                embedding=self._get_embedding(doc)
            )
            new_nodes.append(node)
        
        # ê¸°ì¡´ íŠ¸ë¦¬ì™€ ë³‘í•©
        self._merge_nodes(new_nodes)
    
    def _merge_nodes(self, new_nodes: List[RAPTORNode]):
        """ìƒˆ ë…¸ë“œë“¤ì„ ê¸°ì¡´ íŠ¸ë¦¬ì— ë³‘í•©"""
        # ê°€ì¥ ìœ ì‚¬í•œ ê¸°ì¡´ í´ëŸ¬ìŠ¤í„° ì°¾ê¸°
        for node in new_nodes:
            best_cluster = self._find_best_cluster(node)
            
            if best_cluster:
                # ê¸°ì¡´ í´ëŸ¬ìŠ¤í„°ì— ì¶”ê°€
                self._add_to_cluster(node, best_cluster)
            else:
                # ìƒˆ í´ëŸ¬ìŠ¤í„° ìƒì„±
                self._create_new_cluster(node)
        
        # íŠ¸ë¦¬ ì¬ê· í˜•í™” ì²´í¬
        if self._needs_rebalancing():
            self._rebalance_tree()
    
    def _find_best_cluster(self, node: RAPTORNode) -> Optional[RAPTORNode]:
        """ê°€ì¥ ì í•©í•œ í´ëŸ¬ìŠ¤í„° ì°¾ê¸°"""
        # ë ˆë²¨ 0ì˜ ëª¨ë“  ë¶€ëª¨ ë…¸ë“œë“¤ê³¼ ë¹„êµ
        # ì‹¤ì œ êµ¬í˜„ì€ ë” ë³µì¡í•¨
        return None
    
    def _needs_rebalancing(self) -> bool:
        """íŠ¸ë¦¬ ì¬ê· í˜•í™” í•„ìš” ì—¬ë¶€ í™•ì¸"""
        # í´ëŸ¬ìŠ¤í„° í¬ê¸° ë¶ˆê· í˜• ì²´í¬
        return False
    
    def _rebalance_tree(self):
        """íŠ¸ë¦¬ ì¬ê· í˜•í™”"""
        print("Rebalancing RAPTOR tree...")
        # ì „ì²´ íŠ¸ë¦¬ ì¬êµ¬ì¶• ë˜ëŠ” ë¶€ë¶„ ì¬êµ¬ì¡°í™”

# ì‚¬ìš© ì˜ˆì œ
print("=== RAPTOR ë°ëª¨ ===\n")

# ìƒ˜í”Œ ë¬¸ì„œ
documents = [
    "Machine learning is a subset of artificial intelligence.",
    "Deep learning uses neural networks with multiple layers.",
    "Natural language processing enables computers to understand human language.",
    "Computer vision allows machines to interpret visual information.",
    "Reinforcement learning trains agents through rewards and penalties.",
    "Transfer learning reuses knowledge from one task for another.",
    "Supervised learning requires labeled training data.",
    "Unsupervised learning finds patterns without labels.",
    "Semi-supervised learning uses both labeled and unlabeled data.",
    "Active learning selects the most informative samples for labeling."
]

# RAPTOR íŠ¸ë¦¬ êµ¬ì¶•
raptor = RAPTOR(max_cluster_size=3)
root = raptor.build_tree(documents)

# íŠ¸ë¦¬ ì‹œê°í™”
print("RAPTOR Tree Structure:")
print(raptor.visualize_tree(max_depth=3))

# ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
queries = [
    "What are the types of machine learning?",
    "How does deep learning work?",
    "Explain learning without labels"
]

print("\n\n=== RAPTOR Search Results ===")
for query in queries:
    print(f"\nQuery: {query}")
    results = raptor.search(query, top_k=3)
    
    for i, (node, score) in enumerate(results, 1):
        print(f"\n{i}. Level {node.level} (Score: {score:.3f})")
        print(f"   Summary: {node.summary[:100]}...")
        if node.level == 0:
            print(f"   Type: Leaf node (original document)")
        else:
            print(f"   Type: Internal node (summary of {len(node.children)} children)")`}
                </pre>
              </div>
            </div>
          </div>
        </section>

        {/* Section 3: Multimodal RAG */}
        <section className="bg-white dark:bg-gray-800 rounded-2xl p-8 shadow-sm border border-gray-200 dark:border-gray-700">
          <div className="flex items-center gap-3 mb-6">
            <div className="w-12 h-12 rounded-xl bg-green-100 dark:bg-green-900/20 flex items-center justify-center">
              <Eye className="text-green-600" size={24} />
            </div>
            <div>
              <h2 className="text-2xl font-bold text-gray-900 dark:text-white">6.3 Multimodal RAG: í…ìŠ¤íŠ¸ë¥¼ ë„˜ì–´ì„œ</h2>
              <p className="text-gray-600 dark:text-gray-400">ì´ë¯¸ì§€, ë¹„ë””ì˜¤, ì˜¤ë””ì˜¤ë¥¼ í†µí•©í•œ ì°¨ì„¸ëŒ€ ê²€ìƒ‰</p>
            </div>
          </div>

          <div className="space-y-6">
            <div className="bg-green-50 dark:bg-green-900/20 p-6 rounded-xl border border-green-200 dark:border-green-700">
              <h3 className="font-bold text-green-800 dark:text-green-200 mb-4">ë©€í‹°ëª¨ë‹¬ RAGì˜ ìµœì‹  ë™í–¥</h3>
              
              <div className="grid md:grid-cols-2 gap-4">
                <div className="bg-white dark:bg-gray-800 p-4 rounded-lg border">
                  <h4 className="font-medium text-gray-900 dark:text-white mb-3">ğŸ–¼ï¸ Visual RAG</h4>
                  <ul className="text-sm text-gray-700 dark:text-gray-300 space-y-1">
                    <li>â€¢ CLIP ê¸°ë°˜ ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ê²€ìƒ‰</li>
                    <li>â€¢ LayoutLMì„ í™œìš©í•œ ë¬¸ì„œ ì´í•´</li>
                    <li>â€¢ Scene Graph ê¸°ë°˜ ì¶”ë¡ </li>
                    <li>â€¢ OCR + RAG í†µí•©</li>
                  </ul>
                </div>
                
                <div className="bg-white dark:bg-gray-800 p-4 rounded-lg border">
                  <h4 className="font-medium text-gray-900 dark:text-white mb-3">ğŸ¥ Video RAG</h4>
                  <ul className="text-sm text-gray-700 dark:text-gray-300 space-y-1">
                    <li>â€¢ ì‹œê°„ì  ì •ë³´ ì¸ë±ì‹±</li>
                    <li>â€¢ í‚¤í”„ë ˆì„ ì¶”ì¶œ ë° ê²€ìƒ‰</li>
                    <li>â€¢ ë¹„ë””ì˜¤ ìš”ì•½ê³¼ QA</li>
                    <li>â€¢ ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° RAG</li>
                  </ul>
                </div>
              </div>

              <div className="mt-4 bg-blue-50 dark:bg-blue-900/20 p-4 rounded-lg">
                <h4 className="font-medium text-blue-800 dark:text-blue-200 mb-2">ìµœê·¼ ì—°êµ¬ í•˜ì´ë¼ì´íŠ¸</h4>
                <ul className="text-sm text-gray-700 dark:text-gray-300 space-y-2">
                  <li><strong>â€¢ MM-RAG (Meta, 2024):</strong> 30B íŒŒë¼ë¯¸í„° ë©€í‹°ëª¨ë‹¬ RAG, ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ ë™ì‹œ ê²€ìƒ‰</li>
                  <li><strong>â€¢ VideoChat-RAG (2024):</strong> ë¹„ë””ì˜¤ ëŒ€í™”ë¥¼ ìœ„í•œ ì‹œê°„ ì¸ì‹ RAG</li>
                  <li><strong>â€¢ AudioRAG (Google, 2024):</strong> ìŒì„±/ìŒì•… ê²€ìƒ‰ê³¼ ìƒì„± í†µí•©</li>
                </ul>
              </div>
            </div>

            <div className="bg-purple-50 dark:bg-purple-900/20 p-6 rounded-xl border border-purple-200 dark:border-purple-700">
              <h3 className="font-bold text-purple-800 dark:text-purple-200 mb-4">í†µí•© ë©€í‹°ëª¨ë‹¬ RAG ì•„í‚¤í…ì²˜</h3>
              
              <div className="bg-slate-50 dark:bg-slate-800 p-4 rounded-lg border border-slate-200 dark:border-slate-700 overflow-x-auto">
                <pre className="text-sm text-slate-800 dark:text-slate-200 font-mono">
{`class UnifiedMultimodalRAG:
    """í†µí•© ë©€í‹°ëª¨ë‹¬ RAG ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        # ëª¨ë‹¬ë¦¬í‹°ë³„ ì¸ì½”ë”
        self.text_encoder = AutoModel.from_pretrained("bert-base")
        self.image_encoder = CLIPModel.from_pretrained("openai/clip-vit-base")
        self.audio_encoder = Wav2Vec2Model.from_pretrained("facebook/wav2vec2")
        
        # í†µí•© í”„ë¡œì ì…˜ ë ˆì´ì–´
        self.projection = nn.Linear(768, 512)  # ê³µí†µ ì„ë² ë”© ê³µê°„
        
        # í¬ë¡œìŠ¤ëª¨ë‹¬ ì–´í…ì…˜
        self.cross_attention = nn.MultiheadAttention(512, 8)
        
    def encode_multimodal_query(self, query: Dict[str, Any]) -> torch.Tensor:
        """ë©€í‹°ëª¨ë‹¬ ì¿¼ë¦¬ ì¸ì½”ë”©"""
        embeddings = []
        
        if 'text' in query:
            text_emb = self.text_encoder(query['text'])
            embeddings.append(self.projection(text_emb))
            
        if 'image' in query:
            image_emb = self.image_encoder.get_image_features(query['image'])
            embeddings.append(self.projection(image_emb))
            
        if 'audio' in query:
            audio_emb = self.audio_encoder(query['audio']).last_hidden_state
            embeddings.append(self.projection(audio_emb.mean(dim=1)))
        
        # í¬ë¡œìŠ¤ëª¨ë‹¬ ìœµí•©
        if len(embeddings) > 1:
            fused = torch.stack(embeddings)
            attended, _ = self.cross_attention(fused, fused, fused)
            return attended.mean(dim=0)
        else:
            return embeddings[0]
    
    def retrieve_and_generate(self, query: Dict[str, Any]) -> str:
        """ë©€í‹°ëª¨ë‹¬ ê²€ìƒ‰ ë° ìƒì„±"""
        # 1. ë©€í‹°ëª¨ë‹¬ ì¿¼ë¦¬ ì¸ì½”ë”©
        query_embedding = self.encode_multimodal_query(query)
        
        # 2. í¬ë¡œìŠ¤ëª¨ë‹¬ ê²€ìƒ‰
        retrieved_items = self.cross_modal_search(query_embedding)
        
        # 3. ë©€í‹°ëª¨ë‹¬ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        context = self.build_multimodal_context(retrieved_items)
        
        # 4. ë©€í‹°ëª¨ë‹¬ ìƒì„±
        response = self.generate_with_multimodal_context(query, context)
        
        return response`}
                </pre>
              </div>
            </div>
          </div>
        </section>

        {/* Section 4: Future Directions */}
        <section className="bg-white dark:bg-gray-800 rounded-2xl p-8 shadow-sm border border-gray-200 dark:border-gray-700">
          <div className="flex items-center gap-3 mb-6">
            <div className="w-12 h-12 rounded-xl bg-purple-100 dark:bg-purple-900/20 flex items-center justify-center">
              <Rocket className="text-purple-600" size={24} />
            </div>
            <div>
              <h2 className="text-2xl font-bold text-gray-900 dark:text-white">6.4 RAGì˜ ë¯¸ë˜: 2025ë…„ê³¼ ê·¸ ì´í›„</h2>
              <p className="text-gray-600 dark:text-gray-400">ì°¨ì„¸ëŒ€ RAG ê¸°ìˆ ì˜ ë°œì „ ë°©í–¥</p>
            </div>
          </div>

          <div className="space-y-6">
            <div className="bg-purple-50 dark:bg-purple-900/20 p-6 rounded-xl border border-purple-200 dark:border-purple-700">
              <h3 className="font-bold text-purple-800 dark:text-purple-200 mb-4">ğŸš€ 2025ë…„ RAG ê¸°ìˆ  ì „ë§</h3>
              
              <div className="space-y-4">
                <div className="bg-white dark:bg-gray-800 p-4 rounded-lg border">
                  <h4 className="font-medium text-purple-600 dark:text-purple-400 mb-2">1. Agentic RAG</h4>
                  <p className="text-sm text-gray-700 dark:text-gray-300">
                    RAG ì‹œìŠ¤í…œì´ ë‹¨ìˆœ ê²€ìƒ‰ì„ ë„˜ì–´ ëŠ¥ë™ì ìœ¼ë¡œ ì •ë³´ë¥¼ ìˆ˜ì§‘, ê²€ì¦, ì—…ë°ì´íŠ¸í•˜ëŠ” 
                    ììœ¨ ì—ì´ì „íŠ¸ë¡œ ì§„í™”. í•„ìš”ì‹œ ì™¸ë¶€ API í˜¸ì¶œ, ì‹¤ì‹œê°„ ë°ì´í„° ìˆ˜ì§‘, 
                    ì •ë³´ ì‹ ë¢°ë„ ìë™ í‰ê°€ ë“±ì„ ìˆ˜í–‰.
                  </p>
                </div>
                
                <div className="bg-white dark:bg-gray-800 p-4 rounded-lg border">
                  <h4 className="font-medium text-blue-600 dark:text-blue-400 mb-2">2. Continual Learning RAG</h4>
                  <p className="text-sm text-gray-700 dark:text-gray-300">
                    ì‚¬ìš©ì í”¼ë“œë°±ê³¼ ìƒˆë¡œìš´ ì •ë³´ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ í•™ìŠµí•˜ì—¬ ì§€ì†ì ìœ¼ë¡œ ê°œì„ ë˜ëŠ” RAG. 
                    Catastrophic forgetting ì—†ì´ ìƒˆë¡œìš´ ì§€ì‹ì„ í†µí•©í•˜ê³ , 
                    ì˜¤ë˜ëœ ì •ë³´ë¥¼ ìë™ìœ¼ë¡œ ì—…ë°ì´íŠ¸.
                  </p>
                </div>
                
                <div className="bg-white dark:bg-gray-800 p-4 rounded-lg border">
                  <h4 className="font-medium text-green-600 dark:text-green-400 mb-2">3. Personalized RAG</h4>
                  <p className="text-sm text-gray-700 dark:text-gray-300">
                    ê°œì¸ì˜ ì„ í˜¸ë„, ì „ë¬¸ì„± ìˆ˜ì¤€, ë¬¸ë§¥ì„ ì´í•´í•˜ì—¬ ë§ì¶¤í˜• ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” RAG. 
                    í”„ë¼ì´ë²„ì‹œë¥¼ ë³´ì¥í•˜ë©´ì„œë„ ê°œì¸í™”ëœ ì§€ì‹ ê·¸ë˜í”„ë¥¼ êµ¬ì¶•í•˜ê³  í™œìš©.
                  </p>
                </div>
                
                <div className="bg-white dark:bg-gray-800 p-4 rounded-lg border">
                  <h4 className="font-medium text-orange-600 dark:text-orange-400 mb-2">4. Quantum RAG</h4>
                  <p className="text-sm text-gray-700 dark:text-gray-300">
                    ì–‘ì ì»´í“¨íŒ…ì„ í™œìš©í•œ ì´ˆê³ ì† ë²¡í„° ê²€ìƒ‰ê³¼ ì–‘ì ì¤‘ì²©ì„ ì´ìš©í•œ 
                    ë‹¤ì°¨ì› ì˜ë¯¸ ê³µê°„ íƒìƒ‰. ê¸°ì¡´ RAG ëŒ€ë¹„ 1000ë°° ì´ìƒì˜ ê²€ìƒ‰ ì†ë„ í–¥ìƒ ì˜ˆìƒ.
                  </p>
                </div>
              </div>
            </div>

            <div className="bg-gradient-to-r from-purple-100 to-pink-100 dark:from-purple-900/20 dark:to-pink-900/20 p-6 rounded-xl border border-purple-200 dark:border-purple-700">
              <h3 className="font-bold text-purple-800 dark:text-purple-200 mb-4">ğŸ¯ ì—°êµ¬ìë¥¼ ìœ„í•œ ì˜¤í”ˆ ë¬¸ì œë“¤</h3>
              
              <div className="grid md:grid-cols-2 gap-4">
                <div className="bg-white/50 dark:bg-gray-800/50 p-4 rounded-lg">
                  <h4 className="font-semibold text-gray-800 dark:text-gray-200 mb-2">ì´ë¡ ì  ë„ì „ê³¼ì œ</h4>
                  <ul className="text-sm text-gray-700 dark:text-gray-300 space-y-1">
                    <li>â€¢ RAGì˜ ì´ë¡ ì  í•œê³„ ì¦ëª…</li>
                    <li>â€¢ ìµœì  ê²€ìƒ‰-ìƒì„± ê· í˜•ì </li>
                    <li>â€¢ ì •ë³´ ì´ë¡ ì  ê´€ì ì˜ RAG</li>
                    <li>â€¢ í™˜ê° í˜„ìƒì˜ ìˆ˜í•™ì  ëª¨ë¸ë§</li>
                  </ul>
                </div>
                
                <div className="bg-white/50 dark:bg-gray-800/50 p-4 rounded-lg">
                  <h4 className="font-semibold text-gray-800 dark:text-gray-200 mb-2">ì‹¤ìš©ì  ë„ì „ê³¼ì œ</h4>
                  <ul className="text-sm text-gray-700 dark:text-gray-300 space-y-1">
                    <li>â€¢ ì‹¤ì‹œê°„ ì§€ì‹ ì—…ë°ì´íŠ¸</li>
                    <li>â€¢ ë‹¤êµ­ì–´ í¬ë¡œìŠ¤ë§êµ¬ì–¼ RAG</li>
                    <li>â€¢ ì—ë„ˆì§€ íš¨ìœ¨ì  RAG</li>
                    <li>â€¢ ì—£ì§€ ë””ë°”ì´ìŠ¤ìš© ê²½ëŸ‰ RAG</li>
                  </ul>
                </div>
              </div>
            </div>
          </div>
        </section>

        {/* Research Papers and Resources */}
        <section className="bg-gradient-to-r from-violet-500 to-purple-600 rounded-2xl p-8 text-white">
          <h2 className="text-2xl font-bold mb-6">ì¶”ì²œ ë…¼ë¬¸ ë° ë¦¬ì†ŒìŠ¤</h2>
          
          <div className="space-y-4">
            <div className="bg-white/10 rounded-xl p-6 backdrop-blur">
              <h3 className="font-bold mb-4">ğŸ“š í•„ë… ë…¼ë¬¸ (2023-2024)</h3>
              
              <div className="space-y-3">
                <div className="bg-white/10 p-4 rounded-lg">
                  <h4 className="font-medium mb-1">Self-RAG: Learning to Retrieve, Generate, and Critique</h4>
                  <p className="text-sm opacity-90">Asai et al., 2023 - Washington University</p>
                  <a href="#" className="text-xs underline">arXiv:2310.11511</a>
                </div>
                
                <div className="bg-white/10 p-4 rounded-lg">
                  <h4 className="font-medium mb-1">RAPTOR: Recursive Abstractive Processing for Tree-Organized Retrieval</h4>
                  <p className="text-sm opacity-90">Sarthi et al., 2024 - Stanford University</p>
                  <a href="#" className="text-xs underline">arXiv:2401.18059</a>
                </div>
                
                <div className="bg-white/10 p-4 rounded-lg">
                  <h4 className="font-medium mb-1">Adaptive-RAG: Learning to Adapt Retrieval-Augmented Large Language Models</h4>
                  <p className="text-sm opacity-90">Jeong et al., 2024 - KAIST</p>
                  <a href="#" className="text-xs underline">arXiv:2403.14403</a>
                </div>
              </div>
            </div>
            
            <div className="bg-white/10 rounded-xl p-6 backdrop-blur">
              <h3 className="font-bold mb-4">ğŸ› ï¸ ì˜¤í”ˆì†ŒìŠ¤ í”„ë¡œì íŠ¸</h3>
              
              <div className="grid md:grid-cols-2 gap-4">
                <div className="bg-white/10 p-3 rounded">
                  <h4 className="font-medium text-sm">LlamaIndex</h4>
                  <p className="text-xs opacity-90">ìµœì‹  RAG ê¸°ë²• êµ¬í˜„ì²´</p>
                </div>
                <div className="bg-white/10 p-3 rounded">
                  <h4 className="font-medium text-sm">LangChain</h4>
                  <p className="text-xs opacity-90">í”„ë¡œë•ì…˜ RAG íŒŒì´í”„ë¼ì¸</p>
                </div>
                <div className="bg-white/10 p-3 rounded">
                  <h4 className="font-medium text-sm">RAGAS</h4>
                  <p className="text-xs opacity-90">RAG í‰ê°€ í”„ë ˆì„ì›Œí¬</p>
                </div>
                <div className="bg-white/10 p-3 rounded">
                  <h4 className="font-medium text-sm">Haystack</h4>
                  <p className="text-xs opacity-90">ì—”í„°í”„ë¼ì´ì¦ˆ RAG ì†”ë£¨ì…˜</p>
                </div>
              </div>
            </div>
          </div>
        </section>
      </div>

      {/* Navigation */}
      <div className="mt-12 bg-white dark:bg-gray-800 rounded-2xl p-6 shadow-sm border border-gray-200 dark:border-gray-700">
        <div className="flex justify-between items-center">
          <Link
            href="/modules/rag/advanced/chapter5"
            className="inline-flex items-center gap-2 text-gray-600 dark:text-gray-400 hover:text-gray-900 dark:hover:text-white transition-colors"
          >
            <ArrowLeft size={16} />
            ì´ì „: RAG í‰ê°€ì™€ ëª¨ë‹ˆí„°ë§
          </Link>
          
          <Link
            href="/modules/rag/advanced"
            className="inline-flex items-center gap-2 bg-violet-500 text-white px-6 py-3 rounded-lg font-medium hover:bg-violet-600 transition-colors"
          >
            ê³ ê¸‰ ê³¼ì • ì™„ë£Œ
            <ArrowRight size={16} />
          </Link>
        </div>
      </div>
    </div>
  )
}
'use client'

import { Brain } from 'lucide-react'

export default function Section1() {
  return (
    <section className="bg-white dark:bg-gray-800 rounded-2xl p-8 shadow-sm border border-gray-200 dark:border-gray-700">
      <div className="flex items-center gap-3 mb-6">
        <div className="w-12 h-12 rounded-xl bg-violet-100 dark:bg-violet-900/20 flex items-center justify-center">
          <Brain className="text-violet-600" size={24} />
        </div>
        <div>
          <h2 className="text-2xl font-bold text-gray-900 dark:text-white">6.1 Self-RAG: ìê¸° ì„±ì°°í•˜ëŠ” ê²€ìƒ‰ ì¦ê°• ìƒì„±</h2>
          <p className="text-gray-600 dark:text-gray-400">Washington Universityì˜ í˜ì‹ ì  ì—°êµ¬ (2023.10)</p>
        </div>
      </div>

      <div className="space-y-6">
        <div className="bg-violet-50 dark:bg-violet-900/20 p-6 rounded-xl border border-violet-200 dark:border-violet-700">
          <h3 className="font-bold text-violet-800 dark:text-violet-200 mb-4">Self-RAGì˜ í˜ì‹ ì  ì ‘ê·¼ë²•</h3>

          <div className="prose prose-sm dark:prose-invert mb-4">
            <p className="text-gray-700 dark:text-gray-300">
              <strong>Self-RAGëŠ” ê¸°ì¡´ RAGì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ëŠ” íŒ¨ëŸ¬ë‹¤ì„ ì „í™˜ì…ë‹ˆë‹¤.</strong>
              ëª¨ë¸ì´ ìŠ¤ìŠ¤ë¡œ ê²€ìƒ‰ í•„ìš”ì„±ì„ íŒë‹¨í•˜ê³ , ê²€ìƒ‰ëœ ì •ë³´ì˜ ê´€ë ¨ì„±ì„ í‰ê°€í•˜ë©°,
              ìƒì„±ëœ ë‹µë³€ì˜ í’ˆì§ˆì„ ìì²´ì ìœ¼ë¡œ ê²€ì¦í•©ë‹ˆë‹¤. ì´ëŠ” ì¸ê°„ì˜ ë¹„íŒì  ì‚¬ê³  ê³¼ì •ì„
              ëª¨ë°©í•œ ê²ƒìœ¼ë¡œ, RAG ì‹œìŠ¤í…œì˜ ì‹ ë¢°ì„±ê³¼ íš¨ìœ¨ì„±ì„ í¬ê²Œ í–¥ìƒì‹œí‚µë‹ˆë‹¤.
            </p>
          </div>

          <div className="grid md:grid-cols-3 gap-4">
            <div className="bg-white dark:bg-gray-800 p-4 rounded-lg border">
              <h4 className="font-medium text-violet-600 dark:text-violet-400 mb-2">ğŸ¤” Retrieval Decision</h4>
              <p className="text-sm text-gray-700 dark:text-gray-300">
                ì¿¼ë¦¬ ë¶„ì„ì„ í†µí•´ ì™¸ë¶€ ì§€ì‹ì´ í•„ìš”í•œì§€ ìŠ¤ìŠ¤ë¡œ íŒë‹¨
              </p>
            </div>

            <div className="bg-white dark:bg-gray-800 p-4 rounded-lg border">
              <h4 className="font-medium text-blue-600 dark:text-blue-400 mb-2">âœ… Relevance Check</h4>
              <p className="text-sm text-gray-700 dark:text-gray-300">
                ê²€ìƒ‰ëœ ê° ë¬¸ì„œì˜ ê´€ë ¨ì„±ì„ ìì²´ í‰ê°€í•˜ì—¬ í•„í„°ë§
              </p>
            </div>

            <div className="bg-white dark:bg-gray-800 p-4 rounded-lg border">
              <h4 className="font-medium text-green-600 dark:text-green-400 mb-2">ğŸ“Š Self-Reflection</h4>
              <p className="text-sm text-gray-700 dark:text-gray-300">
                ìƒì„±ëœ ë‹µë³€ì˜ í’ˆì§ˆê³¼ ì •í™•ì„±ì„ ìŠ¤ìŠ¤ë¡œ ê²€ì¦
              </p>
            </div>
          </div>
        </div>

        <div className="bg-blue-50 dark:bg-blue-900/20 p-6 rounded-xl border border-blue-200 dark:border-blue-700">
          <h3 className="font-bold text-blue-800 dark:text-blue-200 mb-4">Self-RAG êµ¬í˜„ ë° í•™ìŠµ</h3>

          <div className="bg-slate-50 dark:bg-slate-800 p-4 rounded-lg border border-slate-200 dark:border-slate-700 overflow-x-auto">
            <pre className="text-sm text-slate-800 dark:text-slate-200 font-mono">
{`import torch
import torch.nn as nn
from typing import List, Dict, Tuple, Optional, Any
from transformers import AutoModel, AutoTokenizer
from dataclasses import dataclass
import numpy as np
from enum import Enum

class ReflectionToken(Enum):
    """Self-RAG íŠ¹ìˆ˜ í† í°"""
    RETRIEVE = "[Retrieve]"
    NO_RETRIEVE = "[No Retrieve]"
    RELEVANT = "[Relevant]"
    IRRELEVANT = "[Irrelevant]"
    SUPPORTED = "[Supported]"
    NOT_SUPPORTED = "[Not Supported]"
    USEFUL = "[Useful]"
    NOT_USEFUL = "[Not Useful]"

@dataclass
class SelfRAGOutput:
    """Self-RAG ì¶œë ¥ êµ¬ì¡°"""
    answer: str
    retrieve_decision: bool
    relevance_scores: List[float]
    support_scores: List[float]
    utility_score: float
    retrieved_docs: List[Dict[str, Any]]
    reflection_tokens: List[str]

class SelfRAG(nn.Module):
    def __init__(self, base_model: str = "meta-llama/Llama-2-7b-hf"):
        """
        Self-RAG ëª¨ë¸ êµ¬í˜„
        - ì ì‘í˜• ê²€ìƒ‰ ê²°ì •
        - ë‹¤ì¤‘ í‰ê°€ ë©”ì»¤ë‹ˆì¦˜
        - ìê¸° ì„±ì°° ìƒì„±
        """
        super().__init__()

        # ê¸°ë³¸ ì–¸ì–´ ëª¨ë¸
        self.base_model = AutoModel.from_pretrained(base_model)
        self.tokenizer = AutoTokenizer.from_pretrained(base_model)

        # íŠ¹ìˆ˜ í† í° ì¶”ê°€
        self._add_special_tokens()

        # í‰ê°€ í—¤ë“œë“¤
        hidden_size = self.base_model.config.hidden_size
        self.retrieve_classifier = nn.Linear(hidden_size, 2)  # ê²€ìƒ‰ í•„ìš”ì„±
        self.relevance_classifier = nn.Linear(hidden_size, 2)  # ê´€ë ¨ì„±
        self.support_classifier = nn.Linear(hidden_size, 2)  # ì§€ì›ë„
        self.utility_classifier = nn.Linear(hidden_size, 2)  # ìœ ìš©ì„±

        # ê²€ìƒ‰ ì—”ì§„ (ì‹œë®¬ë ˆì´ì…˜)
        self.retriever = None  # ì‹¤ì œë¡œëŠ” Dense Retriever

    def _add_special_tokens(self):
        """íŠ¹ìˆ˜ í† í° ì¶”ê°€"""
        special_tokens = [token.value for token in ReflectionToken]
        self.tokenizer.add_special_tokens({'additional_special_tokens': special_tokens})
        self.base_model.resize_token_embeddings(len(self.tokenizer))

    def forward(self, query: str, context: Optional[str] = None) -> SelfRAGOutput:
        """
        Self-RAG ì „ì²´ íŒŒì´í”„ë¼ì¸
        """
        # 1ë‹¨ê³„: ê²€ìƒ‰ í•„ìš”ì„± íŒë‹¨
        retrieve_decision = self._decide_retrieval(query, context)

        retrieved_docs = []
        relevance_scores = []

        # 2ë‹¨ê³„: ì¡°ê±´ë¶€ ê²€ìƒ‰
        if retrieve_decision:
            # ë¬¸ì„œ ê²€ìƒ‰
            retrieved_docs = self._retrieve_documents(query)

            # ê° ë¬¸ì„œì˜ ê´€ë ¨ì„± í‰ê°€
            for doc in retrieved_docs:
                relevance = self._evaluate_relevance(query, doc['content'])
                relevance_scores.append(relevance)
                doc['relevance_score'] = relevance

            # ê´€ë ¨ì„± ë†’ì€ ë¬¸ì„œë§Œ í•„í„°ë§
            threshold = 0.5
            filtered_docs = [doc for doc, score in zip(retrieved_docs, relevance_scores)
                           if score > threshold]
        else:
            filtered_docs = []

        # 3ë‹¨ê³„: ë‹µë³€ ìƒì„±
        answer, support_scores = self._generate_with_reflection(
            query, filtered_docs, context
        )

        # 4ë‹¨ê³„: ìµœì¢… ìœ ìš©ì„± í‰ê°€
        utility_score = self._evaluate_utility(query, answer)

        # 5ë‹¨ê³„: ë°˜ì˜ í† í° ìƒì„±
        reflection_tokens = self._generate_reflection_tokens(
            retrieve_decision, relevance_scores, support_scores, utility_score
        )

        return SelfRAGOutput(
            answer=answer,
            retrieve_decision=retrieve_decision,
            relevance_scores=relevance_scores,
            support_scores=support_scores,
            utility_score=utility_score,
            retrieved_docs=retrieved_docs,
            reflection_tokens=reflection_tokens
        )

    def _decide_retrieval(self, query: str, context: Optional[str] = None) -> bool:
        """ê²€ìƒ‰ í•„ìš”ì„± ê²°ì •"""
        # ì¿¼ë¦¬ ì¸ì½”ë”©
        prompt = f"Query: {query}"
        if context:
            prompt = f"Context: {context}\n{prompt}"

        inputs = self.tokenizer(prompt, return_tensors="pt",
                               truncation=True, max_length=512)

        with torch.no_grad():
            outputs = self.base_model(**inputs)
            hidden_states = outputs.last_hidden_state

            # ë§ˆì§€ë§‰ í† í°ì˜ hidden state ì‚¬ìš©
            pooled = hidden_states[:, -1, :]

            # ê²€ìƒ‰ í•„ìš”ì„± ë¶„ë¥˜
            logits = self.retrieve_classifier(pooled)
            prob_retrieve = torch.softmax(logits, dim=-1)[0, 1].item()

        # ì„ê³„ê°’ ê¸°ë°˜ ê²°ì •
        return prob_retrieve > 0.5

    def _retrieve_documents(self, query: str, top_k: int = 5) -> List[Dict[str, Any]]:
        """ë¬¸ì„œ ê²€ìƒ‰ (ì‹œë®¬ë ˆì´ì…˜)"""
        # ì‹¤ì œë¡œëŠ” Dense Retriever ì‚¬ìš©
        sample_docs = [
            {
                'id': f'doc_{i}',
                'content': f'This is a sample document {i} related to {query}',
                'score': 0.9 - i * 0.1
            }
            for i in range(top_k)
        ]
        return sample_docs

    def _evaluate_relevance(self, query: str, document: str) -> float:
        """ë¬¸ì„œ ê´€ë ¨ì„± í‰ê°€"""
        prompt = f"Query: {query}\nDocument: {document}\nIs this document relevant?"

        inputs = self.tokenizer(prompt, return_tensors="pt",
                               truncation=True, max_length=512)

        with torch.no_grad():
            outputs = self.base_model(**inputs)
            hidden_states = outputs.last_hidden_state
            pooled = hidden_states[:, -1, :]

            logits = self.relevance_classifier(pooled)
            prob_relevant = torch.softmax(logits, dim=-1)[0, 1].item()

        return prob_relevant

    def _generate_with_reflection(self, query: str, documents: List[Dict[str, Any]],
                                 context: Optional[str] = None) -> Tuple[str, List[float]]:
        """ë°˜ì˜ì„ í¬í•¨í•œ ë‹µë³€ ìƒì„±"""
        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt_parts = []

        if context:
            prompt_parts.append(f"Context: {context}")

        prompt_parts.append(f"Query: {query}")

        if documents:
            prompt_parts.append("\nRetrieved Documents:")
            for i, doc in enumerate(documents):
                prompt_parts.append(f"[{i+1}] {doc['content']}")

        prompt_parts.append("\nGenerate answer with reflection:")
        prompt = "\n".join(prompt_parts)

        # ë‹µë³€ ìƒì„±
        inputs = self.tokenizer(prompt, return_tensors="pt",
                               truncation=True, max_length=1024)

        with torch.no_grad():
            # ìƒì„± ì‹œ íŠ¹ìˆ˜ í† í° í¬í•¨
            outputs = self.base_model.generate(
                **inputs,
                max_new_tokens=200,
                temperature=0.7,
                do_sample=True,
                pad_token_id=self.tokenizer.pad_token_id
            )

        generated_text = self.tokenizer.decode(outputs[0], skip_special_tokens=False)

        # ë‹µë³€ê³¼ ì§€ì›ë„ ì ìˆ˜ ì¶”ì¶œ
        answer, support_scores = self._parse_generated_output(generated_text, documents)

        return answer, support_scores

    def _parse_generated_output(self, generated_text: str,
                               documents: List[Dict[str, Any]]) -> Tuple[str, List[float]]:
        """ìƒì„±ëœ ì¶œë ¥ íŒŒì‹±"""
        # íŠ¹ìˆ˜ í† í° ê¸°ë°˜ìœ¼ë¡œ íŒŒì‹±
        answer_parts = []
        support_scores = []

        # ê°„ë‹¨í•œ íŒŒì‹± (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ ë¡œì§ í•„ìš”)
        lines = generated_text.split('\n')
        for line in lines:
            if ReflectionToken.SUPPORTED.value in line:
                support_scores.append(1.0)
            elif ReflectionToken.NOT_SUPPORTED.value in line:
                support_scores.append(0.0)
            elif not any(token.value in line for token in ReflectionToken):
                answer_parts.append(line)

        # ë¶€ì¡±í•œ support scoreëŠ” 0ìœ¼ë¡œ ì±„ì›€
        while len(support_scores) < len(documents):
            support_scores.append(0.0)

        answer = ' '.join(answer_parts).strip()
        return answer, support_scores

    def _evaluate_utility(self, query: str, answer: str) -> float:
        """ë‹µë³€ì˜ ìœ ìš©ì„± í‰ê°€"""
        prompt = f"Query: {query}\nAnswer: {answer}\nIs this answer useful?"

        inputs = self.tokenizer(prompt, return_tensors="pt",
                               truncation=True, max_length=512)

        with torch.no_grad():
            outputs = self.base_model(**inputs)
            hidden_states = outputs.last_hidden_state
            pooled = hidden_states[:, -1, :]

            logits = self.utility_classifier(pooled)
            prob_useful = torch.softmax(logits, dim=-1)[0, 1].item()

        return prob_useful

    def _generate_reflection_tokens(self, retrieve_decision: bool,
                                   relevance_scores: List[float],
                                   support_scores: List[float],
                                   utility_score: float) -> List[str]:
        """ë°˜ì˜ í† í° ìƒì„±"""
        tokens = []

        # ê²€ìƒ‰ ê²°ì •
        if retrieve_decision:
            tokens.append(ReflectionToken.RETRIEVE.value)
        else:
            tokens.append(ReflectionToken.NO_RETRIEVE.value)

        # ê´€ë ¨ì„± í‰ê°€
        for score in relevance_scores:
            if score > 0.5:
                tokens.append(ReflectionToken.RELEVANT.value)
            else:
                tokens.append(ReflectionToken.IRRELEVANT.value)

        # ì§€ì›ë„ í‰ê°€
        for score in support_scores:
            if score > 0.5:
                tokens.append(ReflectionToken.SUPPORTED.value)
            else:
                tokens.append(ReflectionToken.NOT_SUPPORTED.value)

        # ìœ ìš©ì„± í‰ê°€
        if utility_score > 0.5:
            tokens.append(ReflectionToken.USEFUL.value)
        else:
            tokens.append(ReflectionToken.NOT_USEFUL.value)

        return tokens

# Self-RAG í•™ìŠµì„ ìœ„í•œ ë°ì´í„° ìƒì„±
class SelfRAGDataGenerator:
    def __init__(self):
        """Self-RAG í•™ìŠµ ë°ì´í„° ìƒì„±ê¸°"""
        self.critique_model = None  # GPT-4 ë“± ì‚¬ìš©

    def generate_training_data(self, qa_pairs: List[Dict[str, str]],
                             documents: List[str]) -> List[Dict[str, Any]]:
        """í•™ìŠµ ë°ì´í„° ìƒì„±"""
        training_data = []

        for qa in qa_pairs:
            query = qa['question']
            answer = qa['answer']

            # 1. ê²€ìƒ‰ í•„ìš”ì„± ë ˆì´ë¸”
            retrieve_needed = self._label_retrieval_need(query, answer)

            # 2. ê´€ë ¨ ë¬¸ì„œ ìƒ˜í”Œë§
            if retrieve_needed:
                sampled_docs = self._sample_documents(query, documents)

                # 3. ê´€ë ¨ì„± ë ˆì´ë¸”ë§
                relevance_labels = []
                for doc in sampled_docs:
                    relevance = self._label_relevance(query, doc)
                    relevance_labels.append(relevance)

                # 4. ì§€ì›ë„ ë ˆì´ë¸”ë§
                support_labels = self._label_support(answer, sampled_docs)
            else:
                sampled_docs = []
                relevance_labels = []
                support_labels = []

            # 5. ìœ ìš©ì„± ë ˆì´ë¸”
            utility_label = self._label_utility(query, answer)

            training_data.append({
                'query': query,
                'answer': answer,
                'retrieve_needed': retrieve_needed,
                'documents': sampled_docs,
                'relevance_labels': relevance_labels,
                'support_labels': support_labels,
                'utility_label': utility_label
            })

        return training_data

    def _label_retrieval_need(self, query: str, answer: str) -> bool:
        """ê²€ìƒ‰ í•„ìš”ì„± ë ˆì´ë¸”ë§"""
        # íœ´ë¦¬ìŠ¤í‹±: íŒ©íŠ¸ ê¸°ë°˜ ì§ˆë¬¸ì€ ê²€ìƒ‰ í•„ìš”
        fact_keywords = ['when', 'where', 'who', 'how many', 'what year']
        return any(kw in query.lower() for kw in fact_keywords)

    def _sample_documents(self, query: str, documents: List[str], k: int = 5) -> List[str]:
        """ë¬¸ì„œ ìƒ˜í”Œë§ (BM25 ë“± ì‚¬ìš©)"""
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ë§¤ì¹­
        query_words = set(query.lower().split())
        scored_docs = []

        for doc in documents:
            doc_words = set(doc.lower().split())
            score = len(query_words.intersection(doc_words))
            scored_docs.append((doc, score))

        scored_docs.sort(key=lambda x: x[1], reverse=True)
        return [doc for doc, _ in scored_docs[:k]]

    def _label_relevance(self, query: str, document: str) -> float:
        """ê´€ë ¨ì„± ë ˆì´ë¸”ë§"""
        # ì‹¤ì œë¡œëŠ” ì¸ê°„ í‰ê°€ ë˜ëŠ” GPT-4 ì‚¬ìš©
        query_words = set(query.lower().split())
        doc_words = set(document.lower().split())
        overlap = len(query_words.intersection(doc_words))
        return min(overlap / len(query_words), 1.0) if query_words else 0.0

    def _label_support(self, answer: str, documents: List[str]) -> List[float]:
        """ì§€ì›ë„ ë ˆì´ë¸”ë§"""
        support_scores = []
        answer_words = set(answer.lower().split())

        for doc in documents:
            doc_words = set(doc.lower().split())
            overlap = len(answer_words.intersection(doc_words))
            score = min(overlap / len(answer_words), 1.0) if answer_words else 0.0
            support_scores.append(score)

        return support_scores

    def _label_utility(self, query: str, answer: str) -> float:
        """ìœ ìš©ì„± ë ˆì´ë¸”ë§"""
        # ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±: ë‹µë³€ ê¸¸ì´ì™€ ì§ˆë¬¸ ë‹¨ì–´ í¬í•¨ë„
        if len(answer.split()) < 5:
            return 0.3

        query_words = set(query.lower().split())
        answer_words = set(answer.lower().split())
        coverage = len(query_words.intersection(answer_words)) / len(query_words)

        return min(0.5 + coverage * 0.5, 1.0)

# ì‚¬ìš© ì˜ˆì œ
print("=== Self-RAG ë°ëª¨ ===\n")

# Self-RAG ëª¨ë¸ ì´ˆê¸°í™”
self_rag = SelfRAG()

# í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬
queries = [
    "What is the capital of France?",  # íŒ©íŠ¸ ì§ˆë¬¸ - ê²€ìƒ‰ í•„ìš”
    "Hello, how are you?",  # ì¼ë°˜ ëŒ€í™” - ê²€ìƒ‰ ë¶ˆí•„ìš”
    "Explain the theory of relativity",  # ë³µì¡í•œ ì„¤ëª… - ê²€ìƒ‰ ë„ì›€
]

for query in queries:
    print(f"\nQuery: {query}")

    # Self-RAG ì‹¤í–‰
    output = self_rag(query)

    print(f"Retrieve Decision: {output.retrieve_decision}")
    if output.retrieve_decision:
        print(f"Retrieved {len(output.retrieved_docs)} documents")
        print(f"Relevance Scores: {[f'{s:.2f}' for s in output.relevance_scores]}")
    print(f"Answer: {output.answer}")
    print(f"Utility Score: {output.utility_score:.2f}")
    print(f"Reflection Tokens: {' '.join(output.reflection_tokens[:5])}...")

# í•™ìŠµ ë°ì´í„° ìƒì„± ì˜ˆì œ
data_generator = SelfRAGDataGenerator()

qa_pairs = [
    {"question": "What is machine learning?",
     "answer": "Machine learning is a subset of AI that enables systems to learn from data."},
    {"question": "How's the weather?",
     "answer": "I don't have access to real-time weather data."}
]

documents = [
    "Machine learning is a method of data analysis that automates analytical model building.",
    "AI and machine learning are transforming industries.",
    "The weather forecast requires current atmospheric data."
]

training_data = data_generator.generate_training_data(qa_pairs, documents)

print("\n\n=== Generated Training Data ===")
for i, data in enumerate(training_data):
    print(f"\nExample {i+1}:")
    print(f"Query: {data['query']}")
    print(f"Retrieve Needed: {data['retrieve_needed']}")
    print(f"Utility Label: {data['utility_label']:.2f}")`}
            </pre>
          </div>
        </div>

        <div className="bg-green-50 dark:bg-green-900/20 p-6 rounded-xl border border-green-200 dark:border-green-700">
          <h3 className="font-bold text-green-800 dark:text-green-200 mb-4">Self-RAG ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬</h3>

          <div className="grid md:grid-cols-2 gap-4">
            <div className="bg-white dark:bg-gray-800 p-4 rounded-lg border">
              <h4 className="font-medium text-gray-900 dark:text-white mb-3">Open-domain QA ì„±ëŠ¥</h4>
              <div className="space-y-2">
                <div className="flex justify-between text-sm">
                  <span>Self-RAG (7B)</span>
                  <span className="font-bold text-green-600">54.9</span>
                </div>
                <div className="flex justify-between text-sm">
                  <span>ChatGPT</span>
                  <span>44.0</span>
                </div>
                <div className="flex justify-between text-sm">
                  <span>Llama2-chat (7B)</span>
                  <span>28.2</span>
                </div>
                <div className="flex justify-between text-sm">
                  <span>Alpaca (7B)</span>
                  <span>24.5</span>
                </div>
              </div>
            </div>

            <div className="bg-white dark:bg-gray-800 p-4 rounded-lg border">
              <h4 className="font-medium text-gray-900 dark:text-white mb-3">íš¨ìœ¨ì„± ê°œì„ </h4>
              <div className="space-y-2">
                <div className="bg-blue-50 dark:bg-blue-900/30 p-2 rounded">
                  <p className="text-sm"><strong>ê²€ìƒ‰ íšŸìˆ˜:</strong> 60% ê°ì†Œ</p>
                </div>
                <div className="bg-green-50 dark:bg-green-900/30 p-2 rounded">
                  <p className="text-sm"><strong>ì •í™•ë„:</strong> 15% í–¥ìƒ</p>
                </div>
                <div className="bg-purple-50 dark:bg-purple-900/30 p-2 rounded">
                  <p className="text-sm"><strong>í™˜ê°ë¥ :</strong> 70% ê°ì†Œ</p>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>
  )
}

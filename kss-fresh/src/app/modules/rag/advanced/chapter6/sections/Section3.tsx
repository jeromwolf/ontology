'use client'

import { Eye } from 'lucide-react'

export default function Section3() {
  return (
    <section className="bg-white dark:bg-gray-800 rounded-2xl p-8 shadow-sm border border-gray-200 dark:border-gray-700">
      <div className="flex items-center gap-3 mb-6">
        <div className="w-12 h-12 rounded-xl bg-green-100 dark:bg-green-900/20 flex items-center justify-center">
          <Eye className="text-green-600" size={24} />
        </div>
        <div>
          <h2 className="text-2xl font-bold text-gray-900 dark:text-white">6.3 Multimodal RAG: í…ìŠ¤íŠ¸ë¥¼ ë„˜ì–´ì„œ</h2>
          <p className="text-gray-600 dark:text-gray-400">ì´ë¯¸ì§€, ë¹„ë””ì˜¤, ì˜¤ë””ì˜¤ë¥¼ í†µí•©í•œ ì°¨ì„¸ëŒ€ ê²€ìƒ‰</p>
        </div>
      </div>

      <div className="space-y-6">
        <div className="bg-green-50 dark:bg-green-900/20 p-6 rounded-xl border border-green-200 dark:border-green-700">
          <h3 className="font-bold text-green-800 dark:text-green-200 mb-4">ë©€í‹°ëª¨ë‹¬ RAGì˜ ìµœì‹  ë™í–¥</h3>

          <div className="grid md:grid-cols-2 gap-4">
            <div className="bg-white dark:bg-gray-800 p-4 rounded-lg border">
              <h4 className="font-medium text-gray-900 dark:text-white mb-3">ğŸ–¼ï¸ Visual RAG</h4>
              <ul className="text-sm text-gray-700 dark:text-gray-300 space-y-1">
                <li>â€¢ CLIP ê¸°ë°˜ ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ê²€ìƒ‰</li>
                <li>â€¢ LayoutLMì„ í™œìš©í•œ ë¬¸ì„œ ì´í•´</li>
                <li>â€¢ Scene Graph ê¸°ë°˜ ì¶”ë¡ </li>
                <li>â€¢ OCR + RAG í†µí•©</li>
              </ul>
            </div>

            <div className="bg-white dark:bg-gray-800 p-4 rounded-lg border">
              <h4 className="font-medium text-gray-900 dark:text-white mb-3">ğŸ¥ Video RAG</h4>
              <ul className="text-sm text-gray-700 dark:text-gray-300 space-y-1">
                <li>â€¢ ì‹œê°„ì  ì •ë³´ ì¸ë±ì‹±</li>
                <li>â€¢ í‚¤í”„ë ˆì„ ì¶”ì¶œ ë° ê²€ìƒ‰</li>
                <li>â€¢ ë¹„ë””ì˜¤ ìš”ì•½ê³¼ QA</li>
                <li>â€¢ ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° RAG</li>
              </ul>
            </div>
          </div>

          <div className="mt-4 bg-blue-50 dark:bg-blue-900/20 p-4 rounded-lg">
            <h4 className="font-medium text-blue-800 dark:text-blue-200 mb-2">ìµœê·¼ ì—°êµ¬ í•˜ì´ë¼ì´íŠ¸</h4>
            <ul className="text-sm text-gray-700 dark:text-gray-300 space-y-2">
              <li><strong>â€¢ MM-RAG (Meta, 2024):</strong> 30B íŒŒë¼ë¯¸í„° ë©€í‹°ëª¨ë‹¬ RAG, ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ ë™ì‹œ ê²€ìƒ‰</li>
              <li><strong>â€¢ VideoChat-RAG (2024):</strong> ë¹„ë””ì˜¤ ëŒ€í™”ë¥¼ ìœ„í•œ ì‹œê°„ ì¸ì‹ RAG</li>
              <li><strong>â€¢ AudioRAG (Google, 2024):</strong> ìŒì„±/ìŒì•… ê²€ìƒ‰ê³¼ ìƒì„± í†µí•©</li>
            </ul>
          </div>
        </div>

        <div className="bg-purple-50 dark:bg-purple-900/20 p-6 rounded-xl border border-purple-200 dark:border-purple-700">
          <h3 className="font-bold text-purple-800 dark:text-purple-200 mb-4">í†µí•© ë©€í‹°ëª¨ë‹¬ RAG ì•„í‚¤í…ì²˜</h3>

          <div className="bg-slate-50 dark:bg-slate-800 p-4 rounded-lg border border-slate-200 dark:border-slate-700 overflow-x-auto">
            <pre className="text-sm text-slate-800 dark:text-slate-200 font-mono">
{`class UnifiedMultimodalRAG:
    """í†µí•© ë©€í‹°ëª¨ë‹¬ RAG ì‹œìŠ¤í…œ"""

    def __init__(self):
        # ëª¨ë‹¬ë¦¬í‹°ë³„ ì¸ì½”ë”
        self.text_encoder = AutoModel.from_pretrained("bert-base")
        self.image_encoder = CLIPModel.from_pretrained("openai/clip-vit-base")
        self.audio_encoder = Wav2Vec2Model.from_pretrained("facebook/wav2vec2")

        # í†µí•© í”„ë¡œì ì…˜ ë ˆì´ì–´
        self.projection = nn.Linear(768, 512)  # ê³µí†µ ì„ë² ë”© ê³µê°„

        # í¬ë¡œìŠ¤ëª¨ë‹¬ ì–´í…ì…˜
        self.cross_attention = nn.MultiheadAttention(512, 8)

    def encode_multimodal_query(self, query: Dict[str, Any]) -> torch.Tensor:
        """ë©€í‹°ëª¨ë‹¬ ì¿¼ë¦¬ ì¸ì½”ë”©"""
        embeddings = []

        if 'text' in query:
            text_emb = self.text_encoder(query['text'])
            embeddings.append(self.projection(text_emb))

        if 'image' in query:
            image_emb = self.image_encoder.get_image_features(query['image'])
            embeddings.append(self.projection(image_emb))

        if 'audio' in query:
            audio_emb = self.audio_encoder(query['audio']).last_hidden_state
            embeddings.append(self.projection(audio_emb.mean(dim=1)))

        # í¬ë¡œìŠ¤ëª¨ë‹¬ ìœµí•©
        if len(embeddings) > 1:
            fused = torch.stack(embeddings)
            attended, _ = self.cross_attention(fused, fused, fused)
            return attended.mean(dim=0)
        else:
            return embeddings[0]

    def retrieve_and_generate(self, query: Dict[str, Any]) -> str:
        """ë©€í‹°ëª¨ë‹¬ ê²€ìƒ‰ ë° ìƒì„±"""
        # 1. ë©€í‹°ëª¨ë‹¬ ì¿¼ë¦¬ ì¸ì½”ë”©
        query_embedding = self.encode_multimodal_query(query)

        # 2. í¬ë¡œìŠ¤ëª¨ë‹¬ ê²€ìƒ‰
        retrieved_items = self.cross_modal_search(query_embedding)

        # 3. ë©€í‹°ëª¨ë‹¬ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        context = self.build_multimodal_context(retrieved_items)

        # 4. ë©€í‹°ëª¨ë‹¬ ìƒì„±
        response = self.generate_with_multimodal_context(query, context)

        return response`}
            </pre>
          </div>
        </div>
      </div>
    </section>
  )
}

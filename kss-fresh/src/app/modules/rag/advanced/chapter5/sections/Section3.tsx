'use client'

import Link from 'next/link'
import { Activity, ArrowLeft, ArrowRight } from 'lucide-react'
import References from '@/components/common/References'

export default function Section3() {
  return (
    <>
      <section className="bg-white dark:bg-gray-800 rounded-2xl p-8 shadow-sm border border-gray-200 dark:border-gray-700">
        <div className="flex items-center gap-3 mb-6">
          <div className="w-12 h-12 rounded-xl bg-purple-100 dark:bg-purple-900/20 flex items-center justify-center">
            <Activity className="text-purple-600" size={24} />
          </div>
          <div>
            <h2 className="text-2xl font-bold text-gray-900 dark:text-white">5.3 ì‹¤ì‹œê°„ RAG ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ</h2>
            <p className="text-gray-600 dark:text-gray-400">Grafana + Prometheus ê¸°ë°˜ ì¢…í•© ëª¨ë‹ˆí„°ë§</p>
          </div>
        </div>

        <div className="space-y-6">
          <div className="bg-purple-50 dark:bg-purple-900/20 p-6 rounded-xl border border-purple-200 dark:border-purple-700">
            <h3 className="font-bold text-purple-800 dark:text-purple-200 mb-4">í”„ë¡œë•ì…˜ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ êµ¬ì¶•</h3>

            <div className="bg-slate-50 dark:bg-slate-800 p-4 rounded-lg border border-slate-200 dark:border-slate-700 overflow-x-auto">
              <pre className="text-sm text-slate-800 dark:text-slate-200 font-mono">
{`from prometheus_client import Counter, Histogram, Gauge, Summary
import time
from typing import Dict, List, Any, Optional
from datetime import datetime, timedelta
import asyncio
import aiohttp
from dataclasses import dataclass
import pandas as pd

# Prometheus ë©”íŠ¸ë¦­ ì •ì˜
rag_requests_total = Counter(
    'rag_requests_total',
    'Total number of RAG requests',
    ['endpoint', 'status']
)

rag_latency_seconds = Histogram(
    'rag_latency_seconds',
    'RAG request latency in seconds',
    ['operation'],
    buckets=[0.1, 0.25, 0.5, 0.75, 1.0, 2.5, 5.0, 10.0]
)

rag_document_retrieval = Histogram(
    'rag_document_retrieval_count',
    'Number of documents retrieved per request',
    buckets=[1, 5, 10, 20, 50, 100]
)

rag_relevance_score = Summary(
    'rag_relevance_score',
    'Relevance scores of RAG responses'
)

rag_active_users = Gauge(
    'rag_active_users',
    'Number of active users in the last 5 minutes'
)

rag_cache_hit_rate = Gauge(
    'rag_cache_hit_rate',
    'Cache hit rate percentage'
)

rag_model_latency = Histogram(
    'rag_model_latency_seconds',
    'Model inference latency',
    ['model_name', 'operation'],
    buckets=[0.05, 0.1, 0.25, 0.5, 1.0, 2.5]
)

@dataclass
class RAGMetrics:
    """RAG ìš”ì²­ ë©”íŠ¸ë¦­"""
    request_id: str
    timestamp: datetime
    query: str
    latency_total: float
    latency_retrieval: float
    latency_generation: float
    documents_retrieved: int
    relevance_score: float
    cache_hit: bool
    error: Optional[str] = None
    user_id: Optional[str] = None

class RAGMonitoringService:
    def __init__(self):
        """
        ì‹¤ì‹œê°„ RAG ëª¨ë‹ˆí„°ë§ ì„œë¹„ìŠ¤
        - Prometheus ë©”íŠ¸ë¦­ ìˆ˜ì§‘
        - ì‹¤ì‹œê°„ ì´ìƒ íƒì§€
        - ëŒ€ì‹œë³´ë“œ ë°ì´í„° ì œê³µ
        """
        self.metrics_buffer: List[RAGMetrics] = []
        self.active_users: set = set()
        self.alert_rules = self._init_alert_rules()

    def _init_alert_rules(self) -> Dict[str, Dict[str, Any]]:
        """ì•Œë¦¼ ê·œì¹™ ì´ˆê¸°í™”"""
        return {
            'high_latency': {
                'condition': lambda m: m.latency_total > 2.0,
                'severity': 'warning',
                'message': 'High latency detected: {latency_total:.2f}s'
            },
            'low_relevance': {
                'condition': lambda m: m.relevance_score < 0.7,
                'severity': 'warning',
                'message': 'Low relevance score: {relevance_score:.2f}'
            },
            'error_rate': {
                'condition': lambda metrics: self._calculate_error_rate(metrics) > 0.05,
                'severity': 'critical',
                'message': 'Error rate exceeds 5%'
            },
            'cache_miss': {
                'condition': lambda metrics: self._calculate_cache_hit_rate(metrics) < 0.3,
                'severity': 'info',
                'message': 'Cache hit rate below 30%'
            }
        }

    async def record_request(self, metrics: RAGMetrics):
        """ìš”ì²­ ë©”íŠ¸ë¦­ ê¸°ë¡"""
        # Prometheus ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
        rag_requests_total.labels(
            endpoint='rag_query',
            status='success' if not metrics.error else 'error'
        ).inc()

        rag_latency_seconds.labels(operation='total').observe(metrics.latency_total)
        rag_latency_seconds.labels(operation='retrieval').observe(metrics.latency_retrieval)
        rag_latency_seconds.labels(operation='generation').observe(metrics.latency_generation)

        rag_document_retrieval.observe(metrics.documents_retrieved)
        rag_relevance_score.observe(metrics.relevance_score)

        # í™œì„± ì‚¬ìš©ì ì¶”ì 
        if metrics.user_id:
            self.active_users.add(metrics.user_id)

        # ë²„í¼ì— ì¶”ê°€
        self.metrics_buffer.append(metrics)

        # ì´ìƒ íƒì§€
        await self._check_alerts(metrics)

        # ì£¼ê¸°ì  ì •ë¦¬ (5ë¶„ ì´ìƒ ëœ ë°ì´í„°)
        cutoff = datetime.now() - timedelta(minutes=5)
        self.metrics_buffer = [m for m in self.metrics_buffer if m.timestamp > cutoff]

    async def _check_alerts(self, metrics: RAGMetrics):
        """ì•Œë¦¼ ê·œì¹™ ì²´í¬"""
        for rule_name, rule in self.alert_rules.items():
            try:
                if rule_name in ['error_rate', 'cache_miss']:
                    # ì§‘ê³„ ê¸°ë°˜ ê·œì¹™
                    if rule['condition'](self.metrics_buffer):
                        await self._send_alert(rule_name, rule)
                else:
                    # ê°œë³„ ë©”íŠ¸ë¦­ ê¸°ë°˜ ê·œì¹™
                    if rule['condition'](metrics):
                        await self._send_alert(rule_name, rule, metrics)
            except Exception as e:
                print(f"Alert check error: {e}")

    async def _send_alert(self, rule_name: str, rule: Dict[str, Any],
                         metrics: Optional[RAGMetrics] = None):
        """ì•Œë¦¼ ë°œì†¡"""
        message = rule['message']
        if metrics:
            message = message.format(**metrics.__dict__)

        alert = {
            'rule': rule_name,
            'severity': rule['severity'],
            'message': message,
            'timestamp': datetime.now()
        }

        # ì‹¤ì œë¡œëŠ” Slack, PagerDuty ë“±ìœ¼ë¡œ ë°œì†¡
        print(f"ğŸš¨ ALERT [{rule['severity'].upper()}]: {message}")

        # Webhook í˜¸ì¶œ (ì˜ˆì œ)
        if rule['severity'] == 'critical':
            await self._send_webhook(alert)

    async def _send_webhook(self, alert: Dict[str, Any]):
        """Webhook ë°œì†¡"""
        webhook_url = "https://hooks.slack.com/services/YOUR/WEBHOOK/URL"

        payload = {
            'text': f"RAG System Alert",
            'attachments': [{
                'color': 'danger',
                'fields': [
                    {'title': 'Rule', 'value': alert['rule'], 'short': True},
                    {'title': 'Severity', 'value': alert['severity'], 'short': True},
                    {'title': 'Message', 'value': alert['message']},
                    {'title': 'Time', 'value': alert['timestamp'].isoformat()}
                ]
            }]
        }

        # async with aiohttp.ClientSession() as session:
        #     await session.post(webhook_url, json=payload)

    def _calculate_error_rate(self, metrics: List[RAGMetrics]) -> float:
        """ì—ëŸ¬ìœ¨ ê³„ì‚°"""
        if not metrics:
            return 0.0

        error_count = sum(1 for m in metrics if m.error is not None)
        return error_count / len(metrics)

    def _calculate_cache_hit_rate(self, metrics: List[RAGMetrics]) -> float:
        """ìºì‹œ íˆíŠ¸ìœ¨ ê³„ì‚°"""
        if not metrics:
            return 0.0

        cache_hits = sum(1 for m in metrics if m.cache_hit)
        return cache_hits / len(metrics)

    def get_dashboard_data(self) -> Dict[str, Any]:
        """ëŒ€ì‹œë³´ë“œìš© ë°ì´í„° ì¡°íšŒ"""
        if not self.metrics_buffer:
            return self._empty_dashboard_data()

        # ë°ì´í„°í”„ë ˆì„ ë³€í™˜
        df = pd.DataFrame([m.__dict__ for m in self.metrics_buffer])

        # í˜„ì¬ ë©”íŠ¸ë¦­
        current_metrics = {
            'qps': len(df[df['timestamp'] > datetime.now() - timedelta(seconds=60)]),
            'avg_latency': df['latency_total'].mean(),
            'p95_latency': df['latency_total'].quantile(0.95),
            'avg_relevance': df['relevance_score'].mean(),
            'error_rate': self._calculate_error_rate(self.metrics_buffer),
            'cache_hit_rate': self._calculate_cache_hit_rate(self.metrics_buffer),
            'active_users': len(self.active_users),
            'total_requests': len(df)
        }

        # ì‹œê³„ì—´ ë°ì´í„° (1ë¶„ ë‹¨ìœ„)
        df['timestamp_minute'] = df['timestamp'].dt.floor('T')
        time_series = {
            'latency': df.groupby('timestamp_minute')['latency_total'].agg(['mean', 'p95']),
            'throughput': df.groupby('timestamp_minute').size(),
            'relevance': df.groupby('timestamp_minute')['relevance_score'].mean()
        }

        # Top ëŠë¦° ì¿¼ë¦¬
        slow_queries = df.nlargest(10, 'latency_total')[
            ['query', 'latency_total', 'documents_retrieved']
        ].to_dict('records')

        # ëª¨ë¸ë³„ ë ˆì´í„´ì‹œ
        model_latency = {
            'retrieval': {
                'mean': df['latency_retrieval'].mean(),
                'p95': df['latency_retrieval'].quantile(0.95)
            },
            'generation': {
                'mean': df['latency_generation'].mean(),
                'p95': df['latency_generation'].quantile(0.95)
            }
        }

        return {
            'current_metrics': current_metrics,
            'time_series': time_series,
            'slow_queries': slow_queries,
            'model_latency': model_latency,
            'last_updated': datetime.now()
        }

    def _empty_dashboard_data(self) -> Dict[str, Any]:
        """ë¹ˆ ëŒ€ì‹œë³´ë“œ ë°ì´í„°"""
        return {
            'current_metrics': {
                'qps': 0,
                'avg_latency': 0,
                'p95_latency': 0,
                'avg_relevance': 0,
                'error_rate': 0,
                'cache_hit_rate': 0,
                'active_users': 0,
                'total_requests': 0
            },
            'time_series': {},
            'slow_queries': [],
            'model_latency': {},
            'last_updated': datetime.now()
        }

    async def health_check(self) -> Dict[str, Any]:
        """ì‹œìŠ¤í…œ í—¬ìŠ¤ ì²´í¬"""
        health_status = {
            'status': 'healthy',
            'checks': {},
            'timestamp': datetime.now()
        }

        # ê°œë³„ ì»´í¬ë„ŒíŠ¸ ì²´í¬
        checks = {
            'metrics_collection': self._check_metrics_collection(),
            'alert_system': self._check_alert_system(),
            'data_freshness': self._check_data_freshness()
        }

        health_status['checks'] = checks

        # ì „ì²´ ìƒíƒœ ê²°ì •
        if any(check['status'] == 'unhealthy' for check in checks.values()):
            health_status['status'] = 'unhealthy'
        elif any(check['status'] == 'degraded' for check in checks.values()):
            health_status['status'] = 'degraded'

        return health_status

    def _check_metrics_collection(self) -> Dict[str, str]:
        """ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ìƒíƒœ ì²´í¬"""
        if not self.metrics_buffer:
            return {'status': 'unhealthy', 'message': 'No metrics collected'}

        latest_metric = max(self.metrics_buffer, key=lambda m: m.timestamp)
        age = (datetime.now() - latest_metric.timestamp).total_seconds()

        if age > 300:  # 5ë¶„ ì´ìƒ ëœ ë°ì´í„°
            return {'status': 'unhealthy', 'message': f'Stale data: {age:.0f}s old'}
        elif age > 60:  # 1ë¶„ ì´ìƒ
            return {'status': 'degraded', 'message': f'Delayed data: {age:.0f}s old'}

        return {'status': 'healthy', 'message': 'Collecting metrics normally'}

    def _check_alert_system(self) -> Dict[str, str]:
        """ì•Œë¦¼ ì‹œìŠ¤í…œ ìƒíƒœ ì²´í¬"""
        # ì‹¤ì œë¡œëŠ” ë§ˆì§€ë§‰ ì•Œë¦¼ ë°œì†¡ ì‹œê°„ ë“±ì„ ì²´í¬
        return {'status': 'healthy', 'message': 'Alert system operational'}

    def _check_data_freshness(self) -> Dict[str, str]:
        """ë°ì´í„° ì‹ ì„ ë„ ì²´í¬"""
        if not self.metrics_buffer:
            return {'status': 'unhealthy', 'message': 'No data available'}

        # ìµœê·¼ 1ë¶„ê°„ ë°ì´í„° ê°œìˆ˜
        recent_count = sum(1 for m in self.metrics_buffer
                          if m.timestamp > datetime.now() - timedelta(minutes=1))

        if recent_count < 10:
            return {'status': 'degraded', 'message': f'Low traffic: {recent_count} requests/min'}

        return {'status': 'healthy', 'message': f'Normal traffic: {recent_count} requests/min'}

# Grafana ëŒ€ì‹œë³´ë“œ ì„¤ì •
GRAFANA_DASHBOARD_CONFIG = {
    "dashboard": {
        "title": "RAG System Monitoring",
        "panels": [
            {
                "title": "Request Rate",
                "targets": [{
                    "expr": "rate(rag_requests_total[5m])",
                    "legendFormat": "{{endpoint}} - {{status}}"
                }]
            },
            {
                "title": "Latency Percentiles",
                "targets": [{
                    "expr": "histogram_quantile(0.95, rate(rag_latency_seconds_bucket[5m]))",
                    "legendFormat": "P95 {{operation}}"
                }]
            },
            {
                "title": "Relevance Score Distribution",
                "targets": [{
                    "expr": "rag_relevance_score",
                    "legendFormat": "Relevance Score"
                }]
            },
            {
                "title": "Cache Hit Rate",
                "targets": [{
                    "expr": "rag_cache_hit_rate",
                    "legendFormat": "Cache Hit %"
                }]
            },
            {
                "title": "Active Users",
                "targets": [{
                    "expr": "rag_active_users",
                    "legendFormat": "Active Users"
                }]
            },
            {
                "title": "Error Rate",
                "targets": [{
                    "expr": "rate(rag_requests_total{status='error'}[5m]) / rate(rag_requests_total[5m])",
                    "legendFormat": "Error Rate"
                }]
            }
        ]
    }
}

# ì‚¬ìš© ì˜ˆì œ
async def simulate_rag_traffic():
    """RAG íŠ¸ë˜í”½ ì‹œë®¬ë ˆì´ì…˜"""
    monitoring = RAGMonitoringService()

    # 100ê°œì˜ ìš”ì²­ ì‹œë®¬ë ˆì´ì…˜
    for i in range(100):
        # ë©”íŠ¸ë¦­ ìƒì„±
        latency_retrieval = np.random.exponential(0.2)  # í‰ê·  200ms
        latency_generation = np.random.exponential(0.5)  # í‰ê·  500ms

        metrics = RAGMetrics(
            request_id=f"req_{i}",
            timestamp=datetime.now(),
            query=f"Query {i % 20}",
            latency_total=latency_retrieval + latency_generation + np.random.exponential(0.1),
            latency_retrieval=latency_retrieval,
            latency_generation=latency_generation,
            documents_retrieved=np.random.randint(5, 20),
            relevance_score=min(0.95, max(0.5, np.random.normal(0.85, 0.1))),
            cache_hit=np.random.random() > 0.6,
            error="timeout" if np.random.random() < 0.02 else None,
            user_id=f"user_{i % 30}"
        )

        await monitoring.record_request(metrics)
        await asyncio.sleep(0.1)  # 100ms ê°„ê²©

    # ëŒ€ì‹œë³´ë“œ ë°ì´í„° ì¡°íšŒ
    dashboard_data = monitoring.get_dashboard_data()

    print("=== RAG Monitoring Dashboard ===")
    print(f"Current Metrics:")
    for metric, value in dashboard_data['current_metrics'].items():
        if isinstance(value, float):
            print(f"  {metric}: {value:.3f}")
        else:
            print(f"  {metric}: {value}")

    print(f"\nTop Slow Queries:")
    for query in dashboard_data['slow_queries'][:5]:
        print(f"  - {query['query']}: {query['latency_total']:.2f}s")

    # í—¬ìŠ¤ ì²´í¬
    health = await monitoring.health_check()
    print(f"\nHealth Status: {health['status']}")
    for component, status in health['checks'].items():
        print(f"  {component}: {status['status']} - {status['message']}")

# ì‹¤í–‰
print("=== RAG Monitoring System Demo ===\n")
asyncio.run(simulate_rag_traffic())`}
              </pre>
            </div>
          </div>

          <div className="bg-green-50 dark:bg-green-900/20 p-6 rounded-xl border border-green-200 dark:border-green-700">
            <h3 className="font-bold text-green-800 dark:text-green-200 mb-4">ì‹¤ì œ Grafana ëŒ€ì‹œë³´ë“œ êµ¬ì„±</h3>

            <div className="grid md:grid-cols-2 gap-4">
              <div className="bg-white dark:bg-gray-800 p-4 rounded-lg border">
                <h4 className="font-medium text-gray-900 dark:text-white mb-2">ğŸ¯ í•µì‹¬ ë©”íŠ¸ë¦­</h4>
                <ul className="text-sm text-gray-700 dark:text-gray-300 space-y-1">
                  <li>â€¢ Request Rate (QPS)</li>
                  <li>â€¢ Latency (P50, P95, P99)</li>
                  <li>â€¢ Error Rate & Success Rate</li>
                  <li>â€¢ Active Users</li>
                  <li>â€¢ Resource Utilization</li>
                </ul>
              </div>

              <div className="bg-white dark:bg-gray-800 p-4 rounded-lg border">
                <h4 className="font-medium text-gray-900 dark:text-white mb-2">ğŸ“Š ìƒì„¸ ë¶„ì„</h4>
                <ul className="text-sm text-gray-700 dark:text-gray-300 space-y-1">
                  <li>â€¢ Query Distribution</li>
                  <li>â€¢ Document Retrieval Stats</li>
                  <li>â€¢ Model Performance</li>
                  <li>â€¢ Cache Performance</li>
                  <li>â€¢ Cost Analysis</li>
                </ul>
              </div>
            </div>

            <div className="mt-4 bg-emerald-100 dark:bg-emerald-900/40 p-4 rounded-lg">
              <p className="text-sm text-emerald-800 dark:text-emerald-200">
                <strong>ğŸ’¡ Pro Tip:</strong> Golden Signals (Latency, Traffic, Errors, Saturation)ë¥¼
                ê¸°ë°˜ìœ¼ë¡œ ëŒ€ì‹œë³´ë“œë¥¼ êµ¬ì„±í•˜ë©´ ì‹œìŠ¤í…œ ìƒíƒœë¥¼ íš¨ê³¼ì ìœ¼ë¡œ íŒŒì•…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
                íŠ¹íˆ RAG ì‹œìŠ¤í…œì—ì„œëŠ” Relevance Scoreë¥¼ ì¶”ê°€ ì§€í‘œë¡œ í™œìš©í•˜ì„¸ìš”.
              </p>
            </div>
          </div>
        </div>
      </section>

      {/* Practical Exercise */}
      <section className="bg-gradient-to-r from-emerald-500 to-teal-600 rounded-2xl p-8 text-white">
        <h2 className="text-2xl font-bold mb-6">ì‹¤ìŠµ ê³¼ì œ</h2>

        <div className="bg-white/10 rounded-xl p-6 backdrop-blur">
          <h3 className="font-bold mb-4">ì¢…í•© RAG í‰ê°€ ë° ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ êµ¬ì¶•</h3>

          <div className="space-y-4">
            <div className="bg-white/10 p-4 rounded-lg">
              <h4 className="font-medium mb-2">ğŸ“‹ ìš”êµ¬ì‚¬í•­</h4>
              <ol className="space-y-2 text-sm">
                <li>1. RAGAS í”„ë ˆì„ì›Œí¬ë¥¼ í™œìš©í•œ ì˜¤í”„ë¼ì¸ í‰ê°€ ì‹œìŠ¤í…œ êµ¬ì¶•</li>
                <li>2. A/B í…ŒìŠ¤íŠ¸ í”Œë«í¼ êµ¬í˜„ (ìµœì†Œ 3ê°€ì§€ ë³€í˜• ì§€ì›)</li>
                <li>3. Prometheus + Grafana ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ êµ¬ì¶•</li>
                <li>4. ìë™ ì•Œë¦¼ ì‹œìŠ¤í…œ (Slack/Email ì—°ë™)</li>
                <li>5. ì£¼ê°„ ì„±ëŠ¥ ë¦¬í¬íŠ¸ ìë™ ìƒì„±</li>
              </ol>
            </div>

            <div className="bg-white/10 p-4 rounded-lg">
              <h4 className="font-medium mb-2">ğŸ¯ í‰ê°€ ê¸°ì¤€</h4>
              <ul className="space-y-1 text-sm">
                <li>â€¢ í‰ê°€ ë©”íŠ¸ë¦­ì˜ í¬ê´„ì„± (Retrieval + Generation + System)</li>
                <li>â€¢ A/B í…ŒìŠ¤íŠ¸ì˜ í†µê³„ì  ì—„ë°€ì„±</li>
                <li>â€¢ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œì˜ ì‹¤ìš©ì„±</li>
                <li>â€¢ ì•Œë¦¼ ì‹œìŠ¤í…œì˜ ì •í™•ì„± (False positive rate &lt; 5%)</li>
                <li>â€¢ ì‹œìŠ¤í…œ í™•ì¥ì„± (1000+ QPS ì§€ì›)</li>
              </ul>
            </div>

            <div className="bg-white/10 p-4 rounded-lg">
              <h4 className="font-medium mb-2">ğŸ’¡ ë„ì „ ê³¼ì œ</h4>
              <p className="text-sm">
                ML ê¸°ë°˜ ì´ìƒ íƒì§€ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•˜ì—¬ ë‹¨ìˆœ threshold ê¸°ë°˜ ì•Œë¦¼ì„
                ë„˜ì–´ì„œëŠ” ì§€ëŠ¥í˜• ëª¨ë‹ˆí„°ë§ì„ êµ¬í˜„í•´ë³´ì„¸ìš”. íŠ¹íˆ ê³„ì ˆì„±ê³¼ íŠ¸ë Œë“œë¥¼
                ê³ ë ¤í•œ ë™ì  ì„ê³„ê°’ ì„¤ì •ì„ êµ¬í˜„í•˜ë©´ ë”ìš± íš¨ê³¼ì ì…ë‹ˆë‹¤.
              </p>
            </div>
          </div>
        </div>
      </section>

      {/* References */}
      <References
        sections={[
          {
            title: 'ğŸ“š RAG í‰ê°€ í”„ë ˆì„ì›Œí¬',
            icon: 'web' as const,
            color: 'border-emerald-500',
            items: [
              {
                title: 'RAGAS: RAG Assessment Framework',
                authors: 'Explodinggradients',
                year: '2024',
                description: 'RAG ì „ìš© í‰ê°€ - Faithfulness, Answer Relevancy, Context Precision',
                link: 'https://docs.ragas.io/'
              },
              {
                title: 'TruLens: LLM App Evaluation',
                authors: 'TruEra',
                year: '2024',
                description: 'RAG ì¶”ì  ë° í‰ê°€ - Context Relevance, Groundedness, Answer Relevance',
                link: 'https://www.trulens.org/trulens_eval/getting_started/'
              },
              {
                title: 'DeepEval: LLM Testing',
                authors: 'Confident AI',
                year: '2024',
                description: 'Unit Testing for RAG - BLEU, ROUGE, BERTScore, Hallucination Detection',
                link: 'https://docs.confident-ai.com/'
              },
              {
                title: 'Phoenix by Arize AI',
                authors: 'Arize AI',
                year: '2024',
                description: 'LLM Observability - Traces, Evals, Embeddings ì‹œê°í™”',
                link: 'https://docs.arize.com/phoenix'
              },
              {
                title: 'LangSmith Evaluation',
                authors: 'LangChain',
                year: '2024',
                description: 'End-to-end RAG í‰ê°€ - Custom Evaluators, Dataset Management',
                link: 'https://docs.smith.langchain.com/evaluation'
              }
            ]
          },
          {
            title: 'ğŸ“– RAG í‰ê°€ ë©”íŠ¸ë¦­ ì—°êµ¬',
            icon: 'research' as const,
            color: 'border-blue-500',
            items: [
              {
                title: 'ARES: Automated RAG Evaluation System',
                authors: 'Saad-Falcon et al., Stanford',
                year: '2024',
                description: 'ìë™í™”ëœ RAG í‰ê°€ - LLM-as-a-Judge, Synthetic Data Generation',
                link: 'https://arxiv.org/abs/2311.09476'
              },
              {
                title: 'CRUD-RAG: Comprehensive RAG Benchmark',
                authors: 'Lyu et al., Alibaba',
                year: '2024',
                description: 'Create, Read, Update, Delete ì‹œë‚˜ë¦¬ì˜¤ ê¸°ë°˜ ì¢…í•© ë²¤ì¹˜ë§ˆí¬',
                link: 'https://arxiv.org/abs/2401.17043'
              },
              {
                title: 'RGB: Retrieval Generation Benchmark',
                authors: 'Chen et al., Microsoft',
                year: '2024',
                description: 'Multi-domain RAG ë²¤ì¹˜ë§ˆí¬ - ì •í™•ë„, Hallucination, Citation',
                link: 'https://arxiv.org/abs/2309.01431'
              },
              {
                title: 'Evaluating Retrieval Quality in RAG',
                authors: 'Lewis et al., Meta',
                year: '2023',
                description: 'Retrieval Precision vs Generation Quality íŠ¸ë ˆì´ë“œì˜¤í”„ ì—°êµ¬',
                link: 'https://arxiv.org/abs/2312.10997'
              }
            ]
          },
          {
            title: 'ğŸ› ï¸ ëª¨ë‹ˆí„°ë§ & ì˜µì €ë²„ë¹Œë¦¬í‹°',
            icon: 'tools' as const,
            color: 'border-purple-500',
            items: [
              {
                title: 'OpenTelemetry for LLM Apps',
                authors: 'OpenTelemetry',
                year: '2024',
                description: 'RAG íŠ¸ë ˆì´ì‹± - Spans, Metrics, Logs í‘œì¤€í™”',
                link: 'https://opentelemetry.io/docs/instrumentation/python/libraries/openai/'
              },
              {
                title: 'Langfuse: LLM Engineering Platform',
                authors: 'Langfuse',
                year: '2024',
                description: 'RAG ëª¨ë‹ˆí„°ë§ - Traces, Scores, Datasets, Prompt Management',
                link: 'https://langfuse.com/docs'
              },
              {
                title: 'Weights & Biases for LLMs',
                authors: 'Weights & Biases',
                year: '2024',
                description: 'RAG ì‹¤í—˜ ì¶”ì  - Prompts, Model Versions, A/B Testing',
                link: 'https://docs.wandb.ai/guides/prompts'
              },
              {
                title: 'Helicone: LLM Observability',
                authors: 'Helicone',
                year: '2024',
                description: 'OpenAI API ëª¨ë‹ˆí„°ë§ - Cost, Latency, Error Tracking',
                link: 'https://docs.helicone.ai/'
              },
              {
                title: 'Datadog LLM Observability',
                authors: 'Datadog',
                year: '2024',
                description: 'Enterprise RAG ëª¨ë‹ˆí„°ë§ - APM, Logs, Traces í†µí•©',
                link: 'https://docs.datadoghq.com/llm_observability/'
              }
            ]
          }
        ]}
      />

      {/* Navigation */}
      <div className="mt-12 bg-white dark:bg-gray-800 rounded-2xl p-6 shadow-sm border border-gray-200 dark:border-gray-700">
        <div className="flex justify-between items-center">
          <Link
            href="/modules/rag/advanced/chapter4"
            className="inline-flex items-center gap-2 text-gray-600 dark:text-gray-400 hover:text-gray-900 dark:hover:text-white transition-colors"
          >
            <ArrowLeft size={16} />
            ì´ì „: ê³ ê¸‰ Reranking ì „ëµ
          </Link>

          <Link
            href="/modules/rag/advanced/chapter6"
            className="inline-flex items-center gap-2 bg-emerald-500 text-white px-6 py-3 rounded-lg font-medium hover:bg-emerald-600 transition-colors"
          >
            ë‹¤ìŒ: ìµœì‹  ì—°êµ¬ ë™í–¥
            <ArrowRight size={16} />
          </Link>
        </div>
      </div>
    </>
  )
}

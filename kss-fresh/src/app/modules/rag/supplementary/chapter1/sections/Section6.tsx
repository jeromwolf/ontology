'use client'

import Link from 'next/link'
import { ArrowLeft, ArrowRight, TrendingUp } from 'lucide-react'
import References from '@/components/common/References'

export default function Section6() {
  return (
    <>
      <section className="bg-white dark:bg-gray-800 rounded-2xl p-8 shadow-sm border border-gray-200 dark:border-gray-700">
        <div className="flex items-center gap-3 mb-6">
          <div className="w-12 h-12 rounded-xl bg-purple-100 dark:bg-purple-900/20 flex items-center justify-center">
            <TrendingUp className="text-purple-600" size={24} />
          </div>
          <div>
            <h2 className="text-2xl font-bold text-gray-900 dark:text-white">1.6 Production êµ¬í˜„ ê°€ì´ë“œ</h2>
            <p className="text-gray-600 dark:text-gray-400">ì‹¤ì œ ì„œë¹„ìŠ¤ì—ì„œì˜ RAGAS í™œìš©ë²•</p>
          </div>
        </div>

        <div className="space-y-6">
          <div className="bg-gradient-to-r from-purple-50 to-pink-50 dark:from-purple-900/20 dark:to-pink-900/20 p-6 rounded-xl">
            <h3 className="font-bold text-purple-800 dark:text-purple-200 mb-4">ì™„ì „í•œ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ</h3>
            <pre className="bg-black text-green-400 p-4 rounded-lg overflow-x-auto">
              <code>{`# Production ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ
import streamlit as st
import pandas as pd
import plotly.graph_objects as go
from datetime import datetime, timedelta

class RAGMonitoringDashboard:
    def __init__(self):
        self.metrics_history = []

    def add_evaluation(self, eval_results):
        """í‰ê°€ ê²°ê³¼ ì¶”ê°€"""
        self.metrics_history.append({
            'timestamp': datetime.now(),
            'scores': eval_results,
            'alerts': self._check_alerts(eval_results)
        })

    def _check_alerts(self, scores):
        """ì•Œë¦¼ ì¡°ê±´ í™•ì¸"""
        alerts = []
        thresholds = {
            'context_relevancy': 0.7,
            'answer_faithfulness': 0.8,
            'answer_relevancy': 0.75
        }

        for metric, threshold in thresholds.items():
            if scores.get(metric, 1.0) < threshold:
                alerts.append({
                    'metric': metric,
                    'score': scores[metric],
                    'threshold': threshold,
                    'severity': 'high' if scores[metric] < threshold * 0.7 else 'medium'
                })

        return alerts

    def render_dashboard(self):
        """Streamlit ëŒ€ì‹œë³´ë“œ ë Œë”ë§"""
        st.title("ğŸš€ RAG System Monitoring Dashboard")

        # í˜„ì¬ ìƒíƒœ ìš”ì•½
        col1, col2, col3, col4 = st.columns(4)

        latest_scores = self.metrics_history[-1]['scores'] if self.metrics_history else {}

        with col1:
            st.metric(
                "Context Relevancy",
                f"{latest_scores.get('context_relevancy', 0):.2%}",
                delta=self._calculate_delta('context_relevancy')
            )

        with col2:
            st.metric(
                "Answer Faithfulness",
                f"{latest_scores.get('answer_faithfulness', 0):.2%}",
                delta=self._calculate_delta('answer_faithfulness')
            )

        with col3:
            st.metric(
                "Answer Relevancy",
                f"{latest_scores.get('answer_relevancy', 0):.2%}",
                delta=self._calculate_delta('answer_relevancy')
            )

        with col4:
            active_alerts = sum(len(h['alerts']) for h in self.metrics_history[-10:])
            st.metric("Active Alerts", active_alerts, delta=-2 if active_alerts > 0 else 0)

        # ì‹œê³„ì—´ ê·¸ë˜í”„
        st.subheader("ğŸ“Š Metrics Over Time")
        self._render_time_series()

        # ì•Œë¦¼ ì„¹ì…˜
        st.subheader("âš ï¸ Recent Alerts")
        self._render_alerts()

        # ê¶Œì¥ ì¡°ì¹˜
        st.subheader("ğŸ’¡ Recommended Actions")
        self._render_recommendations()

    def _calculate_delta(self, metric_name):
        """ë³€í™”ëŸ‰ ê³„ì‚°"""
        if len(self.metrics_history) < 2:
            return 0

        current = self.metrics_history[-1]['scores'].get(metric_name, 0)
        previous = self.metrics_history[-2]['scores'].get(metric_name, 0)

        return f"{(current - previous):.1%}"

    def _render_time_series(self):
        """ì‹œê³„ì—´ ì°¨íŠ¸ ë Œë”ë§"""
        if not self.metrics_history:
            st.info("No data available yet")
            return

        # ë°ì´í„° ì¤€ë¹„
        df = pd.DataFrame([
            {
                'timestamp': h['timestamp'],
                **h['scores']
            }
            for h in self.metrics_history
        ])

        # Plotly ì°¨íŠ¸
        fig = go.Figure()

        for metric in ['context_relevancy', 'answer_faithfulness', 'answer_relevancy']:
            fig.add_trace(go.Scatter(
                x=df['timestamp'],
                y=df[metric],
                mode='lines+markers',
                name=metric.replace('_', ' ').title(),
                line=dict(width=2)
            ))

        # ì„ê³„ê°’ ë¼ì¸ ì¶”ê°€
        fig.add_hline(y=0.8, line_dash="dash", line_color="red",
                      annotation_text="Critical Threshold")
        fig.add_hline(y=0.7, line_dash="dash", line_color="orange",
                      annotation_text="Warning Threshold")

        fig.update_layout(
            title="RAG Metrics Trend",
            xaxis_title="Time",
            yaxis_title="Score",
            yaxis=dict(range=[0, 1]),
            hovermode='x unified'
        )

        st.plotly_chart(fig, use_container_width=True)

    def _render_alerts(self):
        """ìµœê·¼ ì•Œë¦¼ í‘œì‹œ"""
        recent_alerts = []
        for h in self.metrics_history[-10:]:
            for alert in h['alerts']:
                recent_alerts.append({
                    'Time': h['timestamp'].strftime('%Y-%m-%d %H:%M'),
                    'Metric': alert['metric'].replace('_', ' ').title(),
                    'Score': f"{alert['score']:.2%}",
                    'Threshold': f"{alert['threshold']:.2%}",
                    'Severity': alert['severity'].upper()
                })

        if recent_alerts:
            df = pd.DataFrame(recent_alerts)
            st.dataframe(
                df,
                use_container_width=True,
                hide_index=True
            )
        else:
            st.success("No alerts in recent evaluations!")

    def _render_recommendations(self):
        """ê¶Œì¥ ì¡°ì¹˜ ì œì•ˆ"""
        if not self.metrics_history:
            return

        latest = self.metrics_history[-1]['scores']

        recommendations = []

        if latest.get('context_relevancy', 1) < 0.7:
            recommendations.append({
                'issue': 'Low Context Relevancy',
                'action': 'â€¢ ì„ë² ë”© ëª¨ë¸ ì¬í•™ìŠµ\\nâ€¢ ì²­í‚¹ ì „ëµ ê°œì„ \\nâ€¢ ë©”íƒ€ë°ì´í„° í•„í„°ë§ ê°•í™”'
            })

        if latest.get('answer_faithfulness', 1) < 0.8:
            recommendations.append({
                'issue': 'Low Answer Faithfulness',
                'action': 'â€¢ í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ê°œì„ \\nâ€¢ ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš° í¬ê¸° ì¡°ì •\\nâ€¢ Few-shot ì˜ˆì œ ì¶”ê°€'
            })

        if recommendations:
            for rec in recommendations:
                st.warning(f"**{rec['issue']}**")
                st.markdown(rec['action'])
        else:
            st.success("ì‹œìŠ¤í…œì´ ìµœì  ìƒíƒœë¡œ ìš´ì˜ ì¤‘ì…ë‹ˆë‹¤!")

# ì‹¤ì œ ì‚¬ìš© ì˜ˆì œ
if __name__ == "__main__":
    dashboard = RAGMonitoringDashboard()

    # ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ì¶”ê°€ (ì‹¤ì œë¡œëŠ” ì‹¤ì‹œê°„ í‰ê°€ ê²°ê³¼)
    import random
    for i in range(24):  # 24ì‹œê°„ ë°ì´í„°
        scores = {
            'context_relevancy': random.uniform(0.65, 0.85),
            'answer_faithfulness': random.uniform(0.75, 0.95),
            'answer_relevancy': random.uniform(0.70, 0.90),
            'context_recall': random.uniform(0.60, 0.80)
        }
        dashboard.add_evaluation(scores)

    # Streamlit ì•± ì‹¤í–‰
    dashboard.render_dashboard()`}</code>
            </pre>
          </div>

          <div className="bg-blue-50 dark:bg-blue-900/20 p-6 rounded-xl">
            <h3 className="font-bold text-blue-800 dark:text-blue-200 mb-3">ë¹„ìš© ë¶„ì„</h3>
            <div className="overflow-x-auto">
              <table className="w-full text-sm">
                <thead>
                  <tr className="border-b border-blue-200 dark:border-blue-700">
                    <th className="text-left py-2 text-blue-800 dark:text-blue-200">í‰ê°€ ì „ëµ</th>
                    <th className="text-right py-2 text-blue-800 dark:text-blue-200">ì›”ê°„ ì¿¼ë¦¬</th>
                    <th className="text-right py-2 text-blue-800 dark:text-blue-200">í‰ê°€ ë¹„ìœ¨</th>
                    <th className="text-right py-2 text-blue-800 dark:text-blue-200">ì˜ˆìƒ ë¹„ìš©</th>
                  </tr>
                </thead>
                <tbody className="text-blue-700 dark:text-blue-300">
                  <tr>
                    <td className="py-2">ì „ì²´ í‰ê°€</td>
                    <td className="text-right">100,000</td>
                    <td className="text-right">100%</td>
                    <td className="text-right">$2,000</td>
                  </tr>
                  <tr>
                    <td className="py-2">ìƒ˜í”Œë§ (ê¶Œì¥)</td>
                    <td className="text-right">100,000</td>
                    <td className="text-right">15%</td>
                    <td className="text-right">$300</td>
                  </tr>
                  <tr>
                    <td className="py-2">ì¤‘ìš” ì¿¼ë¦¬ë§Œ</td>
                    <td className="text-right">100,000</td>
                    <td className="text-right">5%</td>
                    <td className="text-right">$100</td>
                  </tr>
                </tbody>
              </table>
            </div>
          </div>
        </div>
      </section>

      {/* References */}
      <References
        sections={[
          {
            title: 'ğŸ“š RAGAS & í‰ê°€ í”„ë ˆì„ì›Œí¬',
            icon: 'web' as const,
            color: 'border-purple-500',
            items: [
              {
                title: 'RAGAS Official Documentation',
                authors: 'Explodinggradients',
                year: '2024',
                description: 'RAG í‰ê°€ í”„ë ˆì„ì›Œí¬ - Context Relevancy, Answer Faithfulness, Answer Relevancy ê³µì‹ ë¬¸ì„œ',
                link: 'https://docs.ragas.io/'
              },
              {
                title: 'TruLens: LLM Evaluation & Observability',
                authors: 'TruEra',
                year: '2024',
                description: 'LLM ì• í”Œë¦¬ì¼€ì´ì…˜ í‰ê°€ - Groundedness, Answer Relevance, Context Relevance ì¸¡ì •',
                link: 'https://www.trulens.org/'
              },
              {
                title: 'LangSmith Evaluation',
                authors: 'LangChain',
                year: '2024',
                description: 'LangChain ê³µì‹ í‰ê°€ ë„êµ¬ - ìë™í™”ëœ í…ŒìŠ¤íŠ¸, ë¹„êµ ë¶„ì„, Production ëª¨ë‹ˆí„°ë§',
                link: 'https://docs.smith.langchain.com/evaluation'
              },
              {
                title: 'DeepEval: Unit Testing for LLMs',
                authors: 'Confident AI',
                year: '2024',
                description: 'LLM ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ í”„ë ˆì„ì›Œí¬ - 14ê°œ í‰ê°€ ë©”íŠ¸ë¦­, Pytest í†µí•©, CI/CD ì§€ì›',
                link: 'https://docs.confident-ai.com/'
              },
              {
                title: 'Evidently AI: ML Monitoring',
                authors: 'Evidently AI',
                year: '2024',
                description: 'ML ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ - ë°ì´í„° ë“œë¦¬í”„íŠ¸, ì„±ëŠ¥ ì €í•˜ ê°ì§€, ëŒ€ì‹œë³´ë“œ ìƒì„±',
                link: 'https://www.evidentlyai.com/'
              }
            ]
          },
          {
            title: 'ğŸ“– RAG í‰ê°€ ì—°êµ¬ ë…¼ë¬¸',
            icon: 'research' as const,
            color: 'border-pink-500',
            items: [
              {
                title: 'ARES: An Automated Evaluation Framework for RAG',
                authors: 'Saad-Falcon et al., Stanford',
                year: '2024',
                description: 'ìë™í™”ëœ RAG í‰ê°€ - Synthetic ë°ì´í„° ìƒì„±, LLM-as-judge, ì¸ê°„ í‰ê°€ ëŒ€ì²´',
                link: 'https://arxiv.org/abs/2311.09476'
              },
              {
                title: 'Benchmarking Large Language Models in RAG',
                authors: 'Chen et al., Tsinghua University',
                year: '2024',
                description: 'RGB ë²¤ì¹˜ë§ˆí¬ - 4ê°œ ë„ë©”ì¸, ë‹¤ì–‘í•œ RAG ì‹œë‚˜ë¦¬ì˜¤, ì¢…í•© í‰ê°€ í”„ë ˆì„ì›Œí¬',
                link: 'https://arxiv.org/abs/2309.01431'
              },
              {
                title: 'RAGAS: Automated Evaluation of RAG',
                authors: 'Es et al., Explodinggradients',
                year: '2023',
                description: 'RAGAS ë…¼ë¬¸ - Reference-free í‰ê°€, LLM ê¸°ë°˜ ë©”íŠ¸ë¦­, ìë™í™”ëœ í’ˆì§ˆ ì¸¡ì •',
                link: 'https://arxiv.org/abs/2309.15217'
              },
              {
                title: 'Evaluating RAG: A Survey',
                authors: 'Liu et al., Microsoft Research',
                year: '2024',
                description: 'RAG í‰ê°€ ì„œë² ì´ - ê¸°ì¡´ ë©”íŠ¸ë¦­ ë¶„ë¥˜, í•œê³„ì  ë¶„ì„, ë¯¸ë˜ ë°©í–¥ ì œì‹œ',
                link: 'https://arxiv.org/abs/2405.17009'
              }
            ]
          },
          {
            title: 'ğŸ› ï¸ Production ëª¨ë‹ˆí„°ë§ ë„êµ¬',
            icon: 'tools' as const,
            color: 'border-blue-500',
            items: [
              {
                title: 'Weights & Biases: ML Experiment Tracking',
                authors: 'Weights & Biases',
                year: '2024',
                description: 'ML ì‹¤í—˜ ì¶”ì  - ë©”íŠ¸ë¦­ ì‹œê°í™”, í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”, íŒ€ í˜‘ì—…',
                link: 'https://wandb.ai/'
              },
              {
                title: 'MLflow: Open Source ML Platform',
                authors: 'Databricks',
                year: '2024',
                description: 'ML ë¼ì´í”„ì‚¬ì´í´ ê´€ë¦¬ - ì‹¤í—˜ ì¶”ì , ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬, ë°°í¬ ìë™í™”',
                link: 'https://mlflow.org/'
              },
              {
                title: 'Streamlit: Data App Framework',
                authors: 'Snowflake',
                year: '2024',
                description: 'Python ëŒ€ì‹œë³´ë“œ - ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ UI, ë¹ ë¥¸ í”„ë¡œí† íƒ€ì´í•‘, ì¸í„°ë™í‹°ë¸Œ ì°¨íŠ¸',
                link: 'https://streamlit.io/'
              },
              {
                title: 'Grafana + Prometheus: Metrics Monitoring',
                authors: 'Grafana Labs',
                year: '2024',
                description: 'ì‹œê³„ì—´ ë©”íŠ¸ë¦­ ëª¨ë‹ˆí„°ë§ - ì•Œë¦¼ ì„¤ì •, ì‹¤ì‹œê°„ ëŒ€ì‹œë³´ë“œ, ë‹¤ì¤‘ ë°ì´í„°ì†ŒìŠ¤ ì§€ì›',
                link: 'https://grafana.com/'
              },
              {
                title: 'Arize AI: ML Observability Platform',
                authors: 'Arize AI',
                year: '2024',
                description: 'ML ê´€ì¸¡ì„± í”Œë«í¼ - ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§, ë“œë¦¬í”„íŠ¸ ê°ì§€, ê·¼ë³¸ ì›ì¸ ë¶„ì„',
                link: 'https://arize.com/'
              }
            ]
          }
        ]}
      />

      {/* Navigation */}
      <div className="flex justify-between items-center mt-12 pt-8 border-t border-gray-200 dark:border-gray-700">
        <Link
          href="/modules/rag/supplementary"
          className="flex items-center gap-2 text-purple-600 hover:text-purple-700 transition-colors"
        >
          <ArrowLeft size={20} />
          ë³´ì¶© ê³¼ì •ìœ¼ë¡œ ëŒì•„ê°€ê¸°
        </Link>

        <Link
          href="/modules/rag/supplementary/chapter2"
          className="flex items-center gap-2 text-purple-600 hover:text-purple-700 transition-colors"
        >
          ë‹¤ìŒ: Security & Privacy
          <ArrowRight size={20} />
        </Link>
      </div>
    </>
  )
}

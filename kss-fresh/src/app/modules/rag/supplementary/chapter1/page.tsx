'use client'

import Link from 'next/link'
import { ArrowLeft, ArrowRight, BarChart3, CheckCircle2, AlertCircle, Code, FileText, TrendingUp } from 'lucide-react'
import References from '@/components/common/References'

export default function Chapter1Page() {
  return (
    <div className="max-w-4xl mx-auto py-8 px-4">
      {/* Header */}
      <div className="mb-8">
        <Link
          href="/modules/rag/supplementary"
          className="inline-flex items-center gap-2 text-purple-600 hover:text-purple-700 mb-4 transition-colors"
        >
          <ArrowLeft size={20} />
          ë³´ì¶© ê³¼ì •ìœ¼ë¡œ ëŒì•„ê°€ê¸°
        </Link>
        
        <div className="bg-gradient-to-r from-purple-500 to-pink-600 rounded-2xl p-8 text-white">
          <div className="flex items-center gap-4 mb-4">
            <div className="w-16 h-16 rounded-xl bg-white/20 flex items-center justify-center">
              <BarChart3 size={32} />
            </div>
            <div>
              <h1 className="text-3xl font-bold">Chapter 1: RAGAS í‰ê°€ í”„ë ˆì„ì›Œí¬</h1>
              <p className="text-purple-100 text-lg">Production RAG ì‹œìŠ¤í…œì˜ ì •ëŸ‰ì  í’ˆì§ˆ ì¸¡ì •</p>
            </div>
          </div>
        </div>
      </div>

      {/* Content */}
      <div className="space-y-8">
        {/* Section 1: RAGAS Introduction */}
        <section className="bg-white dark:bg-gray-800 rounded-2xl p-8 shadow-sm border border-gray-200 dark:border-gray-700">
          <div className="flex items-center gap-3 mb-6">
            <div className="w-12 h-12 rounded-xl bg-purple-100 dark:bg-purple-900/20 flex items-center justify-center">
              <BarChart3 className="text-purple-600" size={24} />
            </div>
            <div>
              <h2 className="text-2xl font-bold text-gray-900 dark:text-white">1.1 RAGASë€ ë¬´ì—‡ì¸ê°€?</h2>
              <p className="text-gray-600 dark:text-gray-400">Reference-Aware Grading And Scoring System</p>
            </div>
          </div>

          <div className="space-y-6">
            <div className="bg-purple-50 dark:bg-purple-900/20 p-6 rounded-xl">
              <h3 className="font-bold text-purple-800 dark:text-purple-200 mb-3">ì™œ RAGASê°€ í•„ìš”í•œê°€?</h3>
              <ul className="space-y-2 text-purple-700 dark:text-purple-300">
                <li>â€¢ RAG ì‹œìŠ¤í…œì˜ í’ˆì§ˆì„ ê°ê´€ì ìœ¼ë¡œ ì¸¡ì •</li>
                <li>â€¢ ì¸ê°„ í‰ê°€ ì—†ì´ ìë™í™”ëœ í‰ê°€ ê°€ëŠ¥</li>
                <li>â€¢ ëª¨ë¸ ë³€ê²½/ì—…ë°ì´íŠ¸ ì‹œ ì„±ëŠ¥ ì¶”ì </li>
                <li>â€¢ A/B í…ŒìŠ¤íŠ¸ ë° ì§€ì†ì  ê°œì„  ê°€ëŠ¥</li>
              </ul>
            </div>

            <div className="bg-gray-50 dark:bg-gray-900 p-6 rounded-xl">
              <h3 className="font-bold text-gray-800 dark:text-gray-200 mb-4">ì„¤ì¹˜ ë° ì´ˆê¸° ì„¤ì •</h3>
              <pre className="bg-black text-green-400 p-4 rounded-lg overflow-x-auto">
                <code>{`# RAGAS ì„¤ì¹˜
pip install ragas langchain openai

# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ import
from ragas import evaluate
from ragas.metrics import (
    context_relevancy,
    answer_faithfulness,
    answer_relevancy,
    context_recall
)`}</code>
              </pre>
            </div>
          </div>
        </section>

        {/* Section 2: Context Relevancy */}
        <section className="bg-white dark:bg-gray-800 rounded-2xl p-8 shadow-sm border border-gray-200 dark:border-gray-700">
          <div className="flex items-center gap-3 mb-6">
            <div className="w-12 h-12 rounded-xl bg-blue-100 dark:bg-blue-900/20 flex items-center justify-center">
              <FileText className="text-blue-600" size={24} />
            </div>
            <div>
              <h2 className="text-2xl font-bold text-gray-900 dark:text-white">1.2 Context Relevancy (ë¬¸ë§¥ ê´€ë ¨ì„±)</h2>
              <p className="text-gray-600 dark:text-gray-400">ê²€ìƒ‰ëœ ë¬¸ì„œê°€ ì§ˆë¬¸ê³¼ ì–¼ë§ˆë‚˜ ê´€ë ¨ì´ ìˆëŠ”ê°€?</p>
            </div>
          </div>

          <div className="space-y-6">
            <div className="bg-blue-50 dark:bg-blue-900/20 p-6 rounded-xl">
              <h3 className="font-bold text-blue-800 dark:text-blue-200 mb-3">í‰ê°€ ì›ë¦¬</h3>
              <p className="text-blue-700 dark:text-blue-300 mb-4">
                Context RelevancyëŠ” ê²€ìƒ‰ëœ ë¬¸ì„œ ì¤‘ ì‹¤ì œë¡œ ì§ˆë¬¸ì— ë‹µí•˜ëŠ”ë° í•„ìš”í•œ ì •ë³´ì˜ ë¹„ìœ¨ì„ ì¸¡ì •í•©ë‹ˆë‹¤.
              </p>
              <div className="bg-white dark:bg-gray-800 p-4 rounded-lg border border-blue-200 dark:border-blue-700">
                <p className="text-sm font-mono text-blue-600 dark:text-blue-400">
                  ì ìˆ˜ = (ê´€ë ¨ ë¬¸ì¥ ìˆ˜) / (ì „ì²´ ë¬¸ì¥ ìˆ˜)
                </p>
              </div>
            </div>

            <div className="bg-gray-50 dark:bg-gray-900 p-6 rounded-xl">
              <h3 className="font-bold text-gray-800 dark:text-gray-200 mb-4">ì‹¤ì œ êµ¬í˜„ ì½”ë“œ</h3>
              <pre className="bg-black text-green-400 p-4 rounded-lg overflow-x-auto">
                <code>{`from ragas.metrics import context_relevancy
from datasets import Dataset

# í‰ê°€ ë°ì´í„° ì¤€ë¹„
data = {
    "question": [
        "í•œêµ­ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì¸ê°€ìš”?",
        "Pythonì—ì„œ ë¦¬ìŠ¤íŠ¸ë¥¼ ì •ë ¬í•˜ëŠ” ë°©ë²•ì€?"
    ],
    "contexts": [
        ["ì„œìš¸ì€ í•œêµ­ì˜ ìˆ˜ë„ì´ë©°, ì¸êµ¬ ì•½ 950ë§Œëª…ì˜ ëŒ€ë„ì‹œì…ë‹ˆë‹¤."],
        ["Pythonì—ì„œëŠ” sort() ë©”ì„œë“œë‚˜ sorted() í•¨ìˆ˜ë¡œ ë¦¬ìŠ¤íŠ¸ë¥¼ ì •ë ¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. sort()ëŠ” ì›ë³¸ì„ ë³€ê²½í•˜ê³ , sorted()ëŠ” ìƒˆ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."]
    ],
    "answer": [
        "í•œêµ­ì˜ ìˆ˜ë„ëŠ” ì„œìš¸ì…ë‹ˆë‹¤.",
        "sort() ë©”ì„œë“œë‚˜ sorted() í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤."
    ]
}

dataset = Dataset.from_dict(data)

# Context Relevancy í‰ê°€
result = evaluate(
    dataset,
    metrics=[context_relevancy],
)

print(f"Context Relevancy Score: {result['context_relevancy']:.3f}")`}</code>
              </pre>
            </div>

            <div className="bg-green-50 dark:bg-green-900/20 p-6 rounded-xl">
              <h3 className="font-bold text-green-800 dark:text-green-200 mb-3">Production ì²´í¬ë¦¬ìŠ¤íŠ¸</h3>
              <ul className="space-y-2">
                <li className="flex items-start gap-2">
                  <CheckCircle2 className="text-green-600 mt-1" size={16} />
                  <span className="text-green-700 dark:text-green-300">ì„ê³„ê°’ ì„¤ì •: ì¼ë°˜ì ìœ¼ë¡œ 0.7 ì´ìƒì„ ê¶Œì¥</span>
                </li>
                <li className="flex items-start gap-2">
                  <CheckCircle2 className="text-green-600 mt-1" size={16} />
                  <span className="text-green-700 dark:text-green-300">ëª¨ë‹ˆí„°ë§: ì‹œê°„ì— ë”°ë¥¸ ì ìˆ˜ ì¶”ì´ ê´€ì°°</span>
                </li>
                <li className="flex items-start gap-2">
                  <CheckCircle2 className="text-green-600 mt-1" size={16} />
                  <span className="text-green-700 dark:text-green-300">ì•Œë¦¼ ì„¤ì •: ì ìˆ˜ê°€ ì„ê³„ê°’ ì´í•˜ë¡œ ë–¨ì–´ì§€ë©´ ì¦‰ì‹œ ì•Œë¦¼</span>
                </li>
              </ul>
            </div>
          </div>
        </section>

        {/* Section 3: Answer Faithfulness */}
        <section className="bg-white dark:bg-gray-800 rounded-2xl p-8 shadow-sm border border-gray-200 dark:border-gray-700">
          <div className="flex items-center gap-3 mb-6">
            <div className="w-12 h-12 rounded-xl bg-green-100 dark:bg-green-900/20 flex items-center justify-center">
              <CheckCircle2 className="text-green-600" size={24} />
            </div>
            <div>
              <h2 className="text-2xl font-bold text-gray-900 dark:text-white">1.3 Answer Faithfulness (ë‹µë³€ ì¶©ì‹¤ë„)</h2>
              <p className="text-gray-600 dark:text-gray-400">ë‹µë³€ì´ ì œê³µëœ ë¬¸ë§¥ì— ì–¼ë§ˆë‚˜ ì¶©ì‹¤í•œê°€?</p>
            </div>
          </div>

          <div className="space-y-6">
            <div className="bg-green-50 dark:bg-green-900/20 p-6 rounded-xl">
              <h3 className="font-bold text-green-800 dark:text-green-200 mb-3">í‰ê°€ ì›ë¦¬</h3>
              <p className="text-green-700 dark:text-green-300 mb-4">
                ë‹µë³€ì˜ ê° ì£¼ì¥ì´ ê²€ìƒ‰ëœ ë¬¸ë§¥ì—ì„œ ì§ì ‘ ìœ ì¶” ê°€ëŠ¥í•œì§€ ê²€ì¦í•©ë‹ˆë‹¤. í™˜ê°(hallucination)ì„ ë°©ì§€í•˜ëŠ” í•µì‹¬ ì§€í‘œì…ë‹ˆë‹¤.
              </p>
            </div>

            <div className="bg-gray-50 dark:bg-gray-900 p-6 rounded-xl">
              <h3 className="font-bold text-gray-800 dark:text-gray-200 mb-4">ì‹¤ë¬´ ì˜ˆì œ: í™˜ê° ê°ì§€</h3>
              <pre className="bg-black text-green-400 p-4 rounded-lg overflow-x-auto">
                <code>{`# í™˜ê° ê°ì§€ ì‹œìŠ¤í…œ êµ¬í˜„
class HallucinationDetector:
    def __init__(self, threshold=0.8):
        self.threshold = threshold
        self.metric = answer_faithfulness
        
    def check_answer(self, question, context, answer):
        data = {
            "question": [question],
            "contexts": [[context]],
            "answer": [answer]
        }
        
        dataset = Dataset.from_dict(data)
        result = evaluate(dataset, metrics=[self.metric])
        
        score = result['answer_faithfulness']
        
        if score < self.threshold:
            return {
                "status": "hallucination_detected",
                "score": score,
                "message": "ë‹µë³€ì— ë¬¸ë§¥ì— ì—†ëŠ” ë‚´ìš©ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤."
            }
        
        return {
            "status": "faithful",
            "score": score,
            "message": "ë‹µë³€ì´ ë¬¸ë§¥ì— ì¶©ì‹¤í•©ë‹ˆë‹¤."
        }

# ì‚¬ìš© ì˜ˆì œ
detector = HallucinationDetector(threshold=0.8)

result = detector.check_answer(
    question="Pythonì˜ ì¥ì ì€?",
    context="Pythonì€ ì½ê¸° ì‰¬ìš´ ë¬¸ë²•ê³¼ í’ë¶€í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì œê³µí•©ë‹ˆë‹¤.",
    answer="Pythonì€ ì½ê¸° ì‰¬ìš´ ë¬¸ë²•, í’ë¶€í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬, ê·¸ë¦¬ê³  ë¹ ë¥¸ ì‹¤í–‰ ì†ë„ë¥¼ ì œê³µí•©ë‹ˆë‹¤."  # í™˜ê°: ë¹ ë¥¸ ì‹¤í–‰ ì†ë„
)

print(result)`}</code>
              </pre>
            </div>
          </div>
        </section>

        {/* Section 4: Answer Relevancy */}
        <section className="bg-white dark:bg-gray-800 rounded-2xl p-8 shadow-sm border border-gray-200 dark:border-gray-700">
          <div className="flex items-center gap-3 mb-6">
            <div className="w-12 h-12 rounded-xl bg-orange-100 dark:bg-orange-900/20 flex items-center justify-center">
              <TrendingUp className="text-orange-600" size={24} />
            </div>
            <div>
              <h2 className="text-2xl font-bold text-gray-900 dark:text-white">1.4 Answer Relevancy (ë‹µë³€ ê´€ë ¨ì„±)</h2>
              <p className="text-gray-600 dark:text-gray-400">ë‹µë³€ì´ ì§ˆë¬¸ì— ì–¼ë§ˆë‚˜ ì§ì ‘ì ìœ¼ë¡œ ë‹µí•˜ëŠ”ê°€?</p>
            </div>
          </div>

          <div className="space-y-6">
            <div className="bg-orange-50 dark:bg-orange-900/20 p-6 rounded-xl">
              <h3 className="font-bold text-orange-800 dark:text-orange-200 mb-3">í‰ê°€ ì›ë¦¬</h3>
              <p className="text-orange-700 dark:text-orange-300 mb-4">
                ë‹µë³€ì—ì„œ ìƒì„± ê°€ëŠ¥í•œ ì§ˆë¬¸ë“¤ê³¼ ì›ë˜ ì§ˆë¬¸ì˜ ìœ ì‚¬ë„ë¥¼ ì¸¡ì •í•©ë‹ˆë‹¤. ë¶ˆí•„ìš”í•œ ì •ë³´ë‚˜ ì£¼ì œì—ì„œ ë²—ì–´ë‚œ ë‚´ìš©ì„ ê°ì§€í•©ë‹ˆë‹¤.
              </p>
            </div>

            <div className="bg-gray-50 dark:bg-gray-900 p-6 rounded-xl">
              <h3 className="font-bold text-gray-800 dark:text-gray-200 mb-4">ìë™í™”ëœ í‰ê°€ íŒŒì´í”„ë¼ì¸</h3>
              <pre className="bg-black text-green-400 p-4 rounded-lg overflow-x-auto">
                <code>{`# Production í™˜ê²½ì„ ìœ„í•œ ìë™ í‰ê°€ ì‹œìŠ¤í…œ
import pandas as pd
from datetime import datetime
import json

class RAGEvaluationPipeline:
    def __init__(self):
        self.metrics = [
            context_relevancy,
            answer_faithfulness,
            answer_relevancy,
            context_recall
        ]
        self.thresholds = {
            'context_relevancy': 0.7,
            'answer_faithfulness': 0.8,
            'answer_relevancy': 0.75,
            'context_recall': 0.65
        }
        
    def evaluate_batch(self, qa_pairs):
        """ë°°ì¹˜ í‰ê°€ ì‹¤í–‰"""
        dataset = Dataset.from_dict(qa_pairs)
        results = evaluate(dataset, metrics=self.metrics)
        
        # ê²°ê³¼ ë¶„ì„
        analysis = self.analyze_results(results)
        
        # ë¡œê¹…
        self.log_results(results, analysis)
        
        # ì•Œë¦¼ í™•ì¸
        self.check_alerts(analysis)
        
        return analysis
    
    def analyze_results(self, results):
        """ê²°ê³¼ ë¶„ì„ ë° ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
        analysis = {
            'timestamp': datetime.now().isoformat(),
            'scores': {},
            'warnings': [],
            'insights': []
        }
        
        for metric_name, score in results.items():
            analysis['scores'][metric_name] = score
            
            # ì„ê³„ê°’ ì²´í¬
            if score < self.thresholds.get(metric_name, 0.5):
                analysis['warnings'].append({
                    'metric': metric_name,
                    'score': score,
                    'threshold': self.thresholds[metric_name],
                    'severity': 'high' if score < 0.5 else 'medium'
                })
        
        # ì¸ì‚¬ì´íŠ¸ ìƒì„±
        if results['context_relevancy'] < 0.7:
            analysis['insights'].append(
                "ê²€ìƒ‰ í’ˆì§ˆ ê°œì„  í•„ìš”: ì„ë² ë”© ëª¨ë¸ ì¬í•™ìŠµ ê³ ë ¤"
            )
            
        if results['answer_faithfulness'] < 0.8:
            analysis['insights'].append(
                "í™˜ê° ìœ„í—˜ ê°ì§€: í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ì¬ê²€í†  í•„ìš”"
            )
            
        return analysis
    
    def log_results(self, results, analysis):
        """ê²°ê³¼ ë¡œê¹…"""
        log_entry = {
            'timestamp': analysis['timestamp'],
            'raw_scores': results,
            'analysis': analysis
        }
        
        # JSON íŒŒì¼ë¡œ ì €ì¥ (ì‹¤ì œë¡œëŠ” DBë‚˜ ë¡œê¹… ì‹œìŠ¤í…œ ì‚¬ìš©)
        with open(f"rag_eval_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json", 'w') as f:
            json.dump(log_entry, f, indent=2)
    
    def check_alerts(self, analysis):
        """ì•Œë¦¼ ì¡°ê±´ í™•ì¸"""
        if analysis['warnings']:
            # ì‹¤ì œë¡œëŠ” Slack, Email ë“±ìœ¼ë¡œ ì•Œë¦¼ ë°œì†¡
            print("âš ï¸ ALERT: RAG í’ˆì§ˆ ì €í•˜ ê°ì§€!")
            for warning in analysis['warnings']:
                print(f"  - {warning['metric']}: {warning['score']:.3f} (ì„ê³„ê°’: {warning['threshold']})")

# ì‚¬ìš© ì˜ˆì œ
pipeline = RAGEvaluationPipeline()

# ì‹¤ì œ QA ë°ì´í„°
qa_data = {
    "question": ["ì„œìš¸ì˜ ì¸êµ¬ëŠ”?", "Python ë¦¬ìŠ¤íŠ¸ ì •ë ¬ ë°©ë²•ì€?"],
    "contexts": [
        ["ì„œìš¸ì˜ ì¸êµ¬ëŠ” ì•½ 950ë§Œëª…ì…ë‹ˆë‹¤."],
        ["Pythonì—ì„œ ë¦¬ìŠ¤íŠ¸ë¥¼ ì •ë ¬í•˜ë ¤ë©´ sort() ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì„¸ìš”."]
    ],
    "answer": [
        "ì„œìš¸ì˜ ì¸êµ¬ëŠ” ì•½ 950ë§Œëª…ì…ë‹ˆë‹¤.",
        "sort() ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ë©´ ë©ë‹ˆë‹¤."
    ],
    "ground_truths": [
        ["ì„œìš¸ ì¸êµ¬ëŠ” 950ë§Œëª…"],
        ["sort() ë©”ì„œë“œ ì‚¬ìš©", "sorted() í•¨ìˆ˜ ì‚¬ìš©"]
    ]
}

# í‰ê°€ ì‹¤í–‰
analysis = pipeline.evaluate_batch(qa_data)
print(json.dumps(analysis, indent=2, ensure_ascii=False))`}</code>
              </pre>
            </div>
          </div>
        </section>

        {/* Section 5: Custom Metrics */}
        <section className="bg-white dark:bg-gray-800 rounded-2xl p-8 shadow-sm border border-gray-200 dark:border-gray-700">
          <div className="flex items-center gap-3 mb-6">
            <div className="w-12 h-12 rounded-xl bg-indigo-100 dark:bg-indigo-900/20 flex items-center justify-center">
              <Code className="text-indigo-600" size={24} />
            </div>
            <div>
              <h2 className="text-2xl font-bold text-gray-900 dark:text-white">1.5 ì»¤ìŠ¤í…€ ë©”íŠ¸ë¦­ ê°œë°œ</h2>
              <p className="text-gray-600 dark:text-gray-400">ë¹„ì¦ˆë‹ˆìŠ¤ ìš”êµ¬ì‚¬í•­ì— ë§ì¶˜ í‰ê°€ ì§€í‘œ ìƒì„±</p>
            </div>
          </div>

          <div className="space-y-6">
            <div className="bg-indigo-50 dark:bg-indigo-900/20 p-6 rounded-xl">
              <h3 className="font-bold text-indigo-800 dark:text-indigo-200 mb-3">ì‹¤ë¬´ ì‚¬ë¡€: ë„ë©”ì¸ íŠ¹í™” ë©”íŠ¸ë¦­</h3>
              <p className="text-indigo-700 dark:text-indigo-300 mb-4">
                ì˜ë£Œ, ë²•ë¥ , ê¸ˆìœµ ë“± ë„ë©”ì¸ë³„ë¡œ íŠ¹í™”ëœ í‰ê°€ ê¸°ì¤€ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
              </p>
            </div>

            <div className="bg-gray-50 dark:bg-gray-900 p-6 rounded-xl">
              <h3 className="font-bold text-gray-800 dark:text-gray-200 mb-4">ì˜ë£Œ ë„ë©”ì¸ ì»¤ìŠ¤í…€ ë©”íŠ¸ë¦­ ì˜ˆì œ</h3>
              <pre className="bg-black text-green-400 p-4 rounded-lg overflow-x-auto">
                <code>{`from ragas.metrics import Metric
from langchain.chat_models import ChatOpenAI
import re

class MedicalAccuracyMetric(Metric):
    """ì˜ë£Œ ì •ë³´ì˜ ì •í™•ì„±ì„ í‰ê°€í•˜ëŠ” ì»¤ìŠ¤í…€ ë©”íŠ¸ë¦­"""
    
    name = "medical_accuracy"
    
    def __init__(self):
        self.llm = ChatOpenAI(temperature=0)
        # ì˜ë£Œ ì „ë¬¸ ìš©ì–´ ì‚¬ì „
        self.medical_terms = {
            "ì•½ë¬¼ëª…": ["ì•„ìŠ¤í”¼ë¦°", "íƒ€ì´ë ˆë†€", "ë¶€ë£¨íœ"],
            "ìš©ëŸ‰ë‹¨ìœ„": ["mg", "ml", "IU"],
            "ê¸ˆê¸°ì‚¬í•­": ["ì„ì‚°ë¶€", "ìˆ˜ìœ ë¶€", "ì•Œë ˆë¥´ê¸°"]
        }
    
    def score(self, question, answer, context):
        """ì˜ë£Œ ì •ë³´ ì •í™•ì„± ì ìˆ˜ ê³„ì‚°"""
        scores = []
        
        # 1. ì•½ë¬¼ ìš©ëŸ‰ ì •í™•ì„± ì²´í¬
        dose_score = self._check_dosage_accuracy(answer, context)
        scores.append(dose_score)
        
        # 2. ê¸ˆê¸°ì‚¬í•­ ëˆ„ë½ ì²´í¬
        contraindication_score = self._check_contraindications(answer, context)
        scores.append(contraindication_score)
        
        # 3. ì˜í•™ ìš©ì–´ ì¼ê´€ì„± ì²´í¬
        terminology_score = self._check_terminology_consistency(answer, context)
        scores.append(terminology_score)
        
        # ì „ì²´ ì ìˆ˜ ê³„ì‚° (ê°€ì¤‘í‰ê· )
        weights = [0.5, 0.3, 0.2]  # ìš©ëŸ‰ > ê¸ˆê¸°ì‚¬í•­ > ìš©ì–´
        final_score = sum(s * w for s, w in zip(scores, weights))
        
        return final_score
    
    def _check_dosage_accuracy(self, answer, context):
        """ì•½ë¬¼ ìš©ëŸ‰ ì •ë³´ì˜ ì •í™•ì„± í™•ì¸"""
        # ìˆ«ì+ë‹¨ìœ„ íŒ¨í„´ ì¶”ì¶œ
        dose_pattern = r'\d+\s*(mg|ml|IU|g)'
        
        answer_doses = re.findall(dose_pattern, answer)
        context_doses = re.findall(dose_pattern, context)
        
        if not answer_doses:
            return 1.0  # ìš©ëŸ‰ ì •ë³´ ì—†ìœ¼ë©´ íŒ¨ìŠ¤
            
        # ë‹µë³€ì˜ ìš©ëŸ‰ì´ ë¬¸ë§¥ì— ìˆëŠ”ì§€ í™•ì¸
        correct_doses = sum(1 for dose in answer_doses if dose in context_doses)
        
        return correct_doses / len(answer_doses) if answer_doses else 1.0
    
    def _check_contraindications(self, answer, context):
        """ì¤‘ìš” ê¸ˆê¸°ì‚¬í•­ ëˆ„ë½ í™•ì¸"""
        # ë¬¸ë§¥ì—ì„œ ê¸ˆê¸°ì‚¬í•­ ì¶”ì¶œ
        context_warnings = []
        for warning in self.medical_terms["ê¸ˆê¸°ì‚¬í•­"]:
            if warning in context:
                context_warnings.append(warning)
        
        if not context_warnings:
            return 1.0  # ê¸ˆê¸°ì‚¬í•­ ì—†ìœ¼ë©´ íŒ¨ìŠ¤
            
        # ë‹µë³€ì— í¬í•¨ë˜ì—ˆëŠ”ì§€ í™•ì¸
        included_warnings = sum(1 for w in context_warnings if w in answer)
        
        return included_warnings / len(context_warnings)
    
    def _check_terminology_consistency(self, answer, context):
        """ì˜í•™ ìš©ì–´ ì¼ê´€ì„± í™•ì¸"""
        # ê°„ë‹¨í•œ ì¼ê´€ì„± ì²´í¬ (ì‹¤ì œë¡œëŠ” ë” ë³µì¡)
        return 0.9  # ì˜ˆì œë¥¼ ìœ„í•œ ê³ ì •ê°’

# ì‚¬ìš© ì˜ˆì œ
medical_metric = MedicalAccuracyMetric()

# ì˜ë£Œ QA ë°ì´í„°
medical_qa = {
    "question": "ê°ê¸°ì— íƒ€ì´ë ˆë†€ ë³µìš©ë²•ì€?",
    "context": "íƒ€ì´ë ˆë†€ì€ ì„±ì¸ ê¸°ì¤€ 500mgì„ 4-6ì‹œê°„ë§ˆë‹¤ ë³µìš©í•©ë‹ˆë‹¤. ì¼ì¼ ìµœëŒ€ 4000mgì„ ì´ˆê³¼í•˜ì§€ ë§ˆì„¸ìš”. ì„ì‚°ë¶€ëŠ” ì˜ì‚¬ì™€ ìƒë‹´ í›„ ë³µìš©í•˜ì„¸ìš”.",
    "answer": "íƒ€ì´ë ˆë†€ì€ 500mgì„ 4ì‹œê°„ë§ˆë‹¤ ë³µìš©í•˜ë©´ ë©ë‹ˆë‹¤."  # ì„ì‚°ë¶€ ì£¼ì˜ì‚¬í•­ ëˆ„ë½
}

score = medical_metric.score(
    medical_qa["question"],
    medical_qa["answer"],
    medical_qa["context"]
)

print(f"Medical Accuracy Score: {score:.3f}")
print("âš ï¸ ê²½ê³ : ì¤‘ìš” ê¸ˆê¸°ì‚¬í•­ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤!" if score < 0.8 else "âœ… ì˜ë£Œ ì •ë³´ ì •í™•ë„ ì–‘í˜¸")`}</code>
              </pre>
            </div>

            <div className="bg-yellow-50 dark:bg-yellow-900/20 p-6 rounded-xl">
              <h3 className="font-bold text-yellow-800 dark:text-yellow-200 mb-3">Production ê³ ë ¤ì‚¬í•­</h3>
              <div className="space-y-3">
                <div className="flex items-start gap-2">
                  <AlertCircle className="text-yellow-600 mt-1" size={16} />
                  <div className="text-yellow-700 dark:text-yellow-300">
                    <p className="font-semibold">í‰ê°€ ë¹„ìš© ìµœì í™”</p>
                    <p className="text-sm">ìƒ˜í”Œë§ ì „ëµ: ì „ì²´ì˜ 10-20%ë§Œ í‰ê°€í•˜ì—¬ ë¹„ìš© ì ˆê°</p>
                  </div>
                </div>
                <div className="flex items-start gap-2">
                  <AlertCircle className="text-yellow-600 mt-1" size={16} />
                  <div className="text-yellow-700 dark:text-yellow-300">
                    <p className="font-semibold">ì‹¤ì‹œê°„ vs ë°°ì¹˜ í‰ê°€</p>
                    <p className="text-sm">ì¤‘ìš” ì¿¼ë¦¬ëŠ” ì‹¤ì‹œê°„, ë‚˜ë¨¸ì§€ëŠ” ì¼ì¼ ë°°ì¹˜ë¡œ ì²˜ë¦¬</p>
                  </div>
                </div>
              </div>
            </div>
          </div>
        </section>

        {/* Section 6: Practical Implementation */}
        <section className="bg-white dark:bg-gray-800 rounded-2xl p-8 shadow-sm border border-gray-200 dark:border-gray-700">
          <div className="flex items-center gap-3 mb-6">
            <div className="w-12 h-12 rounded-xl bg-purple-100 dark:bg-purple-900/20 flex items-center justify-center">
              <TrendingUp className="text-purple-600" size={24} />
            </div>
            <div>
              <h2 className="text-2xl font-bold text-gray-900 dark:text-white">1.6 Production êµ¬í˜„ ê°€ì´ë“œ</h2>
              <p className="text-gray-600 dark:text-gray-400">ì‹¤ì œ ì„œë¹„ìŠ¤ì—ì„œì˜ RAGAS í™œìš©ë²•</p>
            </div>
          </div>

          <div className="space-y-6">
            <div className="bg-gradient-to-r from-purple-50 to-pink-50 dark:from-purple-900/20 dark:to-pink-900/20 p-6 rounded-xl">
              <h3 className="font-bold text-purple-800 dark:text-purple-200 mb-4">ì™„ì „í•œ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ</h3>
              <pre className="bg-black text-green-400 p-4 rounded-lg overflow-x-auto">
                <code>{`# Production ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ
import streamlit as st
import pandas as pd
import plotly.graph_objects as go
from datetime import datetime, timedelta

class RAGMonitoringDashboard:
    def __init__(self):
        self.metrics_history = []
        
    def add_evaluation(self, eval_results):
        """í‰ê°€ ê²°ê³¼ ì¶”ê°€"""
        self.metrics_history.append({
            'timestamp': datetime.now(),
            'scores': eval_results,
            'alerts': self._check_alerts(eval_results)
        })
    
    def _check_alerts(self, scores):
        """ì•Œë¦¼ ì¡°ê±´ í™•ì¸"""
        alerts = []
        thresholds = {
            'context_relevancy': 0.7,
            'answer_faithfulness': 0.8,
            'answer_relevancy': 0.75
        }
        
        for metric, threshold in thresholds.items():
            if scores.get(metric, 1.0) < threshold:
                alerts.append({
                    'metric': metric,
                    'score': scores[metric],
                    'threshold': threshold,
                    'severity': 'high' if scores[metric] < threshold * 0.7 else 'medium'
                })
        
        return alerts
    
    def render_dashboard(self):
        """Streamlit ëŒ€ì‹œë³´ë“œ ë Œë”ë§"""
        st.title("ğŸš€ RAG System Monitoring Dashboard")
        
        # í˜„ì¬ ìƒíƒœ ìš”ì•½
        col1, col2, col3, col4 = st.columns(4)
        
        latest_scores = self.metrics_history[-1]['scores'] if self.metrics_history else {}
        
        with col1:
            st.metric(
                "Context Relevancy",
                f"{latest_scores.get('context_relevancy', 0):.2%}",
                delta=self._calculate_delta('context_relevancy')
            )
        
        with col2:
            st.metric(
                "Answer Faithfulness",
                f"{latest_scores.get('answer_faithfulness', 0):.2%}",
                delta=self._calculate_delta('answer_faithfulness')
            )
        
        with col3:
            st.metric(
                "Answer Relevancy",
                f"{latest_scores.get('answer_relevancy', 0):.2%}",
                delta=self._calculate_delta('answer_relevancy')
            )
        
        with col4:
            active_alerts = sum(len(h['alerts']) for h in self.metrics_history[-10:])
            st.metric("Active Alerts", active_alerts, delta=-2 if active_alerts > 0 else 0)
        
        # ì‹œê³„ì—´ ê·¸ë˜í”„
        st.subheader("ğŸ“Š Metrics Over Time")
        self._render_time_series()
        
        # ì•Œë¦¼ ì„¹ì…˜
        st.subheader("âš ï¸ Recent Alerts")
        self._render_alerts()
        
        # ê¶Œì¥ ì¡°ì¹˜
        st.subheader("ğŸ’¡ Recommended Actions")
        self._render_recommendations()
    
    def _calculate_delta(self, metric_name):
        """ë³€í™”ëŸ‰ ê³„ì‚°"""
        if len(self.metrics_history) < 2:
            return 0
        
        current = self.metrics_history[-1]['scores'].get(metric_name, 0)
        previous = self.metrics_history[-2]['scores'].get(metric_name, 0)
        
        return f"{(current - previous):.1%}"
    
    def _render_time_series(self):
        """ì‹œê³„ì—´ ì°¨íŠ¸ ë Œë”ë§"""
        if not self.metrics_history:
            st.info("No data available yet")
            return
        
        # ë°ì´í„° ì¤€ë¹„
        df = pd.DataFrame([
            {
                'timestamp': h['timestamp'],
                **h['scores']
            }
            for h in self.metrics_history
        ])
        
        # Plotly ì°¨íŠ¸
        fig = go.Figure()
        
        for metric in ['context_relevancy', 'answer_faithfulness', 'answer_relevancy']:
            fig.add_trace(go.Scatter(
                x=df['timestamp'],
                y=df[metric],
                mode='lines+markers',
                name=metric.replace('_', ' ').title(),
                line=dict(width=2)
            ))
        
        # ì„ê³„ê°’ ë¼ì¸ ì¶”ê°€
        fig.add_hline(y=0.8, line_dash="dash", line_color="red", 
                      annotation_text="Critical Threshold")
        fig.add_hline(y=0.7, line_dash="dash", line_color="orange", 
                      annotation_text="Warning Threshold")
        
        fig.update_layout(
            title="RAG Metrics Trend",
            xaxis_title="Time",
            yaxis_title="Score",
            yaxis=dict(range=[0, 1]),
            hovermode='x unified'
        )
        
        st.plotly_chart(fig, use_container_width=True)
    
    def _render_alerts(self):
        """ìµœê·¼ ì•Œë¦¼ í‘œì‹œ"""
        recent_alerts = []
        for h in self.metrics_history[-10:]:
            for alert in h['alerts']:
                recent_alerts.append({
                    'Time': h['timestamp'].strftime('%Y-%m-%d %H:%M'),
                    'Metric': alert['metric'].replace('_', ' ').title(),
                    'Score': f"{alert['score']:.2%}",
                    'Threshold': f"{alert['threshold']:.2%}",
                    'Severity': alert['severity'].upper()
                })
        
        if recent_alerts:
            df = pd.DataFrame(recent_alerts)
            st.dataframe(
                df,
                use_container_width=True,
                hide_index=True
            )
        else:
            st.success("No alerts in recent evaluations!")
    
    def _render_recommendations(self):
        """ê¶Œì¥ ì¡°ì¹˜ ì œì•ˆ"""
        if not self.metrics_history:
            return
        
        latest = self.metrics_history[-1]['scores']
        
        recommendations = []
        
        if latest.get('context_relevancy', 1) < 0.7:
            recommendations.append({
                'issue': 'Low Context Relevancy',
                'action': 'â€¢ ì„ë² ë”© ëª¨ë¸ ì¬í•™ìŠµ\nâ€¢ ì²­í‚¹ ì „ëµ ê°œì„ \nâ€¢ ë©”íƒ€ë°ì´í„° í•„í„°ë§ ê°•í™”'
            })
        
        if latest.get('answer_faithfulness', 1) < 0.8:
            recommendations.append({
                'issue': 'Low Answer Faithfulness',
                'action': 'â€¢ í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ê°œì„ \nâ€¢ ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš° í¬ê¸° ì¡°ì •\nâ€¢ Few-shot ì˜ˆì œ ì¶”ê°€'
            })
        
        if recommendations:
            for rec in recommendations:
                st.warning(f"**{rec['issue']}**")
                st.markdown(rec['action'])
        else:
            st.success("ì‹œìŠ¤í…œì´ ìµœì  ìƒíƒœë¡œ ìš´ì˜ ì¤‘ì…ë‹ˆë‹¤!")

# ì‹¤ì œ ì‚¬ìš© ì˜ˆì œ
if __name__ == "__main__":
    dashboard = RAGMonitoringDashboard()
    
    # ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ì¶”ê°€ (ì‹¤ì œë¡œëŠ” ì‹¤ì‹œê°„ í‰ê°€ ê²°ê³¼)
    import random
    for i in range(24):  # 24ì‹œê°„ ë°ì´í„°
        scores = {
            'context_relevancy': random.uniform(0.65, 0.85),
            'answer_faithfulness': random.uniform(0.75, 0.95),
            'answer_relevancy': random.uniform(0.70, 0.90),
            'context_recall': random.uniform(0.60, 0.80)
        }
        dashboard.add_evaluation(scores)
    
    # Streamlit ì•± ì‹¤í–‰
    dashboard.render_dashboard()`}</code>
              </pre>
            </div>

            <div className="bg-blue-50 dark:bg-blue-900/20 p-6 rounded-xl">
              <h3 className="font-bold text-blue-800 dark:text-blue-200 mb-3">ë¹„ìš© ë¶„ì„</h3>
              <div className="overflow-x-auto">
                <table className="w-full text-sm">
                  <thead>
                    <tr className="border-b border-blue-200 dark:border-blue-700">
                      <th className="text-left py-2 text-blue-800 dark:text-blue-200">í‰ê°€ ì „ëµ</th>
                      <th className="text-right py-2 text-blue-800 dark:text-blue-200">ì›”ê°„ ì¿¼ë¦¬</th>
                      <th className="text-right py-2 text-blue-800 dark:text-blue-200">í‰ê°€ ë¹„ìœ¨</th>
                      <th className="text-right py-2 text-blue-800 dark:text-blue-200">ì˜ˆìƒ ë¹„ìš©</th>
                    </tr>
                  </thead>
                  <tbody className="text-blue-700 dark:text-blue-300">
                    <tr>
                      <td className="py-2">ì „ì²´ í‰ê°€</td>
                      <td className="text-right">100,000</td>
                      <td className="text-right">100%</td>
                      <td className="text-right">$2,000</td>
                    </tr>
                    <tr>
                      <td className="py-2">ìƒ˜í”Œë§ (ê¶Œì¥)</td>
                      <td className="text-right">100,000</td>
                      <td className="text-right">15%</td>
                      <td className="text-right">$300</td>
                    </tr>
                    <tr>
                      <td className="py-2">ì¤‘ìš” ì¿¼ë¦¬ë§Œ</td>
                      <td className="text-right">100,000</td>
                      <td className="text-right">5%</td>
                      <td className="text-right">$100</td>
                    </tr>
                  </tbody>
                </table>
              </div>
            </div>
          </div>
        </section>

        {/* References */}
        <References
          sections={[
            {
              title: 'ğŸ“š RAGAS & í‰ê°€ í”„ë ˆì„ì›Œí¬',
              icon: 'web' as const,
              color: 'border-purple-500',
              items: [
                {
                  title: 'RAGAS Official Documentation',
                  authors: 'Explodinggradients',
                  year: '2024',
                  description: 'RAG í‰ê°€ í”„ë ˆì„ì›Œí¬ - Context Relevancy, Answer Faithfulness, Answer Relevancy ê³µì‹ ë¬¸ì„œ',
                  link: 'https://docs.ragas.io/'
                },
                {
                  title: 'TruLens: LLM Evaluation & Observability',
                  authors: 'TruEra',
                  year: '2024',
                  description: 'LLM ì• í”Œë¦¬ì¼€ì´ì…˜ í‰ê°€ - Groundedness, Answer Relevance, Context Relevance ì¸¡ì •',
                  link: 'https://www.trulens.org/'
                },
                {
                  title: 'LangSmith Evaluation',
                  authors: 'LangChain',
                  year: '2024',
                  description: 'LangChain ê³µì‹ í‰ê°€ ë„êµ¬ - ìë™í™”ëœ í…ŒìŠ¤íŠ¸, ë¹„êµ ë¶„ì„, Production ëª¨ë‹ˆí„°ë§',
                  link: 'https://docs.smith.langchain.com/evaluation'
                },
                {
                  title: 'DeepEval: Unit Testing for LLMs',
                  authors: 'Confident AI',
                  year: '2024',
                  description: 'LLM ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ í”„ë ˆì„ì›Œí¬ - 14ê°œ í‰ê°€ ë©”íŠ¸ë¦­, Pytest í†µí•©, CI/CD ì§€ì›',
                  link: 'https://docs.confident-ai.com/'
                },
                {
                  title: 'Evidently AI: ML Monitoring',
                  authors: 'Evidently AI',
                  year: '2024',
                  description: 'ML ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ - ë°ì´í„° ë“œë¦¬í”„íŠ¸, ì„±ëŠ¥ ì €í•˜ ê°ì§€, ëŒ€ì‹œë³´ë“œ ìƒì„±',
                  link: 'https://www.evidentlyai.com/'
                }
              ]
            },
            {
              title: 'ğŸ“– RAG í‰ê°€ ì—°êµ¬ ë…¼ë¬¸',
              icon: 'research' as const,
              color: 'border-pink-500',
              items: [
                {
                  title: 'ARES: An Automated Evaluation Framework for RAG',
                  authors: 'Saad-Falcon et al., Stanford',
                  year: '2024',
                  description: 'ìë™í™”ëœ RAG í‰ê°€ - Synthetic ë°ì´í„° ìƒì„±, LLM-as-judge, ì¸ê°„ í‰ê°€ ëŒ€ì²´',
                  link: 'https://arxiv.org/abs/2311.09476'
                },
                {
                  title: 'Benchmarking Large Language Models in RAG',
                  authors: 'Chen et al., Tsinghua University',
                  year: '2024',
                  description: 'RGB ë²¤ì¹˜ë§ˆí¬ - 4ê°œ ë„ë©”ì¸, ë‹¤ì–‘í•œ RAG ì‹œë‚˜ë¦¬ì˜¤, ì¢…í•© í‰ê°€ í”„ë ˆì„ì›Œí¬',
                  link: 'https://arxiv.org/abs/2309.01431'
                },
                {
                  title: 'RAGAS: Automated Evaluation of RAG',
                  authors: 'Es et al., Explodinggradients',
                  year: '2023',
                  description: 'RAGAS ë…¼ë¬¸ - Reference-free í‰ê°€, LLM ê¸°ë°˜ ë©”íŠ¸ë¦­, ìë™í™”ëœ í’ˆì§ˆ ì¸¡ì •',
                  link: 'https://arxiv.org/abs/2309.15217'
                },
                {
                  title: 'Evaluating RAG: A Survey',
                  authors: 'Liu et al., Microsoft Research',
                  year: '2024',
                  description: 'RAG í‰ê°€ ì„œë² ì´ - ê¸°ì¡´ ë©”íŠ¸ë¦­ ë¶„ë¥˜, í•œê³„ì  ë¶„ì„, ë¯¸ë˜ ë°©í–¥ ì œì‹œ',
                  link: 'https://arxiv.org/abs/2405.17009'
                }
              ]
            },
            {
              title: 'ğŸ› ï¸ Production ëª¨ë‹ˆí„°ë§ ë„êµ¬',
              icon: 'tools' as const,
              color: 'border-blue-500',
              items: [
                {
                  title: 'Weights & Biases: ML Experiment Tracking',
                  authors: 'Weights & Biases',
                  year: '2024',
                  description: 'ML ì‹¤í—˜ ì¶”ì  - ë©”íŠ¸ë¦­ ì‹œê°í™”, í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”, íŒ€ í˜‘ì—…',
                  link: 'https://wandb.ai/'
                },
                {
                  title: 'MLflow: Open Source ML Platform',
                  authors: 'Databricks',
                  year: '2024',
                  description: 'ML ë¼ì´í”„ì‚¬ì´í´ ê´€ë¦¬ - ì‹¤í—˜ ì¶”ì , ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬, ë°°í¬ ìë™í™”',
                  link: 'https://mlflow.org/'
                },
                {
                  title: 'Streamlit: Data App Framework',
                  authors: 'Snowflake',
                  year: '2024',
                  description: 'Python ëŒ€ì‹œë³´ë“œ - ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ UI, ë¹ ë¥¸ í”„ë¡œí† íƒ€ì´í•‘, ì¸í„°ë™í‹°ë¸Œ ì°¨íŠ¸',
                  link: 'https://streamlit.io/'
                },
                {
                  title: 'Grafana + Prometheus: Metrics Monitoring',
                  authors: 'Grafana Labs',
                  year: '2024',
                  description: 'ì‹œê³„ì—´ ë©”íŠ¸ë¦­ ëª¨ë‹ˆí„°ë§ - ì•Œë¦¼ ì„¤ì •, ì‹¤ì‹œê°„ ëŒ€ì‹œë³´ë“œ, ë‹¤ì¤‘ ë°ì´í„°ì†ŒìŠ¤ ì§€ì›',
                  link: 'https://grafana.com/'
                },
                {
                  title: 'Arize AI: ML Observability Platform',
                  authors: 'Arize AI',
                  year: '2024',
                  description: 'ML ê´€ì¸¡ì„± í”Œë«í¼ - ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§, ë“œë¦¬í”„íŠ¸ ê°ì§€, ê·¼ë³¸ ì›ì¸ ë¶„ì„',
                  link: 'https://arize.com/'
                }
              ]
            }
          ]}
        />

        {/* Navigation */}
        <div className="flex justify-between items-center mt-12 pt-8 border-t border-gray-200 dark:border-gray-700">
          <Link
            href="/modules/rag/supplementary"
            className="flex items-center gap-2 text-purple-600 hover:text-purple-700 transition-colors"
          >
            <ArrowLeft size={20} />
            ë³´ì¶© ê³¼ì •ìœ¼ë¡œ ëŒì•„ê°€ê¸°
          </Link>
          
          <Link
            href="/modules/rag/supplementary/chapter2"
            className="flex items-center gap-2 text-purple-600 hover:text-purple-700 transition-colors"
          >
            ë‹¤ìŒ: Security & Privacy
            <ArrowRight size={20} />
          </Link>
        </div>
      </div>
    </div>
  )
}